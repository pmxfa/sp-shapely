{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "cell_execution_strategy": "setup",
      "authorship_tag": "ABX9TyOM17UOvknP4QNb1+V7mLLT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pmxfa/sp-shapely/blob/main/sp_timegan_exchange.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oaMLghK_ipz1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "outputId": "73200327-180a-45d0-d1ab-155340f8f7d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting synthcity\n",
            "  Downloading synthcity-0.2.12-py3-none-any.whl.metadata (37 kB)\n",
            "Collecting tsbootstrap\n",
            "  Downloading tsbootstrap-0.1.5-py3-none-any.whl.metadata (28 kB)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from synthcity) (8.7.0)\n",
            "Requirement already satisfied: pandas>=2.1 in /usr/local/lib/python3.11/dist-packages (from synthcity) (2.2.2)\n",
            "Collecting torch<2.3,>=2.1 (from synthcity)\n",
            "  Downloading torch-2.2.2-cp311-cp311-manylinux1_x86_64.whl.metadata (25 kB)\n",
            "Requirement already satisfied: scikit-learn>=1.2 in /usr/local/lib/python3.11/dist-packages (from synthcity) (1.6.1)\n",
            "Collecting nflows>=0.14 (from synthcity)\n",
            "  Downloading nflows-0.14.tar.gz (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.8/45.8 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting numpy<2.0,>=1.20 (from synthcity)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lifelines<0.30.0,>=0.29.0 (from synthcity)\n",
            "  Downloading lifelines-0.29.0-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting opacus>=1.3 (from synthcity)\n",
            "  Downloading opacus-1.5.3-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting networkx<3.0,>2.0 (from synthcity)\n",
            "  Downloading networkx-2.8.8-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting decaf-synthetic-data>=0.1.6 (from synthcity)\n",
            "  Downloading decaf_synthetic_data-0.1.6-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting optuna>=3.1 (from synthcity)\n",
            "  Downloading optuna-4.3.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: shap in /usr/local/lib/python3.11/dist-packages (from synthcity) (0.47.2)\n",
            "Requirement already satisfied: tenacity in /usr/local/lib/python3.11/dist-packages (from synthcity) (9.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from synthcity) (4.67.1)\n",
            "Collecting loguru (from synthcity)\n",
            "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from synthcity) (2.11.4)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from synthcity) (3.1.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from synthcity) (1.15.3)\n",
            "Requirement already satisfied: xgboost<3.0.0 in /usr/local/lib/python3.11/dist-packages (from synthcity) (2.1.4)\n",
            "Collecting geomloss (from synthcity)\n",
            "  Downloading geomloss-0.2.6.tar.gz (26 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pgmpy<1.0 (from synthcity)\n",
            "  Downloading pgmpy-0.1.26-py3-none-any.whl.metadata (9.1 kB)\n",
            "Collecting redis (from synthcity)\n",
            "  Downloading redis-6.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting pycox (from synthcity)\n",
            "  Downloading pycox-0.3.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting xgbse>=0.3.1 (from synthcity)\n",
            "  Downloading xgbse-0.3.3-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting pykeops (from synthcity)\n",
            "  Downloading pykeops-2.3.tar.gz (552 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m552.2/552.2 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting fflows (from synthcity)\n",
            "  Downloading fflows-0.0.3-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting monai (from synthcity)\n",
            "  Downloading monai-1.4.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting tsai (from synthcity)\n",
            "  Downloading tsai-0.4.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting be-great>=0.0.5 (from synthcity)\n",
            "  Downloading be_great-0.0.9-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting arfpy (from synthcity)\n",
            "  Downloading arfpy-0.1.1.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: fastcore<1.8 in /usr/local/lib/python3.11/dist-packages (from synthcity) (1.7.29)\n",
            "Requirement already satisfied: fastai<2.8 in /usr/local/lib/python3.11/dist-packages (from synthcity) (2.7.19)\n",
            "Collecting scikit-base<0.11,>=0.10.0 (from tsbootstrap)\n",
            "  Downloading scikit_base-0.10.1-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting scikit-learn>=1.2 (from synthcity)\n",
            "  Downloading scikit_learn-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Collecting scipy (from synthcity)\n",
            "  Downloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting packaging<24.2,>=24.0 (from tsbootstrap)\n",
            "  Downloading packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: datasets>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from be-great>=0.0.5->synthcity) (2.14.4)\n",
            "Requirement already satisfied: transformers>=4.22.1 in /usr/local/lib/python3.11/dist-packages (from be-great>=0.0.5->synthcity) (4.51.3)\n",
            "Requirement already satisfied: accelerate>=0.20.1 in /usr/local/lib/python3.11/dist-packages (from be-great>=0.0.5->synthcity) (1.6.0)\n",
            "Collecting pytorch-lightning<2.0 (from decaf-synthetic-data>=0.1.6->synthcity)\n",
            "  Downloading pytorch_lightning-1.9.5-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting torchtext>=0.10 (from decaf-synthetic-data>=0.1.6->synthcity)\n",
            "  Downloading torchtext-0.18.0-cp311-cp311-manylinux1_x86_64.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (from fastai<2.8->synthcity) (24.1.2)\n",
            "Requirement already satisfied: fastdownload<2,>=0.0.5 in /usr/local/lib/python3.11/dist-packages (from fastai<2.8->synthcity) (0.0.7)\n",
            "Requirement already satisfied: torchvision>=0.11 in /usr/local/lib/python3.11/dist-packages (from fastai<2.8->synthcity) (0.21.0+cu124)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from fastai<2.8->synthcity) (3.10.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from fastai<2.8->synthcity) (2.32.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from fastai<2.8->synthcity) (6.0.2)\n",
            "Requirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.11/dist-packages (from fastai<2.8->synthcity) (1.0.3)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from fastai<2.8->synthcity) (11.2.1)\n",
            "Requirement already satisfied: spacy<4 in /usr/local/lib/python3.11/dist-packages (from fastai<2.8->synthcity) (3.8.5)\n",
            "Requirement already satisfied: autograd>=1.5 in /usr/local/lib/python3.11/dist-packages (from lifelines<0.30.0,>=0.29.0->synthcity) (1.8.0)\n",
            "Collecting autograd-gamma>=0.3 (from lifelines<0.30.0,>=0.29.0->synthcity)\n",
            "  Downloading autograd-gamma-0.5.0.tar.gz (4.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting formulaic>=0.2.2 (from lifelines<0.30.0,>=0.29.0->synthcity)\n",
            "  Downloading formulaic-1.1.1-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (from nflows>=0.14->synthcity) (2.18.0)\n",
            "Requirement already satisfied: opt-einsum>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from opacus>=1.3->synthcity) (3.4.0)\n",
            "Collecting alembic>=1.5.0 (from optuna>=3.1->synthcity)\n",
            "  Downloading alembic-1.16.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting colorlog (from optuna>=3.1->synthcity)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna>=3.1->synthcity) (2.0.40)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1->synthcity) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1->synthcity) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1->synthcity) (2025.2)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from pgmpy<1.0->synthcity) (3.2.3)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.11/dist-packages (from pgmpy<1.0->synthcity) (0.14.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from pgmpy<1.0->synthcity) (1.5.0)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (from pgmpy<1.0->synthcity) (0.8.5)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->synthcity) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->synthcity) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->synthcity) (4.13.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->synthcity) (0.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.2->synthcity) (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<2.3,>=2.1->synthcity) (3.18.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch<2.3,>=2.1->synthcity) (1.13.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<2.3,>=2.1->synthcity) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<2.3,>=2.1->synthcity) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch<2.3,>=2.1->synthcity)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch<2.3,>=2.1->synthcity)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch<2.3,>=2.1->synthcity)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch<2.3,>=2.1->synthcity)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch<2.3,>=2.1->synthcity)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch<2.3,>=2.1->synthcity)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch<2.3,>=2.1->synthcity)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch<2.3,>=2.1->synthcity)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch<2.3,>=2.1->synthcity)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch<2.3,>=2.1->synthcity)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch<2.3,>=2.1->synthcity)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.2.0 (from torch<2.3,>=2.1->synthcity)\n",
            "  Downloading triton-2.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<2.3,>=2.1->synthcity) (12.5.82)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->synthcity) (3.21.0)\n",
            "Collecting torchtuples>=0.2.0 (from pycox->synthcity)\n",
            "  Downloading torchtuples-0.2.2-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting feather-format>=0.4.0 (from pycox->synthcity)\n",
            "  Downloading feather-format-0.4.1.tar.gz (3.2 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from pycox->synthcity) (3.13.0)\n",
            "Requirement already satisfied: numba>=0.44 in /usr/local/lib/python3.11/dist-packages (from pycox->synthcity) (0.60.0)\n",
            "Collecting py7zr>=0.11.3 (from pycox->synthcity)\n",
            "  Downloading py7zr-0.22.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting pybind11 (from pykeops->synthcity)\n",
            "  Downloading pybind11-2.13.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Collecting keopscore==2.3 (from pykeops->synthcity)\n",
            "  Downloading keopscore-2.3.tar.gz (118 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.5/118.5 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: slicer==0.0.8 in /usr/local/lib/python3.11/dist-packages (from shap->synthcity) (0.0.8)\n",
            "Collecting pyts>=0.13.0 (from tsai->synthcity)\n",
            "  Downloading pyts-0.13.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: imbalanced-learn>=0.12.4 in /usr/local/lib/python3.11/dist-packages (from tsai->synthcity) (0.13.0)\n",
            "Collecting psutil>=6.1.0 (from tsai->synthcity)\n",
            "  Downloading psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.20.1->be-great>=0.0.5->synthcity) (0.31.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.20.1->be-great>=0.0.5->synthcity) (0.5.3)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna>=3.1->synthcity) (1.1.3)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.5.2->be-great>=0.0.5->synthcity) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.5.2->be-great>=0.0.5->synthcity) (0.3.7)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets>=2.5.2->be-great>=0.0.5->synthcity) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets>=2.5.2->be-great>=0.0.5->synthcity) (0.70.15)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.5.2->be-great>=0.0.5->synthcity) (3.11.15)\n",
            "Collecting interface-meta>=1.2.0 (from formulaic>=0.2.2->lifelines<0.30.0,>=0.29.0->synthcity)\n",
            "  Downloading interface_meta-1.3.0-py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: wrapt>=1.0 in /usr/local/lib/python3.11/dist-packages (from formulaic>=0.2.2->lifelines<0.30.0,>=0.29.0->synthcity) (1.17.2)\n",
            "Requirement already satisfied: sklearn-compat<1,>=0.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn>=0.12.4->tsai->synthcity) (0.1.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->fastai<2.8->synthcity) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->fastai<2.8->synthcity) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->fastai<2.8->synthcity) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->fastai<2.8->synthcity) (1.4.8)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.44->pycox->synthcity) (0.43.0)\n",
            "Collecting texttable (from py7zr>=0.11.3->pycox->synthcity)\n",
            "  Downloading texttable-1.7.0-py2.py3-none-any.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: pycryptodomex>=3.16.0 in /usr/local/lib/python3.11/dist-packages (from py7zr>=0.11.3->pycox->synthcity) (3.22.0)\n",
            "Collecting pyzstd>=0.15.9 (from py7zr>=0.11.3->pycox->synthcity)\n",
            "  Downloading pyzstd-0.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
            "Collecting pyppmd<1.2.0,>=1.1.0 (from py7zr>=0.11.3->pycox->synthcity)\n",
            "  Downloading pyppmd-1.1.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
            "Collecting pybcj<1.1.0,>=1.0.0 (from py7zr>=0.11.3->pycox->synthcity)\n",
            "  Downloading pybcj-1.0.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.7 kB)\n",
            "Collecting multivolumefile>=0.2.3 (from py7zr>=0.11.3->pycox->synthcity)\n",
            "  Downloading multivolumefile-0.2.3-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting inflate64<1.1.0,>=1.0.0 (from py7zr>=0.11.3->pycox->synthcity)\n",
            "  Downloading inflate64-1.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Collecting brotli>=1.1.0 (from py7zr>=0.11.3->pycox->synthcity)\n",
            "  Downloading Brotli-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=2.1->synthcity) (1.17.0)\n",
            "Collecting torchmetrics>=0.7.0 (from pytorch-lightning<2.0->decaf-synthetic-data>=0.1.6->synthcity)\n",
            "  Downloading torchmetrics-1.7.1-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting lightning-utilities>=0.6.0.post0 (from pytorch-lightning<2.0->decaf-synthetic-data>=0.1.6->synthcity)\n",
            "  Downloading lightning_utilities-0.14.3-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->fastai<2.8->synthcity) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->fastai<2.8->synthcity) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->fastai<2.8->synthcity) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->fastai<2.8->synthcity) (2025.4.26)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai<2.8->synthcity) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai<2.8->synthcity) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai<2.8->synthcity) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai<2.8->synthcity) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai<2.8->synthcity) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai<2.8->synthcity) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai<2.8->synthcity) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai<2.8->synthcity) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai<2.8->synthcity) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai<2.8->synthcity) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai<2.8->synthcity) (0.15.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai<2.8->synthcity) (75.2.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai<2.8->synthcity) (3.5.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna>=3.1->synthcity) (3.2.2)\n",
            "INFO: pip is looking at multiple versions of torchtext to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torchtext>=0.10 (from decaf-synthetic-data>=0.1.6->synthcity)\n",
            "  Downloading torchtext-0.17.2-cp311-cp311-manylinux1_x86_64.whl.metadata (7.9 kB)\n",
            "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torchvision>=0.11 (from fastai<2.8->synthcity)\n",
            "  Downloading torchvision-0.22.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
            "  Downloading torchvision-0.21.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
            "  Downloading torchvision-0.20.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
            "  Downloading torchvision-0.20.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
            "  Downloading torchvision-0.19.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.0 kB)\n",
            "  Downloading torchvision-0.19.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.0 kB)\n",
            "  Downloading torchvision-0.18.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "INFO: pip is still looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading torchvision-0.18.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "  Downloading torchvision-0.17.2-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.22.1->be-great>=0.0.5->synthcity) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.22.1->be-great>=0.0.5->synthcity) (0.21.1)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai->pgmpy<1.0->synthcity) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai->pgmpy<1.0->synthcity) (2.24.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai->pgmpy<1.0->synthcity) (2.169.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai->pgmpy<1.0->synthcity) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai->pgmpy<1.0->synthcity) (5.29.4)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai->pgmpy<1.0->synthcity) (1.26.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<2.3,>=2.1->synthcity) (3.0.2)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.11/dist-packages (from statsmodels->pgmpy<1.0->synthcity) (1.0.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch<2.3,>=2.1->synthcity) (1.3.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard->nflows>=0.14->synthcity) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard->nflows>=0.14->synthcity) (1.71.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard->nflows>=0.14->synthcity) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->nflows>=0.14->synthcity) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard->nflows>=0.14->synthcity) (3.1.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.5.2->be-great>=0.0.5->synthcity) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.5.2->be-great>=0.0.5->synthcity) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.5.2->be-great>=0.0.5->synthcity) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.5.2->be-great>=0.0.5->synthcity) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.5.2->be-great>=0.0.5->synthcity) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.5.2->be-great>=0.0.5->synthcity) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.5.2->be-great>=0.0.5->synthcity) (1.20.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai->pgmpy<1.0->synthcity) (1.70.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai->pgmpy<1.0->synthcity) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai->pgmpy<1.0->synthcity) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai->pgmpy<1.0->synthcity) (4.9.1)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<4->fastai<2.8->synthcity) (1.3.0)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy<4->fastai<2.8->synthcity) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy<4->fastai<2.8->synthcity) (0.1.5)\n",
            "INFO: pip is looking at multiple versions of thinc to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting thinc<8.4.0,>=8.3.4 (from spacy<4->fastai<2.8->synthcity)\n",
            "  Downloading thinc-8.3.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\n",
            "Collecting blis<1.3.0,>=1.2.0 (from thinc<8.4.0,>=8.3.4->spacy<4->fastai<2.8->synthcity)\n",
            "  Downloading blis-1.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<4->fastai<2.8->synthcity) (8.2.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<4->fastai<2.8->synthcity) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<4->fastai<2.8->synthcity) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<4->fastai<2.8->synthcity) (0.21.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<4->fastai<2.8->synthcity) (7.1.0)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai->pgmpy<1.0->synthcity) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai->pgmpy<1.0->synthcity) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai->pgmpy<1.0->synthcity) (4.1.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai->pgmpy<1.0->synthcity) (1.71.0)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<4->fastai<2.8->synthcity) (1.2.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai->pgmpy<1.0->synthcity) (0.6.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4->fastai<2.8->synthcity) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4->fastai<2.8->synthcity) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4->fastai<2.8->synthcity) (0.1.2)\n",
            "Downloading synthcity-0.2.12-py3-none-any.whl (434 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.3/434.3 kB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tsbootstrap-0.1.5-py3-none-any.whl (104 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.4/104.4 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading be_great-0.0.9-py3-none-any.whl (19 kB)\n",
            "Downloading decaf_synthetic_data-0.1.6-py3-none-any.whl (9.1 kB)\n",
            "Downloading lifelines-0.29.0-py3-none-any.whl (349 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m349.3/349.3 kB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading networkx-2.8.8-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m72.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m98.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opacus-1.5.3-py3-none-any.whl (251 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.7/251.7 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading optuna-4.3.0-py3-none-any.whl (386 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.6/386.6 kB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading packaging-24.1-py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pgmpy-0.1.26-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m82.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scikit_base-0.10.1-py3-none-any.whl (136 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m136.1/136.1 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scikit_learn-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m111.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.2.2-cp311-cp311-manylinux1_x86_64.whl (755.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.6/755.6 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m99.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m84.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xgbse-0.3.3-py3-none-any.whl (35 kB)\n",
            "Downloading fflows-0.0.3-py3-none-any.whl (19 kB)\n",
            "Downloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading monai-1.4.0-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m73.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pycox-0.3.0-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading redis-6.1.0-py3-none-any.whl (273 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m273.8/273.8 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tsai-0.4.0-py3-none-any.whl (324 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m324.3/324.3 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.16.1-py3-none-any.whl (242 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading formulaic-1.1.1-py3-none-any.whl (115 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.7/115.7 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (277 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.0/278.0 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading py7zr-0.22.0-py3-none-any.whl (67 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.9/67.9 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_lightning-1.9.5-py3-none-any.whl (829 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m829.5/829.5 kB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyts-0.13.0-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m86.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchtext-0.17.2-cp311-cp311-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m76.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchtuples-0.2.2-py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.9/41.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.17.2-cp311-cp311-manylinux1_x86_64.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m110.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading pybind11-2.13.6-py3-none-any.whl (243 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.3/243.3 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Brotli-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m91.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading inflate64-1.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (96 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.2/96.2 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading interface_meta-1.3.0-py3-none-any.whl (14 kB)\n",
            "Downloading lightning_utilities-0.14.3-py3-none-any.whl (28 kB)\n",
            "Downloading multivolumefile-0.2.3-py3-none-any.whl (17 kB)\n",
            "Downloading pybcj-1.0.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyppmd-1.1.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.3/141.3 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyzstd-0.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (412 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m412.9/412.9 kB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading thinc-8.3.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchmetrics-1.7.1-py3-none-any.whl (961 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m961.5/961.5 kB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading texttable-1.7.0-py2.py3-none-any.whl (10 kB)\n",
            "Downloading blis-1.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.7/11.7 MB\u001b[0m \u001b[31m109.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: nflows, arfpy, geomloss, pykeops, keopscore, autograd-gamma, feather-format\n",
            "  Building wheel for nflows (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nflows: filename=nflows-0.14-py3-none-any.whl size=53654 sha256=1bb58fb73af13debd4a9dc12a2046033c136003f7bd64f4398636bfbf179830c\n",
            "  Stored in directory: /root/.cache/pip/wheels/11/9d/b5/5c88631a7bdb388738d147b6a28ba435ab969f25eff552f75a\n",
            "  Building wheel for arfpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for arfpy: filename=arfpy-0.1.1-py3-none-any.whl size=8664 sha256=01490d9cd2934917e55fad0cb5a3e19379ec8d006fe5991aed90b051b700f6ef\n",
            "  Stored in directory: /root/.cache/pip/wheels/9b/9a/2b/0414258a3b781854c07acca132cf155a7d93b69f23c3cd6826\n",
            "  Building wheel for geomloss (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for geomloss: filename=geomloss-0.2.6-py3-none-any.whl size=32247 sha256=bf5ca5533fa1fd35c51e963e4c8ac1baf07a0f4b1df19eb4e0f6ec63bc46b6ef\n",
            "  Stored in directory: /root/.cache/pip/wheels/f5/cf/07/9d1d883feac2951b968fed8ef676842dc90b9860ea49a4dcac\n",
            "  Building wheel for pykeops (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pykeops: filename=pykeops-2.3-py3-none-any.whl size=120491 sha256=3490834ad81207529691119e453341383da2fb899e6775f4823b792f4e4a4586\n",
            "  Stored in directory: /root/.cache/pip/wheels/a8/91/ea/d9e54997a840e38595b9a2c5b9021f3969173edbda2fc99686\n",
            "  Building wheel for keopscore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keopscore: filename=keopscore-2.3-py3-none-any.whl size=185897 sha256=a266e841dd765ddff6b12541756831b4c398857491a3798240c5456fce1f710f\n",
            "  Stored in directory: /root/.cache/pip/wheels/32/77/92/17707f162cb65cfa8e97f0360cdb30681038f7762cf929b1b4\n",
            "  Building wheel for autograd-gamma (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for autograd-gamma: filename=autograd_gamma-0.5.0-py3-none-any.whl size=4030 sha256=5c414a50f6cba79d9c70d5bfa921dbf1e26143e7c696857bde871c5c9c202acd\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/67/f4/2caaae2146198dcb824f31a303833b07b14a5ec863fb3acd7b\n",
            "  Building wheel for feather-format (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for feather-format: filename=feather_format-0.4.1-py3-none-any.whl size=2434 sha256=293a31913b80e864490ae7ba85dcac3faecc9515ac0e6ed4ea3827b4119aa590\n",
            "  Stored in directory: /root/.cache/pip/wheels/77/5b/0e/0e63d10b6353208a085a321ea2eed2578f220a77bb8a4bd7ab\n",
            "Successfully built nflows arfpy geomloss pykeops keopscore autograd-gamma feather-format\n",
            "Installing collected packages: texttable, brotli, triton, scikit-base, redis, pyzstd, pyppmd, pybind11, pybcj, psutil, packaging, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, multivolumefile, loguru, keopscore, interface-meta, inflate64, feather-format, colorlog, scipy, pykeops, py7zr, nvidia-cusolver-cu12, nvidia-cudnn-cu12, lightning-utilities, blis, alembic, torch, scikit-learn, optuna, formulaic, autograd-gamma, tsbootstrap, torchvision, torchtuples, torchtext, torchmetrics, thinc, pyts, opacus, nflows, monai, lifelines, geomloss, fflows, arfpy, xgbse, pytorch-lightning, pycox, be-great, decaf-synthetic-data, tsai, pgmpy, synthcity\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 5.9.5\n",
            "    Uninstalling psutil-5.9.5:\n",
            "      Successfully uninstalled psutil-5.9.5\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.2\n",
            "    Uninstalling packaging-24.2:\n",
            "      Successfully uninstalled packaging-24.2\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.21.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.21.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.4.2\n",
            "    Uninstalling networkx-3.4.2:\n",
            "      Successfully uninstalled networkx-3.4.2\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.15.3\n",
            "    Uninstalling scipy-1.15.3:\n",
            "      Successfully uninstalled scipy-1.15.3\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: blis\n",
            "    Found existing installation: blis 1.3.0\n",
            "    Uninstalling blis-1.3.0:\n",
            "      Successfully uninstalled blis-1.3.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n",
            "      Successfully uninstalled torch-2.6.0+cu124\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.6.1\n",
            "    Uninstalling scikit-learn-1.6.1:\n",
            "      Successfully uninstalled scikit-learn-1.6.1\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.21.0+cu124\n",
            "    Uninstalling torchvision-0.21.0+cu124:\n",
            "      Successfully uninstalled torchvision-0.21.0+cu124\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 8.3.6\n",
            "    Uninstalling thinc-8.3.6:\n",
            "      Successfully uninstalled thinc-8.3.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "nx-cugraph-cu12 25.2.0 requires networkx>=3.2, but you have networkx 2.8.8 which is incompatible.\n",
            "google-cloud-bigquery 3.32.0 requires packaging>=24.2.0, but you have packaging 24.1 which is incompatible.\n",
            "scikit-image 0.25.2 requires networkx>=3.0, but you have networkx 2.8.8 which is incompatible.\n",
            "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.2.2 which is incompatible.\n",
            "tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.13.1 which is incompatible.\n",
            "db-dtypes 1.4.3 requires packaging>=24.2.0, but you have packaging 24.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed alembic-1.16.1 arfpy-0.1.1 autograd-gamma-0.5.0 be-great-0.0.9 blis-1.2.1 brotli-1.1.0 colorlog-6.9.0 decaf-synthetic-data-0.1.6 feather-format-0.4.1 fflows-0.0.3 formulaic-1.1.1 geomloss-0.2.6 inflate64-1.0.1 interface-meta-1.3.0 keopscore-2.3 lifelines-0.29.0 lightning-utilities-0.14.3 loguru-0.7.3 monai-1.4.0 multivolumefile-0.2.3 networkx-2.8.8 nflows-0.14 numpy-1.26.4 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvtx-cu12-12.1.105 opacus-1.5.3 optuna-4.3.0 packaging-24.1 pgmpy-0.1.26 psutil-7.0.0 py7zr-0.22.0 pybcj-1.0.6 pybind11-2.13.6 pycox-0.3.0 pykeops-2.3 pyppmd-1.1.1 pytorch-lightning-1.9.5 pyts-0.13.0 pyzstd-0.17.0 redis-6.1.0 scikit-base-0.10.1 scikit-learn-1.5.2 scipy-1.13.1 synthcity-0.2.12 texttable-1.7.0 thinc-8.3.4 torch-2.2.2 torchmetrics-1.7.1 torchtext-0.17.2 torchtuples-0.2.2 torchvision-0.17.2 triton-2.2.0 tsai-0.4.0 tsbootstrap-0.1.5 xgbse-0.3.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "psutil"
                ]
              },
              "id": "8f2ec63155c74999ae15c3ba132a85f9"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install synthcity tsbootstrap"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "NcwQ6Yo09JC8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import sys\n",
        "import warnings\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "import synthcity.logger as log\n",
        "from synthcity.plugins import Plugins\n",
        "from synthcity.plugins.core.dataloader import TimeSeriesDataLoader\n",
        "from synthcity.utils.serialization import save_to_file, load_from_file\n",
        "\n",
        "log.add(sink=sys.stderr, level=\"INFO\")"
      ],
      "metadata": {
        "id": "kfDi7FQF9LIv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "279fbba9-d914-476a-f804-d3a56dc76d2a",
        "collapsed": true
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "[KeOps] Warning : CUDA libraries not found or could not be loaded; Switching to CPU only.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/drive/Shareddrives/sp_env/datasets/Exchange Rate/exchange_rate.txt\"\n",
        "\n",
        "df = pd.read_csv(file_path)\n",
        "print(df.head())\n",
        "print(df.info())\n",
        "print('missing values:', df.isnull().sum())"
      ],
      "metadata": {
        "id": "DCLsmN-F9NGv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec74edf9-37f4-4edb-e542-5fb003549b10"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   0.785500  1.611000  0.861698  0.634196  0.211242  0.006838  0.593000  \\\n",
            "0    0.7818    1.6100  0.861104  0.633513  0.211242  0.006863    0.5940   \n",
            "1    0.7867    1.6293  0.861030  0.648508  0.211242  0.006975    0.5973   \n",
            "2    0.7860    1.6370  0.862069  0.650618  0.211242  0.006953    0.5970   \n",
            "3    0.7849    1.6530  0.861995  0.656254  0.211242  0.006940    0.5985   \n",
            "4    0.7866    1.6537  0.861030  0.654879  0.211242  0.006887    0.6040   \n",
            "\n",
            "   0.525486  \n",
            "0  0.523972  \n",
            "1  0.526316  \n",
            "2  0.523834  \n",
            "3  0.527426  \n",
            "4  0.526177  \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 7587 entries, 0 to 7586\n",
            "Data columns (total 8 columns):\n",
            " #   Column    Non-Null Count  Dtype  \n",
            "---  ------    --------------  -----  \n",
            " 0   0.785500  7587 non-null   float64\n",
            " 1   1.611000  7587 non-null   float64\n",
            " 2   0.861698  7587 non-null   float64\n",
            " 3   0.634196  7587 non-null   float64\n",
            " 4   0.211242  7587 non-null   float64\n",
            " 5   0.006838  7587 non-null   float64\n",
            " 6   0.593000  7587 non-null   float64\n",
            " 7   0.525486  7587 non-null   float64\n",
            "dtypes: float64(8)\n",
            "memory usage: 474.3 KB\n",
            "None\n",
            "missing values: 0.785500    0\n",
            "1.611000    0\n",
            "0.861698    0\n",
            "0.634196    0\n",
            "0.211242    0\n",
            "0.006838    0\n",
            "0.593000    0\n",
            "0.525486    0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for exchange dataset only\n",
        "df.columns = [\n",
        "    'Australia', 'British_Pound', 'Canada', 'Switzerland',\n",
        "    'China', 'Japan', 'New_Zealand', 'Singapore'\n",
        "]\n",
        "\n",
        "# set seed and randomly choose 2 features\n",
        "np.random.seed(42)\n",
        "\n",
        "# Filter the dataframe to only include selected features\n",
        "selected_features = np.random.choice(df.columns, size=2, replace=False)\n",
        "print(f\"Selected features: {selected_features}\")\n",
        "\n",
        "# Immediately filter your full DataFrame down to just those two series:\n",
        "df = df[selected_features]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5oUv4bBtKwyH",
        "outputId": "6f544108-c71f-4f75-b63c-9ec70c3d763d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected features: ['British_Pound' 'Japan']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Keep the latest 5000 rows\n",
        "df_latest = df.tail(5000)\n",
        "\n",
        "# Train-test split: 70% for training (for TimeGAN), 30% for testing (TSTR)\n",
        "train_size = int(0.7 * len(df_latest))\n",
        "df_train = df_latest.iloc[:train_size]\n",
        "df_test = df_latest.iloc[train_size:]  # use later for LSTM-TSTR\n",
        "\n",
        "# Normalize the data\n",
        "scaler = MinMaxScaler()\n",
        "scaled_train = scaler.fit_transform(df_train)\n",
        "df_scaled_train = pd.DataFrame(scaled_train, columns=df_train.columns, index=df_train.index)\n",
        "scaled_test = scaler.transform(df_test)\n",
        "df_scaled_test = pd.DataFrame(scaled_test, columns=df_test.columns, index=df_test.index)\n",
        "\n",
        "\n",
        "# set sequence length to 30 to capture monthly patterns\n",
        "# dataset = daily\n",
        "sequence_length = 30\n",
        "# temporal_data = []\n",
        "# observation_times = []\n",
        "\n",
        "# for start in range(len(df_scaled_train) - sequence_length + 1):\n",
        "#     sequence = df_scaled_train.iloc[start:start + sequence_length].reset_index(drop=True)\n",
        "#     temporal_data.append(sequence)\n",
        "#     observation_times.append(list(range(sequence_length)))  # relative time within the window\n",
        "\n",
        "\n",
        "# # Dummy outcome for data loader\n",
        "# dummy_outcome = pd.DataFrame(np.zeros(len(temporal_data)), columns=[\"outcome\"])\n",
        "\n",
        "# # --- Create DataLoader for TimeGAN ---\n",
        "# loader = TimeSeriesDataLoader(\n",
        "#     temporal_data=temporal_data,  # List of sequences (DataFrames)\n",
        "#     observation_times=observation_times,  # List of time indices (DataFrames)\n",
        "#     static_data=None,  # No static data for now (can be set if needed)\n",
        "#     outcome=dummy_outcome,  # Dummy outcome for forecasting\n",
        "# )\n",
        "\n",
        "# # Print the loader info\n",
        "# print(f\"TimeSeriesDataLoader created with {len(temporal_data)} sequences\")"
      ],
      "metadata": {
        "id": "siWRiBtn9O0V"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temporal_data_test = []\n",
        "observation_times_test = []\n",
        "\n",
        "# Generate sequences from df_scaled_test only\n",
        "for start in range(len(df_scaled_test) - sequence_length + 1):\n",
        "    sequence = df_scaled_test.iloc[start:start + sequence_length].reset_index(drop=True)\n",
        "    temporal_data_test.append(sequence)\n",
        "    observation_times_test.append(list(range(sequence_length)))  # relative time within the window\n",
        "\n",
        "# Dummy outcome for TimeGAN (can be used in DataLoader)\n",
        "dummy_outcome = pd.DataFrame(np.zeros(len(temporal_data_test)), columns=[\"outcome\"])\n",
        "\n",
        "# Create DataLoader for TimeGAN\n",
        "loader_test = TimeSeriesDataLoader(\n",
        "    temporal_data=temporal_data_test,\n",
        "    observation_times=observation_times_test,\n",
        "    static_data=None,\n",
        "    outcome=dummy_outcome,\n",
        ")\n",
        "\n",
        "# Print the loader info\n",
        "print(f\"TimeSeriesDataLoader TEST SET created with {len(temporal_data_test)} sequences\")"
      ],
      "metadata": {
        "id": "pL_ZceMaImFr",
        "outputId": "7553a80f-60de-4fb4-b3c1-87f61fb04496",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TimeSeriesDataLoader TEST SET created with 1471 sequences\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(df_train))  # Check the length of the dataframe\n",
        "print(loader.dataframe())"
      ],
      "metadata": {
        "id": "FmZe08FM9Rd0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbaf108b-2727-4446-ec6c-70626f9a76a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3500\n",
            "        seq_id  seq_time_id  seq_temporal_British_Pound  seq_temporal_Japan  \\\n",
            "0            0            0                    0.175634            0.327109   \n",
            "1            0            1                    0.177668            0.321058   \n",
            "2            0            2                    0.168709            0.315871   \n",
            "3            0            3                    0.163281            0.314661   \n",
            "4            0            4                    0.165788            0.318638   \n",
            "...        ...          ...                         ...                 ...   \n",
            "104125    3470           25                    0.325966            0.882434   \n",
            "104126    3470           26                    0.327503            0.875692   \n",
            "104127    3470           27                    0.313072            0.865318   \n",
            "104128    3470           28                    0.312271            0.866010   \n",
            "104129    3470           29                    0.305651            0.874308   \n",
            "\n",
            "        seq_out_outcome  \n",
            "0                   0.0  \n",
            "1                   0.0  \n",
            "2                   0.0  \n",
            "3                   0.0  \n",
            "4                   0.0  \n",
            "...                 ...  \n",
            "104125              0.0  \n",
            "104126              0.0  \n",
            "104127              0.0  \n",
            "104128              0.0  \n",
            "104129              0.0  \n",
            "\n",
            "[104130 rows x 5 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from synthcity.plugins import Plugins\n",
        "\n",
        "hparams = {\n",
        "          \"mode\": \"LSTM\",\n",
        "}\n",
        "\n",
        "# Load TimeGAN with custom parameters\n",
        "syn_model = Plugins().get(\"timegan\", **hparams)"
      ],
      "metadata": {
        "id": "oYqRdbxl9W74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d6785c2-e953-4cfd-bc8c-a2aeacfd2bf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2025-04-26T13:20:23.621941+0000][2010][CRITICAL] module disabled: /usr/local/lib/python3.11/dist-packages/synthcity/plugins/generic/plugin_goggle.py\n",
            "[2025-04-26T13:20:23.621941+0000][2010][CRITICAL] module disabled: /usr/local/lib/python3.11/dist-packages/synthcity/plugins/generic/plugin_goggle.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print all parameters of initialized model\n",
        "for attr in dir(syn_model):\n",
        "    if not attr.startswith(\"_\") and not callable(getattr(syn_model, attr)):\n",
        "        print(f\"{attr}: {getattr(syn_model, attr)}\")"
      ],
      "metadata": {
        "id": "y9ZVw8pT9Y_Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7706da83-221f-4767-a4cc-a2ea573812b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch_size: 64\n",
            "class_name: TimeGANPlugin\n",
            "clipping_value: 0\n",
            "compress_dataset: False\n",
            "dataloader_sampling_strategy: imbalanced_time_censoring\n",
            "device: cuda\n",
            "discriminator_batch_norm: False\n",
            "discriminator_dropout: 0.1\n",
            "discriminator_loss: None\n",
            "discriminator_lr: 0.001\n",
            "discriminator_n_iter: 1\n",
            "discriminator_n_layers_hidden: 3\n",
            "discriminator_n_units_hidden: 300\n",
            "discriminator_nonlin: leaky_relu\n",
            "discriminator_weight_decay: 0.001\n",
            "embedding_penalty: 10\n",
            "encoder: None\n",
            "encoder_max_clusters: 20\n",
            "expecting_conditional: False\n",
            "fitted: False\n",
            "gamma_penalty: 1\n",
            "generator_batch_norm: False\n",
            "generator_dropout: 0.01\n",
            "generator_loss: None\n",
            "generator_lr: 0.001\n",
            "generator_n_layers_hidden: 2\n",
            "generator_n_units_hidden: 150\n",
            "generator_nonlin: leaky_relu\n",
            "generator_nonlin_out_continuous: tanh\n",
            "generator_nonlin_out_discrete: softmax\n",
            "generator_residual: True\n",
            "generator_weight_decay: 0.001\n",
            "mode: LSTM\n",
            "module_name: synthcity.plugins.time_series.plugin_timegan\n",
            "module_relative_path: ../time_series/plugin_timegan.py\n",
            "moments_penalty: 100\n",
            "n_iter: 1000\n",
            "n_iter_print: 10\n",
            "outcome_encoder: TabularEncoder(cat_encoder_params={'handle_unknown': 'ignore',\n",
            "                                   'sparse_output': False},\n",
            "               categorical_encoder='onehot',\n",
            "               cont_encoder_params={'n_components': 20},\n",
            "               continuous_encoder='bayesian_gmm', max_clusters=20)\n",
            "random_state: 0\n",
            "sampling_patience: 500\n",
            "sampling_strategy: marginal\n",
            "strict: True\n",
            "use_horizon_condition: True\n",
            "workspace: workspace\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## fitting the model"
      ],
      "metadata": {
        "id": "IKG0O5Pg9hpG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(loader.shape)\n",
        "\n",
        "# --- Train the model ---\n",
        "syn_model.fit(loader)"
      ],
      "metadata": {
        "id": "-BKXe4G19l_8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "565f33d2-0363-4e8e-d990-09369ddf9aff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(104130, 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [1:56:52<00:00,  7.01s/it]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<synthcity.plugins.time_series.plugin_timegan.TimeGANPlugin at 0x7c2c901b33d0>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title optional: generate data from saved model\n",
        "from synthcity.utils.serialization import save_to_file, load_from_file\n",
        "\n",
        "# Save model to drive\n",
        "save_to_file('/content/drive/Shareddrives/sp_env/saved_models/GAN_Exchange.pkl', syn_model)\n",
        "\n",
        "# Load the model\n",
        "# syn_model = load_from_file('/content/drive/Shareddrives/sp_env/synmodel.pkl')"
      ],
      "metadata": {
        "id": "Fbk3BDCNVJAZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Generate Synthetic Data ---\n",
        "n_samples = len(temporal_data)\n",
        "syn_data = syn_model.generate(count=n_samples)\n",
        "print(syn_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMAgkbp3QnVz",
        "outputId": "d9e6bc6f-a14b-4adf-ecb9-09459c516749"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100017, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Save with automated format ---\n",
        "import datetime\n",
        "import os\n",
        "# Get the current date and time\n",
        "now = datetime.datetime.now()\n",
        "timestamp = now.strftime(\"%m%d%y-%H%M%S\")  # MMDDYY-HHMMSS format\n",
        "\n",
        "# Define the base directory\n",
        "base_dir = \"/content/drive/Shareddrives/sp_env/synthetic_datasets/TimeGAN/exchange\"  #CHANGE THIS\n",
        "if not os.path.exists(base_dir):\n",
        "    os.makedirs(base_dir)\n",
        "\n",
        "# Construct the filename\n",
        "model_name = type(syn_model).__name__.lower() # Get model name dynamically\n",
        "filename = f\"{timestamp}-{model_name}-3500.csv\"\n",
        "filepath = os.path.join(base_dir, filename)\n",
        "\n",
        "# Save the data\n",
        "df_syn = syn_data.dataframe()\n",
        "df_syn.to_csv(filepath, index=False)\n",
        "\n",
        "print(f\"Synthetic data saved to: {filepath}\")"
      ],
      "metadata": {
        "id": "J4rF0HY29o65",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e286bbe9-8440-4c9d-8579-e10924ecd843"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synthetic data saved to: /content/drive/Shareddrives/sp_env/synthetic_datasets/TimeGAN/exchange/042625-152949-timeganplugin-3500.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "TICnBaoH9r8Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prerequisites"
      ],
      "metadata": {
        "id": "QlHAzxfV9uXf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "syn_data = pd.read_csv('/content/drive/Shareddrives/sp_env/synthetic_datasets/TimeGAN/exchange/042625-152949-timeganplugin-3500.csv')"
      ],
      "metadata": {
        "id": "nsU_9iZBI2ro"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define selected columns explicitly\n",
        "# selected_columns = ['seq_temporal_HUFL', 'seq_temporal_HULL', 'seq_temporal_LUFL', 'seq_temporal_LULL', 'seq_temporal_MUFL', 'seq_temporal_MULL', 'seq_temporal_OT']\n",
        "selected_columns = ['seq_temporal_British_Pound','seq_temporal_Japan']\n",
        "# Ensure real_data and synthetic_data only contain the selected columns\n",
        "real_data = loader_test.dataframe()[selected_columns].to_numpy()\n",
        "synthetic_data = syn_data[selected_columns].to_numpy()"
      ],
      "metadata": {
        "id": "zUMHadsq9vw8"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(real_data, \"\\n ------------------------------------------------------- \\n\", synthetic_data)\n",
        "print(type(real_data),type(synthetic_data))\n",
        "print(real_data.shape,synthetic_data.shape)"
      ],
      "metadata": {
        "id": "DumXr_Gg9y6U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "926065ef-5a6d-4b37-a301-07b3e44949c2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.30750644  0.87102351]\n",
            " [ 0.3059454   0.88191563]\n",
            " [ 0.3059454   0.88520055]\n",
            " ...\n",
            " [-0.18759935  0.197787  ]\n",
            " [-0.18787898  0.19657676]\n",
            " [-0.18787898  0.19657676]] \n",
            " ------------------------------------------------------- \n",
            " [[0.25763111 0.18547966]\n",
            " [0.0866552  0.18546773]\n",
            " [0.08670829 0.18559386]\n",
            " ...\n",
            " [0.31743031 0.1863488 ]\n",
            " [0.25738601 0.18644113]\n",
            " [0.61835132 0.18653295]]\n",
            "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
            "(44130, 2) (100017, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate distance metrics"
      ],
      "metadata": {
        "id": "0pU8BORS9vWk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Helper Functions"
      ],
      "metadata": {
        "id": "DVguOJWi-Fos"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import wasserstein_distance, entropy\n",
        "import numpy as np\n",
        "\n",
        "def compute_wasserstein(real_data, synthetic_data, selected_columns):\n",
        "    \"\"\"\n",
        "    Computes Wasserstein Distance between real and synthetic time-series data.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # Ensure both datasets have the same number of samples\n",
        "    min_length = min(len(real_data), len(synthetic_data))\n",
        "    real_trimmed = real_data[:min_length]  # Keep original order (no random sampling)\n",
        "    synthetic_trimmed = synthetic_data[:min_length]  # Match size\n",
        "    print(real_trimmed.shape,synthetic_trimmed.shape)\n",
        "\n",
        "    wasserstein_results = {}\n",
        "\n",
        "    # Compute Wasserstein Distance for each feature\n",
        "    for i, col in enumerate(selected_columns):\n",
        "        w_dist = wasserstein_distance(real_trimmed[:, i], synthetic_trimmed[:, i])\n",
        "        wasserstein_results[col] = w_dist\n",
        "        print(f\"{w_dist}\")\n",
        "\n",
        "    return wasserstein_results\n",
        "\n",
        "def compute_kl_divergence(real_data, synthetic_data, selected_columns, bins=50):\n",
        "    \"\"\"\n",
        "    Computes KL Divergence between real and synthetic time-series data.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # Ensure both datasets have the same number of samples\n",
        "    min_length = min(len(real_data), len(synthetic_data))\n",
        "    real_trimmed = real_data[:min_length]  # Keep original order\n",
        "    synthetic_trimmed = synthetic_data[:min_length]  # Match size\n",
        "\n",
        "    kl_results = {}\n",
        "\n",
        "    for i, col in enumerate(selected_columns):\n",
        "        # Compute histogram-based probability distributions\n",
        "        real_hist, _ = np.histogram(real_trimmed[:, i], bins=bins, density=True)\n",
        "        synth_hist, _ = np.histogram(synthetic_trimmed[:, i], bins=bins, density=True)\n",
        "\n",
        "        # Avoid zero probabilities (KL Divergence is undefined for zero values)\n",
        "        real_hist += 1e-10\n",
        "        synth_hist += 1e-10\n",
        "\n",
        "        # Compute KL Divergence\n",
        "        kl_div = entropy(real_hist, synth_hist)\n",
        "        kl_results[col] = kl_div\n",
        "        print(f\"{kl_div}\")\n",
        "\n",
        "    return kl_results"
      ],
      "metadata": {
        "id": "krpvQN9Ac8jL"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate Metrics"
      ],
      "metadata": {
        "id": "yLnb7Vqg-IG_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming df_scaled is the DataFrame containing your scaled ETD data\n",
        "\n",
        "# Compute Wasserstein Distance\n",
        "wasserstein_results = compute_wasserstein(real_data, synthetic_data, selected_columns)\n",
        "print(\"Wasserstein Distance Results:\")\n",
        "print(wasserstein_results)\n",
        "\n",
        "# Compute KL Divergence\n",
        "kl_results = compute_kl_divergence(real_data, synthetic_data, selected_columns)\n",
        "print(\"KL Divergence Results:\")\n",
        "print(kl_results)"
      ],
      "metadata": {
        "id": "olm0RYP89-SN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "991a538f-4e2b-473c-eafc-02b7a2643f14"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(44130, 2) (44130, 2)\n",
            "0.08117466787512753\n",
            "0.15334526304995016\n",
            "Wasserstein Distance Results:\n",
            "{'seq_temporal_British_Pound': 0.08117466787512753, 'seq_temporal_Japan': 0.15334526304995016}\n",
            "17.43605457568381\n",
            "17.20093945765117\n",
            "KL Divergence Results:\n",
            "{'seq_temporal_British_Pound': 17.43605457568381, 'seq_temporal_Japan': 17.20093945765117}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM downstream"
      ],
      "metadata": {
        "id": "UpJLIRUZChiz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "real_data = loader_test.dataframe()\n",
        "df_synth = pd.read_csv(\"/content/drive/Shareddrives/sp_env/synthetic_datasets/TimeGAN/exchange/042625-152949-timeganplugin-3500.csv\")\n",
        "\n",
        "# drop unwanted column\n",
        "real_data = real_data.drop(columns=[\"seq_id\", \"seq_time_id\", \"seq_out_outcome\"], errors=\"ignore\")\n",
        "df_synth = df_synth.drop(columns=[\"seq_id\", \"seq_time_id\", \"seq_out_outcome\"], errors=\"ignore\")\n",
        "\n",
        "print(f\"real_data: {real_data.shape}, synthetic_data: {df_synth.shape}\")"
      ],
      "metadata": {
        "id": "G_02CkO3ZlPY",
        "outputId": "d3190ad1-c0f7-49be-d443-3bb5a319a93e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "real_data: (3500, 2), synthetic_data: (100017, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "real_data = loader_test.dataframe()\n",
        "df_synth = syn_data\n",
        "\n",
        "# 2. Drop the unwanted column\n",
        "real_data = real_data.drop(columns=[\"seq_id\", \"seq_time_id\", \"seq_out_outcome\"], errors=\"ignore\")\n",
        "df_synth = df_synth.drop(columns=[\"seq_id\", \"seq_time_id\", \"seq_out_outcome\"], errors=\"ignore\")"
      ],
      "metadata": {
        "id": "l04RaNc9KcoC"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error"
      ],
      "metadata": {
        "id": "W5iE43OTZ7La"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to tensors (float32 for PyTorch)\n",
        "data_real = torch.tensor(real_data.values, dtype=torch.float32)\n",
        "data_synth = torch.tensor(df_synth.values, dtype=torch.float32)\n",
        "\n",
        "#  Sequence builder\n",
        "def make_sequences(data, seq_len):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - seq_len):\n",
        "        X.append(data[i:i+seq_len])\n",
        "        y.append(data[i+seq_len])\n",
        "    return torch.stack(X), torch.stack(y)\n",
        "\n",
        "SEQ_LEN = sequence_length\n",
        "\n",
        "# Sequences for synthetic (train)\n",
        "X_train, y_train = make_sequences(data_synth, SEQ_LEN)\n",
        "train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=32, shuffle=True)\n",
        "\n",
        "# Sequences for real (test)\n",
        "X_test, y_test = make_sequences(data_real, SEQ_LEN)"
      ],
      "metadata": {
        "id": "411oyQeWZ_YK"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ─── Model Definition ──────────────────────────────────────\n",
        "class ShallowLSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size=64):\n",
        "        super().__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
        "        self.linear = nn.Linear(hidden_size, input_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        _, (hn, _) = self.lstm(x)  # hn shape: (1, batch, hidden_size)\n",
        "        out = self.linear(hn.squeeze(0))  # squeeze to (batch, hidden_size)\n",
        "        return out\n",
        "\n",
        "\n",
        "# ─── Model Init ─────────────────────────────────────────────\n",
        "model = ShallowLSTM(input_size=X_train.shape[2], hidden_size=64)\n",
        "\n",
        "# ─── Optimizer & Loss ───────────────────────────────────────\n",
        "loss_fn = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.002)"
      ],
      "metadata": {
        "id": "cfzvaAMyaCuG"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ─── Training ───────────────────────────────────────────────\n",
        "EPOCHS = 50\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    model.train()\n",
        "    for xb, yb in train_loader:\n",
        "        pred = model(xb)\n",
        "        loss = loss_fn(pred, yb)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # if epoch % 10 == 0 or epoch == 1:\n",
        "    print(f\"Epoch {epoch}: Train MSE = {loss.item():.6f}\")"
      ],
      "metadata": {
        "id": "RbFgsjHfKs5z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ✧.* model evaluation ✧.*\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    preds = model(X_test)\n",
        "    test_mse = loss_fn(preds, y_test).item()\n",
        "    test_mae = mean_absolute_error(y_test.numpy(), preds.numpy())\n",
        "\n",
        "    print(f\"Test MSE: {test_mse:.6f}\")\n",
        "    print(f\"Test MAE: {test_mae:.6f}\")"
      ],
      "metadata": {
        "id": "KY5QbSyQaFhg",
        "outputId": "a8963008-83f8-4f3f-ad81-e586b1840725",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test MSE: 0.103023\n",
            "Test MAE: 0.235100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bootstrapping"
      ],
      "metadata": {
        "id": "uOUnAejOIulC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tsbootstrap import MovingBlockBootstrap\n",
        "import numpy as np\n",
        "\n",
        "bootstrap_configs = {\n",
        "    \"weather\": {\"block_length\": 36, \"n_bootstraps\": 15, \"rng\": 42},       # 6-hour pattern (10-min interval)\n",
        "    \"electricity\": {\"block_length\": 24, \"n_bootstraps\": 15, \"rng\": 42},   # 1-day pattern (hourly)\n",
        "    \"exchange\": {\"block_length\": 30, \"n_bootstraps\": 15, \"rng\": 42},      # 1-month pattern (daily)\n",
        "}\n",
        "\n",
        "# Example for weather\n",
        "dataset_name = \"exchange\"\n",
        "config = bootstrap_configs[dataset_name]\n",
        "\n",
        "real_test_array = real_data[selected_columns].to_numpy()  # shape (N, features)\n",
        "mbb = MovingBlockBootstrap(\n",
        "    n_bootstraps=config[\"n_bootstraps\"],\n",
        "    rng=config[\"rng\"],\n",
        "    block_length=config[\"block_length\"]\n",
        ")\n",
        "boot_samples = mbb.bootstrap(real_test_array, return_indices=False)"
      ],
      "metadata": {
        "id": "yFNCdlAkKwCs"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bootstrap_results = []\n",
        "\n",
        "for b_idx, boot_real in enumerate(boot_samples):\n",
        "    # 1. Match the synthetic data size\n",
        "    syn_trimmed = synthetic_data[:len(boot_real)]\n",
        "\n",
        "    # 2. Fidelity metrics\n",
        "    wasserstein = compute_wasserstein(boot_real, syn_trimmed, selected_columns)\n",
        "    kl = compute_kl_divergence(boot_real, syn_trimmed, selected_columns)\n",
        "\n",
        "    # 3. Utility metrics\n",
        "    # Preprocess this bootstrap sample for LSTM (as you do with real_data)\n",
        "    boot_tensor = torch.tensor(boot_real, dtype=torch.float32)\n",
        "    Xb_test, yb_test = make_sequences(boot_tensor, SEQ_LEN)\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        preds = model(Xb_test)\n",
        "        mse = mean_squared_error(yb_test.numpy(), preds.numpy())\n",
        "        rmse = np.sqrt(mse)\n",
        "        mae = mean_absolute_error(yb_test.numpy(), preds.numpy())\n",
        "\n",
        "    # 4. Store results\n",
        "    bootstrap_results.append({\n",
        "        'bootstrap': b_idx,\n",
        "        'wasserstein': np.mean(list(wasserstein.values())),\n",
        "        'kl': np.mean(list(kl.values())),\n",
        "        'rmse': rmse,\n",
        "        'mae': mae\n",
        "    })"
      ],
      "metadata": {
        "id": "YvkxLCtXKyuI",
        "outputId": "4a379e78-2d8e-4576-d0fc-7d5e6573cbbb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(44130, 2) (44130, 2)\n",
            "0.0830805148889528\n",
            "0.1536210888468385\n",
            "17.22113952016976\n",
            "17.17537103841086\n",
            "(44130, 2) (44130, 2)\n",
            "0.08140693101833461\n",
            "0.151777377023289\n",
            "17.570698564722292\n",
            "17.093488783171985\n",
            "(44130, 2) (44130, 2)\n",
            "0.07904870100812919\n",
            "0.15336695594370459\n",
            "17.404968717813574\n",
            "17.111706387512072\n",
            "(44130, 2) (44130, 2)\n",
            "0.07371995443513063\n",
            "0.1550851659946605\n",
            "17.604149779229555\n",
            "17.497905603480316\n",
            "(44130, 2) (44130, 2)\n",
            "0.0783790714929946\n",
            "0.1528026503834652\n",
            "17.55428492841301\n",
            "17.18087286787068\n",
            "(44130, 2) (44130, 2)\n",
            "0.08656598937119925\n",
            "0.15277463234966976\n",
            "17.150676311522567\n",
            "17.387680415791646\n",
            "(44130, 2) (44130, 2)\n",
            "0.07948165084286721\n",
            "0.1551900434558216\n",
            "17.464554902022062\n",
            "17.39558241925526\n",
            "(44130, 2) (44130, 2)\n",
            "0.08018590411887444\n",
            "0.14861175137008495\n",
            "17.500306343573524\n",
            "17.070677191868725\n",
            "(44130, 2) (44130, 2)\n",
            "0.07661886504049417\n",
            "0.15364064790638426\n",
            "17.540829620098332\n",
            "17.46420603818756\n",
            "(44130, 2) (44130, 2)\n",
            "0.08574885338852964\n",
            "0.14794079273658156\n",
            "17.18785140096761\n",
            "17.136194500628374\n",
            "(44130, 2) (44130, 2)\n",
            "0.08520386206932949\n",
            "0.1577888993107748\n",
            "17.072698051273328\n",
            "16.9007159655047\n",
            "(44130, 2) (44130, 2)\n",
            "0.0846597213792495\n",
            "0.1525407815739534\n",
            "17.493688566094097\n",
            "16.98911893772111\n",
            "(44130, 2) (44130, 2)\n",
            "0.08158050285044398\n",
            "0.15094772501478002\n",
            "17.412552923570125\n",
            "17.426410256960057\n",
            "(44130, 2) (44130, 2)\n",
            "0.0858660222415572\n",
            "0.15443959137748062\n",
            "17.261941543740367\n",
            "17.29748843055387\n",
            "(44130, 2) (44130, 2)\n",
            "0.08678566162899905\n",
            "0.14833999052140776\n",
            "17.543700213104408\n",
            "16.758841075500385\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(bootstrap_results)\n",
        "\n",
        "# Assuming bootstrap_results is your list of dicts\n",
        "df_results = pd.DataFrame(bootstrap_results)\n",
        "\n",
        "df_results['Dataset'] = 'Ex'\n",
        "df_results['Model'] = 'GAN'\n",
        "\n",
        "df_results"
      ],
      "metadata": {
        "id": "zmPVy3AVK1xA",
        "outputId": "50fd9fb4-2c68-42ee-d9b6-85f48eb705cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'bootstrap': 0, 'wasserstein': 0.11835080186789565, 'kl': 17.198255279290308, 'rmse': 0.38150477, 'mae': 0.34895927}, {'bootstrap': 1, 'wasserstein': 0.1165921540208118, 'kl': 17.33209367394714, 'rmse': 0.38105005, 'mae': 0.3488917}, {'bootstrap': 2, 'wasserstein': 0.11620782847591689, 'kl': 17.258337552662823, 'rmse': 0.3816973, 'mae': 0.3492574}, {'bootstrap': 3, 'wasserstein': 0.11440256021489556, 'kl': 17.551027691354935, 'rmse': 0.38413608, 'mae': 0.35278928}, {'bootstrap': 4, 'wasserstein': 0.1155908609382299, 'kl': 17.367578898141844, 'rmse': 0.38333693, 'mae': 0.35128868}, {'bootstrap': 5, 'wasserstein': 0.1196703108604345, 'kl': 17.269178363657105, 'rmse': 0.3816743, 'mae': 0.3482936}, {'bootstrap': 6, 'wasserstein': 0.1173358471493444, 'kl': 17.43006866063866, 'rmse': 0.38431364, 'mae': 0.35078558}, {'bootstrap': 7, 'wasserstein': 0.1143988277444797, 'kl': 17.285491767721126, 'rmse': 0.37837842, 'mae': 0.347053}, {'bootstrap': 8, 'wasserstein': 0.11512975647343922, 'kl': 17.502517829142946, 'rmse': 0.38261274, 'mae': 0.3508019}, {'bootstrap': 9, 'wasserstein': 0.1168448230625556, 'kl': 17.16202295079799, 'rmse': 0.37668654, 'mae': 0.34411466}, {'bootstrap': 10, 'wasserstein': 0.12149638069005214, 'kl': 16.98670700838901, 'rmse': 0.3840061, 'mae': 0.3501566}, {'bootstrap': 11, 'wasserstein': 0.11860025147660144, 'kl': 17.241403751907605, 'rmse': 0.38081795, 'mae': 0.34725565}, {'bootstrap': 12, 'wasserstein': 0.11626411393261199, 'kl': 17.419481590265093, 'rmse': 0.38142624, 'mae': 0.34794736}, {'bootstrap': 13, 'wasserstein': 0.12015280680951891, 'kl': 17.279714987147116, 'rmse': 0.38146392, 'mae': 0.34758225}, {'bootstrap': 14, 'wasserstein': 0.11756282607520341, 'kl': 17.151270644302397, 'rmse': 0.3761826, 'mae': 0.34337842}]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    bootstrap  wasserstein         kl      rmse       mae Dataset Model\n",
              "0           0     0.118351  17.198255  0.381505  0.348959      Ex   GAN\n",
              "1           1     0.116592  17.332094  0.381050  0.348892      Ex   GAN\n",
              "2           2     0.116208  17.258338  0.381697  0.349257      Ex   GAN\n",
              "3           3     0.114403  17.551028  0.384136  0.352789      Ex   GAN\n",
              "4           4     0.115591  17.367579  0.383337  0.351289      Ex   GAN\n",
              "5           5     0.119670  17.269178  0.381674  0.348294      Ex   GAN\n",
              "6           6     0.117336  17.430069  0.384314  0.350786      Ex   GAN\n",
              "7           7     0.114399  17.285492  0.378378  0.347053      Ex   GAN\n",
              "8           8     0.115130  17.502518  0.382613  0.350802      Ex   GAN\n",
              "9           9     0.116845  17.162023  0.376687  0.344115      Ex   GAN\n",
              "10         10     0.121496  16.986707  0.384006  0.350157      Ex   GAN\n",
              "11         11     0.118600  17.241404  0.380818  0.347256      Ex   GAN\n",
              "12         12     0.116264  17.419482  0.381426  0.347947      Ex   GAN\n",
              "13         13     0.120153  17.279715  0.381464  0.347582      Ex   GAN\n",
              "14         14     0.117563  17.151271  0.376183  0.343378      Ex   GAN"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-286d40b5-f3ae-4814-a329-582a4c6fc880\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bootstrap</th>\n",
              "      <th>wasserstein</th>\n",
              "      <th>kl</th>\n",
              "      <th>rmse</th>\n",
              "      <th>mae</th>\n",
              "      <th>Dataset</th>\n",
              "      <th>Model</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.118351</td>\n",
              "      <td>17.198255</td>\n",
              "      <td>0.381505</td>\n",
              "      <td>0.348959</td>\n",
              "      <td>Ex</td>\n",
              "      <td>GAN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.116592</td>\n",
              "      <td>17.332094</td>\n",
              "      <td>0.381050</td>\n",
              "      <td>0.348892</td>\n",
              "      <td>Ex</td>\n",
              "      <td>GAN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.116208</td>\n",
              "      <td>17.258338</td>\n",
              "      <td>0.381697</td>\n",
              "      <td>0.349257</td>\n",
              "      <td>Ex</td>\n",
              "      <td>GAN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.114403</td>\n",
              "      <td>17.551028</td>\n",
              "      <td>0.384136</td>\n",
              "      <td>0.352789</td>\n",
              "      <td>Ex</td>\n",
              "      <td>GAN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.115591</td>\n",
              "      <td>17.367579</td>\n",
              "      <td>0.383337</td>\n",
              "      <td>0.351289</td>\n",
              "      <td>Ex</td>\n",
              "      <td>GAN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>0.119670</td>\n",
              "      <td>17.269178</td>\n",
              "      <td>0.381674</td>\n",
              "      <td>0.348294</td>\n",
              "      <td>Ex</td>\n",
              "      <td>GAN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>0.117336</td>\n",
              "      <td>17.430069</td>\n",
              "      <td>0.384314</td>\n",
              "      <td>0.350786</td>\n",
              "      <td>Ex</td>\n",
              "      <td>GAN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>0.114399</td>\n",
              "      <td>17.285492</td>\n",
              "      <td>0.378378</td>\n",
              "      <td>0.347053</td>\n",
              "      <td>Ex</td>\n",
              "      <td>GAN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>0.115130</td>\n",
              "      <td>17.502518</td>\n",
              "      <td>0.382613</td>\n",
              "      <td>0.350802</td>\n",
              "      <td>Ex</td>\n",
              "      <td>GAN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>0.116845</td>\n",
              "      <td>17.162023</td>\n",
              "      <td>0.376687</td>\n",
              "      <td>0.344115</td>\n",
              "      <td>Ex</td>\n",
              "      <td>GAN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>10</td>\n",
              "      <td>0.121496</td>\n",
              "      <td>16.986707</td>\n",
              "      <td>0.384006</td>\n",
              "      <td>0.350157</td>\n",
              "      <td>Ex</td>\n",
              "      <td>GAN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>11</td>\n",
              "      <td>0.118600</td>\n",
              "      <td>17.241404</td>\n",
              "      <td>0.380818</td>\n",
              "      <td>0.347256</td>\n",
              "      <td>Ex</td>\n",
              "      <td>GAN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>12</td>\n",
              "      <td>0.116264</td>\n",
              "      <td>17.419482</td>\n",
              "      <td>0.381426</td>\n",
              "      <td>0.347947</td>\n",
              "      <td>Ex</td>\n",
              "      <td>GAN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>13</td>\n",
              "      <td>0.120153</td>\n",
              "      <td>17.279715</td>\n",
              "      <td>0.381464</td>\n",
              "      <td>0.347582</td>\n",
              "      <td>Ex</td>\n",
              "      <td>GAN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>14</td>\n",
              "      <td>0.117563</td>\n",
              "      <td>17.151271</td>\n",
              "      <td>0.376183</td>\n",
              "      <td>0.343378</td>\n",
              "      <td>Ex</td>\n",
              "      <td>GAN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "      \n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-286d40b5-f3ae-4814-a329-582a4c6fc880')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "      \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-286d40b5-f3ae-4814-a329-582a4c6fc880 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-286d40b5-f3ae-4814-a329-582a4c6fc880');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "  \n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary_row = {\n",
        "    'Dataset': 'El',\n",
        "    'Model': 'GAN',\n",
        "    'Wasserstein': df_results['wasserstein'].mean(),\n",
        "    'KL': df_results['kl'].mean(),\n",
        "    'RMSE': df_results['rmse'].mean(),\n",
        "    'MAE': df_results['mae'].mean()\n",
        "}\n",
        "\n",
        "df_summary = pd.DataFrame([summary_row])\n",
        "print(df_summary)"
      ],
      "metadata": {
        "id": "APRipnSLK4F6",
        "outputId": "357d74ff-99b2-4257-e47f-2381c8aa5fde",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Dataset Model  Wasserstein         KL      RMSE      MAE\n",
            "0      El   GAN      0.11724  17.295677  0.381286  0.34857\n"
          ]
        }
      ]
    }
  ]
}