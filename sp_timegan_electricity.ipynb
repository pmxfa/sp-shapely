{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNuc5n56ZQ6sAS282UoXmyl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pmxfa/sp-shapely/blob/main/sp_timegan_electricity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oaMLghK_ipz1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "outputId": "978abd2d-dff7-4039-86d0-6635f7c7ba0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting synthcity\n",
            "  Downloading synthcity-0.2.11-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from synthcity) (8.6.1)\n",
            "Requirement already satisfied: pandas>=2.1 in /usr/local/lib/python3.11/dist-packages (from synthcity) (2.2.2)\n",
            "Collecting torch<2.3,>=2.1 (from synthcity)\n",
            "  Downloading torch-2.2.2-cp311-cp311-manylinux1_x86_64.whl.metadata (25 kB)\n",
            "Requirement already satisfied: scikit-learn>=1.2 in /usr/local/lib/python3.11/dist-packages (from synthcity) (1.6.1)\n",
            "Collecting nflows>=0.14 (from synthcity)\n",
            "  Downloading nflows-0.14.tar.gz (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.8/45.8 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting numpy<2.0,>=1.20 (from synthcity)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lifelines<0.30.0,>=0.29.0 (from synthcity)\n",
            "  Downloading lifelines-0.29.0-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting opacus>=1.3 (from synthcity)\n",
            "  Downloading opacus-1.5.3-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting networkx<3.0,>2.0 (from synthcity)\n",
            "  Downloading networkx-2.8.8-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting decaf-synthetic-data>=0.1.6 (from synthcity)\n",
            "  Downloading decaf_synthetic_data-0.1.6-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting optuna>=3.1 (from synthcity)\n",
            "  Downloading optuna-4.3.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: shap in /usr/local/lib/python3.11/dist-packages (from synthcity) (0.47.2)\n",
            "Requirement already satisfied: tenacity in /usr/local/lib/python3.11/dist-packages (from synthcity) (9.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from synthcity) (4.67.1)\n",
            "Collecting loguru (from synthcity)\n",
            "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting pydantic<2.0 (from synthcity)\n",
            "  Downloading pydantic-1.10.22-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.1/154.1 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from synthcity) (3.1.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from synthcity) (1.14.1)\n",
            "Requirement already satisfied: xgboost<3.0.0 in /usr/local/lib/python3.11/dist-packages (from synthcity) (2.1.4)\n",
            "Collecting geomloss (from synthcity)\n",
            "  Downloading geomloss-0.2.6.tar.gz (26 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pgmpy (from synthcity)\n",
            "  Downloading pgmpy-1.0.0-py3-none-any.whl.metadata (9.4 kB)\n",
            "Collecting redis (from synthcity)\n",
            "  Downloading redis-5.2.1-py3-none-any.whl.metadata (9.1 kB)\n",
            "Collecting pycox (from synthcity)\n",
            "  Downloading pycox-0.3.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting xgbse>=0.3.1 (from synthcity)\n",
            "  Downloading xgbse-0.3.3-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting pykeops (from synthcity)\n",
            "  Downloading pykeops-2.3.tar.gz (552 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m552.2/552.2 kB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting fflows (from synthcity)\n",
            "  Downloading fflows-0.0.3-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting monai (from synthcity)\n",
            "  Downloading monai-1.4.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting arfpy (from synthcity)\n",
            "  Downloading arfpy-0.1.1.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tsai (from synthcity)\n",
            "  Downloading tsai-0.4.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting be-great>=0.0.5 (from synthcity)\n",
            "  Downloading be_great-0.0.8-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting datasets>=2.5.2 (from be-great>=0.0.5->synthcity)\n",
            "  Downloading datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: transformers>=4.22.1 in /usr/local/lib/python3.11/dist-packages (from be-great>=0.0.5->synthcity) (4.51.3)\n",
            "Requirement already satisfied: accelerate>=0.20.1 in /usr/local/lib/python3.11/dist-packages (from be-great>=0.0.5->synthcity) (1.5.2)\n",
            "Collecting pytorch-lightning<2.0 (from decaf-synthetic-data>=0.1.6->synthcity)\n",
            "  Downloading pytorch_lightning-1.9.5-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting torchtext>=0.10 (from decaf-synthetic-data>=0.1.6->synthcity)\n",
            "  Downloading torchtext-0.18.0-cp311-cp311-manylinux1_x86_64.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: matplotlib>=3.0 in /usr/local/lib/python3.11/dist-packages (from lifelines<0.30.0,>=0.29.0->synthcity) (3.10.0)\n",
            "Requirement already satisfied: autograd>=1.5 in /usr/local/lib/python3.11/dist-packages (from lifelines<0.30.0,>=0.29.0->synthcity) (1.7.0)\n",
            "Collecting autograd-gamma>=0.3 (from lifelines<0.30.0,>=0.29.0->synthcity)\n",
            "  Downloading autograd-gamma-0.5.0.tar.gz (4.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting formulaic>=0.2.2 (from lifelines<0.30.0,>=0.29.0->synthcity)\n",
            "  Downloading formulaic-1.1.1-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (from nflows>=0.14->synthcity) (2.18.0)\n",
            "Requirement already satisfied: opt-einsum>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from opacus>=1.3->synthcity) (3.4.0)\n",
            "Collecting alembic>=1.5.0 (from optuna>=3.1->synthcity)\n",
            "  Downloading alembic-1.15.2-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting colorlog (from optuna>=3.1->synthcity)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna>=3.1->synthcity) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna>=3.1->synthcity) (2.0.40)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna>=3.1->synthcity) (6.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1->synthcity) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1->synthcity) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1->synthcity) (2025.2)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.0->synthcity) (4.13.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.2->synthcity) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.2->synthcity) (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<2.3,>=2.1->synthcity) (3.18.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch<2.3,>=2.1->synthcity) (1.13.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<2.3,>=2.1->synthcity) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<2.3,>=2.1->synthcity) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch<2.3,>=2.1->synthcity)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch<2.3,>=2.1->synthcity)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch<2.3,>=2.1->synthcity)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch<2.3,>=2.1->synthcity)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch<2.3,>=2.1->synthcity)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch<2.3,>=2.1->synthcity)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch<2.3,>=2.1->synthcity)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch<2.3,>=2.1->synthcity)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch<2.3,>=2.1->synthcity)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch<2.3,>=2.1->synthcity)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch<2.3,>=2.1->synthcity)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.2.0 (from torch<2.3,>=2.1->synthcity)\n",
            "  Downloading triton-2.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<2.3,>=2.1->synthcity) (12.5.82)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->synthcity) (3.21.0)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.11/dist-packages (from pgmpy->synthcity) (0.14.4)\n",
            "Collecting pyro-ppl (from pgmpy->synthcity)\n",
            "  Downloading pyro_ppl-1.9.1-py3-none-any.whl.metadata (7.8 kB)\n",
            "Collecting torchtuples>=0.2.0 (from pycox->synthcity)\n",
            "  Downloading torchtuples-0.2.2-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting feather-format>=0.4.0 (from pycox->synthcity)\n",
            "  Downloading feather-format-0.4.1.tar.gz (3.2 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from pycox->synthcity) (3.13.0)\n",
            "Requirement already satisfied: numba>=0.44 in /usr/local/lib/python3.11/dist-packages (from pycox->synthcity) (0.60.0)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.11/dist-packages (from pycox->synthcity) (2.32.3)\n",
            "Collecting py7zr>=0.11.3 (from pycox->synthcity)\n",
            "  Downloading py7zr-0.22.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting pybind11 (from pykeops->synthcity)\n",
            "  Downloading pybind11-2.13.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Collecting keopscore==2.3 (from pykeops->synthcity)\n",
            "  Downloading keopscore-2.3.tar.gz (118 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.5/118.5 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: slicer==0.0.8 in /usr/local/lib/python3.11/dist-packages (from shap->synthcity) (0.0.8)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (from tsai->synthcity) (24.1.2)\n",
            "Requirement already satisfied: fastai>=2.7.18 in /usr/local/lib/python3.11/dist-packages (from tsai->synthcity) (2.7.19)\n",
            "Collecting pyts>=0.13.0 (from tsai->synthcity)\n",
            "  Downloading pyts-0.13.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: imbalanced-learn>=0.12.4 in /usr/local/lib/python3.11/dist-packages (from tsai->synthcity) (0.13.0)\n",
            "Collecting psutil>=6.1.0 (from tsai->synthcity)\n",
            "  Downloading psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.20.1->be-great>=0.0.5->synthcity) (0.30.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.20.1->be-great>=0.0.5->synthcity) (0.5.3)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna>=3.1->synthcity) (1.1.3)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.5.2->be-great>=0.0.5->synthcity) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets>=2.5.2->be-great>=0.0.5->synthcity)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting xxhash (from datasets>=2.5.2->be-great>=0.0.5->synthcity)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets>=2.5.2->be-great>=0.0.5->synthcity)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec (from torch<2.3,>=2.1->synthcity)\n",
            "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.5.2->be-great>=0.0.5->synthcity) (3.11.15)\n",
            "Requirement already satisfied: fastdownload<2,>=0.0.5 in /usr/local/lib/python3.11/dist-packages (from fastai>=2.7.18->tsai->synthcity) (0.0.7)\n",
            "Requirement already satisfied: fastcore<1.8,>=1.5.29 in /usr/local/lib/python3.11/dist-packages (from fastai>=2.7.18->tsai->synthcity) (1.7.29)\n",
            "Requirement already satisfied: torchvision>=0.11 in /usr/local/lib/python3.11/dist-packages (from fastai>=2.7.18->tsai->synthcity) (0.21.0+cu124)\n",
            "Requirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.11/dist-packages (from fastai>=2.7.18->tsai->synthcity) (1.0.3)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from fastai>=2.7.18->tsai->synthcity) (11.1.0)\n",
            "Requirement already satisfied: spacy<4 in /usr/local/lib/python3.11/dist-packages (from fastai>=2.7.18->tsai->synthcity) (3.8.5)\n",
            "Collecting interface-meta>=1.2.0 (from formulaic>=0.2.2->lifelines<0.30.0,>=0.29.0->synthcity)\n",
            "  Downloading interface_meta-1.3.0-py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: wrapt>=1.0 in /usr/local/lib/python3.11/dist-packages (from formulaic>=0.2.2->lifelines<0.30.0,>=0.29.0->synthcity) (1.17.2)\n",
            "Requirement already satisfied: sklearn-compat<1,>=0.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn>=0.12.4->tsai->synthcity) (0.1.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines<0.30.0,>=0.29.0->synthcity) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines<0.30.0,>=0.29.0->synthcity) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines<0.30.0,>=0.29.0->synthcity) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines<0.30.0,>=0.29.0->synthcity) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines<0.30.0,>=0.29.0->synthcity) (3.2.3)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.44->pycox->synthcity) (0.43.0)\n",
            "Collecting texttable (from py7zr>=0.11.3->pycox->synthcity)\n",
            "  Downloading texttable-1.7.0-py2.py3-none-any.whl.metadata (9.8 kB)\n",
            "Collecting pycryptodomex>=3.16.0 (from py7zr>=0.11.3->pycox->synthcity)\n",
            "  Downloading pycryptodomex-3.22.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Collecting pyzstd>=0.15.9 (from py7zr>=0.11.3->pycox->synthcity)\n",
            "  Downloading pyzstd-0.16.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.4 kB)\n",
            "Collecting pyppmd<1.2.0,>=1.1.0 (from py7zr>=0.11.3->pycox->synthcity)\n",
            "  Downloading pyppmd-1.1.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
            "Collecting pybcj<1.1.0,>=1.0.0 (from py7zr>=0.11.3->pycox->synthcity)\n",
            "  Downloading pybcj-1.0.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
            "Collecting multivolumefile>=0.2.3 (from py7zr>=0.11.3->pycox->synthcity)\n",
            "  Downloading multivolumefile-0.2.3-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting inflate64<1.1.0,>=1.0.0 (from py7zr>=0.11.3->pycox->synthcity)\n",
            "  Downloading inflate64-1.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Collecting brotli>=1.1.0 (from py7zr>=0.11.3->pycox->synthcity)\n",
            "  Downloading Brotli-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=2.1->synthcity) (1.17.0)\n",
            "Collecting torchmetrics>=0.7.0 (from pytorch-lightning<2.0->decaf-synthetic-data>=0.1.6->synthcity)\n",
            "  Downloading torchmetrics-1.7.1-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting lightning-utilities>=0.6.0.post0 (from pytorch-lightning<2.0->decaf-synthetic-data>=0.1.6->synthcity)\n",
            "  Downloading lightning_utilities-0.14.3-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22.0->pycox->synthcity) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22.0->pycox->synthcity) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22.0->pycox->synthcity) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22.0->pycox->synthcity) (2025.1.31)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna>=3.1->synthcity) (3.2.1)\n",
            "INFO: pip is looking at multiple versions of torchtext to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torchtext>=0.10 (from decaf-synthetic-data>=0.1.6->synthcity)\n",
            "  Downloading torchtext-0.17.2-cp311-cp311-manylinux1_x86_64.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.22.1->be-great>=0.0.5->synthcity) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.22.1->be-great>=0.0.5->synthcity) (0.21.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<2.3,>=2.1->synthcity) (3.0.2)\n",
            "Collecting pyro-api>=0.1.1 (from pyro-ppl->pgmpy->synthcity)\n",
            "  Downloading pyro_api-0.1.2-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.11/dist-packages (from statsmodels->pgmpy->synthcity) (1.0.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch<2.3,>=2.1->synthcity) (1.3.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard->nflows>=0.14->synthcity) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard->nflows>=0.14->synthcity) (1.71.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard->nflows>=0.14->synthcity) (3.8)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard->nflows>=0.14->synthcity) (5.29.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->nflows>=0.14->synthcity) (75.2.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->nflows>=0.14->synthcity) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard->nflows>=0.14->synthcity) (3.1.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.5.2->be-great>=0.0.5->synthcity) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.5.2->be-great>=0.0.5->synthcity) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.5.2->be-great>=0.0.5->synthcity) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.5.2->be-great>=0.0.5->synthcity) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.5.2->be-great>=0.0.5->synthcity) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.5.2->be-great>=0.0.5->synthcity) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.5.2->be-great>=0.0.5->synthcity) (1.20.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai>=2.7.18->tsai->synthcity) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai>=2.7.18->tsai->synthcity) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai>=2.7.18->tsai->synthcity) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai>=2.7.18->tsai->synthcity) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai>=2.7.18->tsai->synthcity) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai>=2.7.18->tsai->synthcity) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai>=2.7.18->tsai->synthcity) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai>=2.7.18->tsai->synthcity) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai>=2.7.18->tsai->synthcity) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai>=2.7.18->tsai->synthcity) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai>=2.7.18->tsai->synthcity) (0.15.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai>=2.7.18->tsai->synthcity) (3.5.0)\n",
            "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torchvision>=0.11 (from fastai>=2.7.18->tsai->synthcity)\n",
            "  Downloading torchvision-0.22.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
            "  Downloading torchvision-0.21.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
            "  Downloading torchvision-0.20.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
            "  Downloading torchvision-0.20.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
            "  Downloading torchvision-0.19.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.0 kB)\n",
            "  Downloading torchvision-0.19.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.0 kB)\n",
            "  Downloading torchvision-0.18.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "INFO: pip is still looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading torchvision-0.18.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "  Downloading torchvision-0.17.2-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<4->fastai>=2.7.18->tsai->synthcity) (1.3.0)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy<4->fastai>=2.7.18->tsai->synthcity) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy<4->fastai>=2.7.18->tsai->synthcity) (0.1.5)\n",
            "INFO: pip is looking at multiple versions of thinc to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting thinc<8.4.0,>=8.3.4 (from spacy<4->fastai>=2.7.18->tsai->synthcity)\n",
            "  Downloading thinc-8.3.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\n",
            "Collecting blis<1.3.0,>=1.2.0 (from thinc<8.4.0,>=8.3.4->spacy<4->fastai>=2.7.18->tsai->synthcity)\n",
            "  Downloading blis-1.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<4->fastai>=2.7.18->tsai->synthcity) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<4->fastai>=2.7.18->tsai->synthcity) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<4->fastai>=2.7.18->tsai->synthcity) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<4->fastai>=2.7.18->tsai->synthcity) (0.21.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<4->fastai>=2.7.18->tsai->synthcity) (7.1.0)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<4->fastai>=2.7.18->tsai->synthcity) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4->fastai>=2.7.18->tsai->synthcity) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4->fastai>=2.7.18->tsai->synthcity) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4->fastai>=2.7.18->tsai->synthcity) (0.1.2)\n",
            "Downloading synthcity-0.2.11-py3-none-any.whl (430 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m430.1/430.1 kB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading be_great-0.0.8-py3-none-any.whl (16 kB)\n",
            "Downloading decaf_synthetic_data-0.1.6-py3-none-any.whl (9.1 kB)\n",
            "Downloading lifelines-0.29.0-py3-none-any.whl (349 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m349.3/349.3 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading networkx-2.8.8-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m79.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m110.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opacus-1.5.3-py3-none-any.whl (251 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.7/251.7 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading optuna-4.3.0-py3-none-any.whl (386 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.6/386.6 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic-1.10.22-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.2.2-cp311-cp311-manylinux1_x86_64.whl (755.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.6/755.6 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m111.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m73.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xgbse-0.3.3-py3-none-any.whl (35 kB)\n",
            "Downloading fflows-0.0.3-py3-none-any.whl (19 kB)\n",
            "Downloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading monai-1.4.0-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pgmpy-1.0.0-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m69.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pycox-0.3.0-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading redis-5.2.1-py3-none-any.whl (261 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.5/261.5 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tsai-0.4.0-py3-none-any.whl (324 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m324.3/324.3 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.15.2-py3-none-any.whl (231 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.9/231.9 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.5.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading formulaic-1.1.1-py3-none-any.whl (115 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.7/115.7 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (277 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.0/278.0 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading py7zr-0.22.0-py3-none-any.whl (67 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.9/67.9 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_lightning-1.9.5-py3-none-any.whl (829 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m829.5/829.5 kB\u001b[0m \u001b[31m51.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyts-0.13.0-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m85.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchtext-0.17.2-cp311-cp311-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m87.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchtuples-0.2.2-py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.9/41.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading pybind11-2.13.6-py3-none-any.whl (243 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.3/243.3 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyro_ppl-1.9.1-py3-none-any.whl (755 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m756.0/756.0 kB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Brotli-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m101.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading inflate64-1.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (96 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.2/96.2 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading interface_meta-1.3.0-py3-none-any.whl (14 kB)\n",
            "Downloading lightning_utilities-0.14.3-py3-none-any.whl (28 kB)\n",
            "Downloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multivolumefile-0.2.3-py3-none-any.whl (17 kB)\n",
            "Downloading pybcj-1.0.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.6/50.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pycryptodomex-3.22.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m62.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyppmd-1.1.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.3/141.3 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyro_api-0.1.2-py3-none-any.whl (11 kB)\n",
            "Downloading pyzstd-0.16.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (413 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m413.7/413.7 kB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchmetrics-1.7.1-py3-none-any.whl (961 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m961.5/961.5 kB\u001b[0m \u001b[31m44.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.17.2-cp311-cp311-manylinux1_x86_64.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m89.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading texttable-1.7.0-py2.py3-none-any.whl (10 kB)\n",
            "Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading thinc-8.3.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m90.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading blis-1.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.7/11.7 MB\u001b[0m \u001b[31m89.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: nflows, arfpy, geomloss, pykeops, keopscore, autograd-gamma, feather-format\n",
            "  Building wheel for nflows (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nflows: filename=nflows-0.14-py3-none-any.whl size=53654 sha256=d64a213b3db38a0d69c8f0134d7adba10224cc7c27b08147aa1aa5c027d2ffa5\n",
            "  Stored in directory: /root/.cache/pip/wheels/11/9d/b5/5c88631a7bdb388738d147b6a28ba435ab969f25eff552f75a\n",
            "  Building wheel for arfpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for arfpy: filename=arfpy-0.1.1-py3-none-any.whl size=8664 sha256=833d2874c83b052c56bdb8a7c0ca3adb6a5c94fc75e8451f6229af0fef25789e\n",
            "  Stored in directory: /root/.cache/pip/wheels/9b/9a/2b/0414258a3b781854c07acca132cf155a7d93b69f23c3cd6826\n",
            "  Building wheel for geomloss (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for geomloss: filename=geomloss-0.2.6-py3-none-any.whl size=32247 sha256=0f32c6e140fb29d6170f7b71ee290a163589ed83746a810b0b71028647c3b503\n",
            "  Stored in directory: /root/.cache/pip/wheels/f5/cf/07/9d1d883feac2951b968fed8ef676842dc90b9860ea49a4dcac\n",
            "  Building wheel for pykeops (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pykeops: filename=pykeops-2.3-py3-none-any.whl size=120491 sha256=fd41ecdccb929dd553575e3bb13fc07e32b7035b696298ec739c5db881eaeac3\n",
            "  Stored in directory: /root/.cache/pip/wheels/a8/91/ea/d9e54997a840e38595b9a2c5b9021f3969173edbda2fc99686\n",
            "  Building wheel for keopscore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keopscore: filename=keopscore-2.3-py3-none-any.whl size=185897 sha256=6332e9812564a56ccde8ace825fbd415b312417f7d5229bdfa043092c2fbcaa8\n",
            "  Stored in directory: /root/.cache/pip/wheels/32/77/92/17707f162cb65cfa8e97f0360cdb30681038f7762cf929b1b4\n",
            "  Building wheel for autograd-gamma (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for autograd-gamma: filename=autograd_gamma-0.5.0-py3-none-any.whl size=4030 sha256=7d1dcfd4892ed2e8f0e820330a92b2df378b9147d8c602b32960407929cc9526\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/67/f4/2caaae2146198dcb824f31a303833b07b14a5ec863fb3acd7b\n",
            "  Building wheel for feather-format (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for feather-format: filename=feather_format-0.4.1-py3-none-any.whl size=2434 sha256=758985255200bfc5c83d34f2d634f5a3b65351e9d7bf29ff3f2cf3403146bb41\n",
            "  Stored in directory: /root/.cache/pip/wheels/77/5b/0e/0e63d10b6353208a085a321ea2eed2578f220a77bb8a4bd7ab\n",
            "Successfully built nflows arfpy geomloss pykeops keopscore autograd-gamma feather-format\n",
            "Installing collected packages: texttable, pyro-api, brotli, xxhash, triton, redis, pyzstd, pyppmd, pydantic, pycryptodomex, pybind11, pybcj, psutil, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, multivolumefile, loguru, lightning-utilities, keopscore, interface-meta, inflate64, fsspec, feather-format, dill, colorlog, pykeops, py7zr, nvidia-cusolver-cu12, nvidia-cudnn-cu12, multiprocess, blis, alembic, torch, thinc, optuna, formulaic, autograd-gamma, torchvision, torchtuples, torchtext, torchmetrics, pyts, pyro-ppl, opacus, nflows, monai, lifelines, geomloss, fflows, datasets, arfpy, xgbse, pytorch-lightning, pycox, pgmpy, be-great, decaf-synthetic-data, tsai, synthcity\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.11.3\n",
            "    Uninstalling pydantic-2.11.3:\n",
            "      Successfully uninstalled pydantic-2.11.3\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 5.9.5\n",
            "    Uninstalling psutil-5.9.5:\n",
            "      Successfully uninstalled psutil-5.9.5\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.21.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.21.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.4.2\n",
            "    Uninstalling networkx-3.4.2:\n",
            "      Successfully uninstalled networkx-3.4.2\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: blis\n",
            "    Found existing installation: blis 1.3.0\n",
            "    Uninstalling blis-1.3.0:\n",
            "      Successfully uninstalled blis-1.3.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n",
            "      Successfully uninstalled torch-2.6.0+cu124\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 8.3.6\n",
            "    Uninstalling thinc-8.3.6:\n",
            "      Successfully uninstalled thinc-8.3.6\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.21.0+cu124\n",
            "    Uninstalling torchvision-0.21.0+cu124:\n",
            "      Successfully uninstalled torchvision-0.21.0+cu124\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-core 0.3.55 requires pydantic<3.0.0,>=2.5.2; python_full_version < \"3.12.4\", but you have pydantic 1.10.22 which is incompatible.\n",
            "scikit-image 0.25.2 requires networkx>=3.0, but you have networkx 2.8.8 which is incompatible.\n",
            "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.2.2 which is incompatible.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.12.0 which is incompatible.\n",
            "google-genai 1.11.0 requires pydantic<3.0.0,>=2.0.0, but you have pydantic 1.10.22 which is incompatible.\n",
            "langchain 0.3.24 requires pydantic<3.0.0,>=2.7.4, but you have pydantic 1.10.22 which is incompatible.\n",
            "nx-cugraph-cu12 25.2.0 requires networkx>=3.2, but you have networkx 2.8.8 which is incompatible.\n",
            "albumentations 2.0.5 requires pydantic>=2.9.2, but you have pydantic 1.10.22 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed alembic-1.15.2 arfpy-0.1.1 autograd-gamma-0.5.0 be-great-0.0.8 blis-1.2.1 brotli-1.1.0 colorlog-6.9.0 datasets-3.5.0 decaf-synthetic-data-0.1.6 dill-0.3.8 feather-format-0.4.1 fflows-0.0.3 formulaic-1.1.1 fsspec-2024.12.0 geomloss-0.2.6 inflate64-1.0.1 interface-meta-1.3.0 keopscore-2.3 lifelines-0.29.0 lightning-utilities-0.14.3 loguru-0.7.3 monai-1.4.0 multiprocess-0.70.16 multivolumefile-0.2.3 networkx-2.8.8 nflows-0.14 numpy-1.26.4 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvtx-cu12-12.1.105 opacus-1.5.3 optuna-4.3.0 pgmpy-1.0.0 psutil-7.0.0 py7zr-0.22.0 pybcj-1.0.3 pybind11-2.13.6 pycox-0.3.0 pycryptodomex-3.22.0 pydantic-1.10.22 pykeops-2.3 pyppmd-1.1.1 pyro-api-0.1.2 pyro-ppl-1.9.1 pytorch-lightning-1.9.5 pyts-0.13.0 pyzstd-0.16.2 redis-5.2.1 synthcity-0.2.11 texttable-1.7.0 thinc-8.3.4 torch-2.2.2 torchmetrics-1.7.1 torchtext-0.17.2 torchtuples-0.2.2 torchvision-0.17.2 triton-2.2.0 tsai-0.4.0 xgbse-0.3.3 xxhash-3.5.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "psutil"
                ]
              },
              "id": "32f376698b134e959350ccf4f8e1d85b"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install synthcity"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "NcwQ6Yo09JC8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import sys\n",
        "import warnings\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "import synthcity.logger as log\n",
        "from synthcity.plugins import Plugins\n",
        "from synthcity.plugins.core.dataloader import TimeSeriesDataLoader\n",
        "log.add(sink=sys.stderr, level=\"INFO\")\n"
      ],
      "metadata": {
        "id": "kfDi7FQF9LIv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac25774f-4218-4807-8512-6a277a768b15",
        "collapsed": true
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "[KeOps] Compiling cuda jit compiler engine ... OK\n",
            "[pyKeOps] Compiling nvrtc binder for python ... OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/drive/Shareddrives/sp_env/datasets/Electricity Transformer Dataset (ETDataset)/ETTh1.csv\"\n",
        "\n",
        "df = pd.read_csv(file_path)\n",
        "print(df.head())\n",
        "print(df.info())\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "id": "DCLsmN-F9NGv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b17985d-b5b5-4df6-8d70-cc21c0f6aadc",
        "collapsed": true
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                  date   HUFL   HULL   MUFL   MULL   LUFL   LULL         OT\n",
            "0  2016-07-01 00:00:00  5.827  2.009  1.599  0.462  4.203  1.340  30.531000\n",
            "1  2016-07-01 01:00:00  5.693  2.076  1.492  0.426  4.142  1.371  27.787001\n",
            "2  2016-07-01 02:00:00  5.157  1.741  1.279  0.355  3.777  1.218  27.787001\n",
            "3  2016-07-01 03:00:00  5.090  1.942  1.279  0.391  3.807  1.279  25.044001\n",
            "4  2016-07-01 04:00:00  5.358  1.942  1.492  0.462  3.868  1.279  21.948000\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 17420 entries, 0 to 17419\n",
            "Data columns (total 8 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   date    17420 non-null  object \n",
            " 1   HUFL    17420 non-null  float64\n",
            " 2   HULL    17420 non-null  float64\n",
            " 3   MUFL    17420 non-null  float64\n",
            " 4   MULL    17420 non-null  float64\n",
            " 5   LUFL    17420 non-null  float64\n",
            " 6   LULL    17420 non-null  float64\n",
            " 7   OT      17420 non-null  float64\n",
            "dtypes: float64(7), object(1)\n",
            "memory usage: 1.1+ MB\n",
            "None\n",
            "date    0\n",
            "HUFL    0\n",
            "HULL    0\n",
            "MUFL    0\n",
            "MULL    0\n",
            "LUFL    0\n",
            "LULL    0\n",
            "OT      0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert 'date' to datetime, set as index, and sort\n",
        "df['date'] = pd.to_datetime(df['date'])\n",
        "df.set_index('date', inplace=True)\n",
        "df.sort_index(inplace=True)\n",
        "\n",
        "# Keep the latest 5000 rows\n",
        "df_latest = df.tail(5000)\n",
        "\n",
        "# Train-test split: 70% for training (for TimeGAN), 30% for testing (TSTR)\n",
        "train_size = int(0.7 * len(df_latest))\n",
        "df_train = df_latest.iloc[:train_size]\n",
        "df_test = df_latest.iloc[train_size:]  # use later for LSTM-TSTR\n",
        "\n",
        "# Normalize the data using StandardScaler\n",
        "scaler = MinMaxScaler()\n",
        "scaled_train = scaler.fit_transform(df_train)\n",
        "df_scaled_train = pd.DataFrame(scaled_train, columns=df_train.columns, index=df_train.index)\n",
        "scaled_test = scaler.transform(df_test)\n",
        "df_scaled_test = pd.DataFrame(scaled_train, columns=df_train.columns, index=df_train.index)\n",
        "\n",
        "# Sequence length for time-series data (dataset = hourly; 24 hours)\n",
        "sequence_length = 24\n",
        "temporal_data = []\n",
        "observation_times = []\n",
        "\n",
        "# Generate sequences from df_train only\n",
        "for start in range(len(df_train) - sequence_length + 1):\n",
        "    sequence = df_train.iloc[start:start + sequence_length].reset_index(drop=True)\n",
        "    temporal_data.append(sequence)\n",
        "    observation_times.append(list(range(sequence_length)))  # relative time within the window\n",
        "\n",
        "# Dummy outcome for TimeGAN (can be used in DataLoader)\n",
        "dummy_outcome = pd.DataFrame(np.zeros(len(temporal_data)), columns=[\"outcome\"])\n",
        "\n",
        "# --- Create DataLoader for TimeGAN ---\n",
        "loader = TimeSeriesDataLoader(\n",
        "    temporal_data=temporal_data,\n",
        "    observation_times=observation_times,\n",
        "    static_data=None,\n",
        "    outcome=dummy_outcome,\n",
        ")\n",
        "\n",
        "# Print the loader info\n",
        "print(f\"TimeSeriesDataLoader created with {len(temporal_data)} sequences\")\n"
      ],
      "metadata": {
        "id": "siWRiBtn9O0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(df_train))  # Check the length of the dataframe\n",
        "print(loader.dataframe())"
      ],
      "metadata": {
        "id": "FmZe08FM9Rd0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d6a5542-342b-4bd2-efd5-0577e4277b12",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3500\n",
            "       seq_id  seq_time_id  seq_temporal_HUFL  seq_temporal_HULL  \\\n",
            "0           0            0          -0.144002          -0.872259   \n",
            "1           0            1          -0.285107          -0.086752   \n",
            "2           0            2          -0.073391           0.031162   \n",
            "3           0            3          -0.120465          -0.322580   \n",
            "4           0            4           0.193244          -0.047447   \n",
            "...       ...          ...                ...                ...   \n",
            "83443    3476           19           0.820780          -0.440494   \n",
            "83444    3476           20           0.938348          -0.440494   \n",
            "83445    3476           21           0.930502           0.109772   \n",
            "83446    3476           22           1.252174           0.424209   \n",
            "83447    3476           23           0.577565          -0.126057   \n",
            "\n",
            "       seq_temporal_LUFL  seq_temporal_LULL  seq_temporal_MUFL  \\\n",
            "0              -0.437390           0.611581          -0.114356   \n",
            "1              -0.437390           1.116499          -0.296925   \n",
            "2              -0.878665           0.192196          -0.040447   \n",
            "3              -0.819764           0.192196          -0.018667   \n",
            "4              -0.466358           0.611581           0.268280   \n",
            "...                  ...                ...                ...   \n",
            "83443           0.738701           0.862660           0.733634   \n",
            "83444           0.738701           0.023891           0.907515   \n",
            "83445           0.886436           0.526049           0.916203   \n",
            "83446           1.885823           0.443275           1.085801   \n",
            "83447          -0.731895          -0.061642           0.668414   \n",
            "\n",
            "       seq_temporal_MULL  seq_temporal_OT  seq_out_outcome  \n",
            "0              -0.749515        -0.946543              0.0  \n",
            "1              -0.172201        -0.870846              0.0  \n",
            "2              -0.247810        -0.814207              0.0  \n",
            "3              -0.398322        -0.776627              0.0  \n",
            "4              -0.046421        -0.795417              0.0  \n",
            "...                  ...              ...              ...  \n",
            "83443          -0.849856         0.299776              0.0  \n",
            "83444          -0.975636         0.035373              0.0  \n",
            "83445          -0.372883         0.167709              0.0  \n",
            "83446          -0.372883         0.394263              0.0  \n",
            "83447           0.078652         0.715305              0.0  \n",
            "\n",
            "[83448 rows x 10 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from synthcity.plugins import Plugins\n",
        "\n",
        "hparams = {\n",
        "          \"mode\": \"LSTM\", # default mode = RNN\n",
        "}\n",
        "\n",
        "# Load TimeGAN with custom parameters\n",
        "syn_model = Plugins().get(\"timegan\", **hparams)"
      ],
      "metadata": {
        "id": "oYqRdbxl9W74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82011e24-a71b-48c3-d844-9253dc7d49fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2025-04-17T07:15:09.112208+0000][1404][CRITICAL] module disabled: /usr/local/lib/python3.11/dist-packages/synthcity/plugins/generic/plugin_goggle.py\n",
            "[2025-04-17T07:15:09.112208+0000][1404][CRITICAL] module disabled: /usr/local/lib/python3.11/dist-packages/synthcity/plugins/generic/plugin_goggle.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Print all parameters of initialized model ---\n",
        "for attr in dir(syn_model):\n",
        "    if not attr.startswith(\"_\") and not callable(getattr(syn_model, attr)):\n",
        "        print(f\"{attr}: {getattr(syn_model, attr)}\")"
      ],
      "metadata": {
        "id": "y9ZVw8pT9Y_Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c482f019-1ce6-4117-b6b3-77d8628fb043"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch_size: 64\n",
            "class_name: TimeGANPlugin\n",
            "clipping_value: 0\n",
            "compress_dataset: False\n",
            "dataloader_sampling_strategy: imbalanced_time_censoring\n",
            "device: cuda\n",
            "discriminator_batch_norm: False\n",
            "discriminator_dropout: 0.1\n",
            "discriminator_loss: None\n",
            "discriminator_lr: 0.001\n",
            "discriminator_n_iter: 1\n",
            "discriminator_n_layers_hidden: 3\n",
            "discriminator_n_units_hidden: 300\n",
            "discriminator_nonlin: leaky_relu\n",
            "discriminator_weight_decay: 0.001\n",
            "embedding_penalty: 10\n",
            "encoder: None\n",
            "encoder_max_clusters: 20\n",
            "expecting_conditional: False\n",
            "fitted: False\n",
            "gamma_penalty: 1\n",
            "generator_batch_norm: False\n",
            "generator_dropout: 0.01\n",
            "generator_loss: None\n",
            "generator_lr: 0.001\n",
            "generator_n_layers_hidden: 2\n",
            "generator_n_units_hidden: 150\n",
            "generator_nonlin: leaky_relu\n",
            "generator_nonlin_out_continuous: tanh\n",
            "generator_nonlin_out_discrete: softmax\n",
            "generator_residual: True\n",
            "generator_weight_decay: 0.001\n",
            "mode: LSTM\n",
            "module_name: synthcity.plugins.time_series.plugin_timegan\n",
            "module_relative_path: ../time_series/plugin_timegan.py\n",
            "moments_penalty: 100\n",
            "n_iter: 1000\n",
            "n_iter_print: 10\n",
            "outcome_encoder: TabularEncoder(cat_encoder_params={'handle_unknown': 'ignore',\n",
            "                                   'sparse_output': False},\n",
            "               categorical_encoder='onehot',\n",
            "               cont_encoder_params={'n_components': 20},\n",
            "               continuous_encoder='bayesian_gmm', max_clusters=20)\n",
            "random_state: 0\n",
            "sampling_patience: 500\n",
            "sampling_strategy: marginal\n",
            "strict: True\n",
            "use_horizon_condition: True\n",
            "workspace: workspace\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## fitting the model"
      ],
      "metadata": {
        "id": "IKG0O5Pg9hpG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ──────── Train the model ────────\n",
        "syn_model.fit(loader)"
      ],
      "metadata": {
        "id": "-BKXe4G19l_8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "727bd450-de06-446f-9797-3c87dd6ccbf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [3:17:55<00:00, 11.88s/it]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<synthcity.plugins.time_series.plugin_timegan.TimeGANPlugin at 0x7f95bf7ed090>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "syn_seqs = syn_data.temporal_data()\n",
        "print(len(syn_seqs))  # Should match len(temporal_data)\n",
        "print(syn_seqs[0].shape)  # Should be (30, num_features)\n",
        "\n",
        "# ──────── Generate Synthetic Data ────────\n",
        "n_samples = len(temporal_data)\n",
        "syn_data = syn_model.generate(count=n_samples)\n",
        "print(syn_data.shape)"
      ],
      "metadata": {
        "id": "JviqEDru9nMO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d0ac9fa-6fa8-444d-e5c5-5e01a95a41cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32986, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ──────── Save with automated format ────────\n",
        "import datetime\n",
        "import os\n",
        "# Get the current date and time\n",
        "now = datetime.datetime.now()\n",
        "timestamp = now.strftime(\"%m%d%y-%H%M%S\")  # MMDDYY-HHMMSS format\n",
        "\n",
        "# Define the base directory\n",
        "base_dir = \"/content/drive/Shareddrives/sp_env/synthetic_datasets/TimeGAN/electricity\"  #CHANGE THIS\n",
        "if not os.path.exists(base_dir):\n",
        "    os.makedirs(base_dir)\n",
        "\n",
        "# Construct the filename\n",
        "model_name = type(syn_model).__name__.lower() # Get model name dynamically\n",
        "filename = f\"{timestamp}-{model_name}-n_3000.csv\"\n",
        "filepath = os.path.join(base_dir, filename)\n",
        "\n",
        "# Save the data\n",
        "df_syn = syn_data.dataframe()\n",
        "df_syn.to_csv(filepath, index=False)\n",
        "\n",
        "print(f\"Synthetic data saved to: {filepath}\")"
      ],
      "metadata": {
        "id": "J4rF0HY29o65",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "737949ea-4352-47a8-dbb4-4e116a781d65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synthetic data saved to: /content/drive/Shareddrives/sp_env/synthetic_datasets/TimeGAN/electricity/041725-104510-timeganplugin-n_3000.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "TICnBaoH9r8Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prerequisites"
      ],
      "metadata": {
        "id": "QlHAzxfV9uXf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ──────── Convert to NumPy ────────\n",
        "\n",
        "# Define selected columns explicitly\n",
        "selected_columns = ['seq_temporal_HUFL', 'seq_temporal_HULL', 'seq_temporal_LUFL', 'seq_temporal_LULL', 'seq_temporal_MUFL', 'seq_temporal_MULL', 'seq_temporal_OT']\n",
        "\n",
        "# Ensure real_data and synthetic_data only contain the selected columns\n",
        "real_data = loader.dataframe()[selected_columns].to_numpy()\n",
        "synthetic_data = syn_data.dataframe()[selected_columns].to_numpy()"
      ],
      "metadata": {
        "id": "zUMHadsq9vw8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ──────── Check datasets ────────\n",
        "\n",
        "print(real_data, \"\\n ------------------------------------------------------- \\n\", synthetic_data)\n",
        "print(type(real_data),type(synthetic_data))\n",
        "print(real_data.shape,synthetic_data.shape)"
      ],
      "metadata": {
        "id": "DumXr_Gg9y6U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adbf267a-f779-4274-f1ab-da42bd809ad4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.14400208 -0.87225887 -0.43739017 ... -0.11435603 -0.74951542\n",
            "  -0.94654288]\n",
            " [-0.28510688 -0.08675185 -0.43739017 ... -0.29692476 -0.17220108\n",
            "  -0.87084576]\n",
            " [-0.0733911   0.03116217 -0.87866536 ... -0.04044749 -0.24781018\n",
            "  -0.81420704]\n",
            " ...\n",
            " [ 0.93050234  0.10977157  0.88643612 ...  0.91620296 -0.37288316\n",
            "   0.16770871]\n",
            " [ 1.25217444  0.42420902  1.88582339 ...  1.08580096 -0.37288316\n",
            "   0.39426346]\n",
            " [ 0.57756456 -0.12605662 -0.73189547 ...  0.66841365  0.07865156\n",
            "   0.71530527]] \n",
            " ------------------------------------------------------- \n",
            " [[ 0.27356008 -0.4228107  -1.5115763  ... -0.65500891  0.85368312\n",
            "  -1.0524259 ]\n",
            " [-2.14916147 -0.42275688 -0.75809738 ... -1.36527979 -2.06244054\n",
            "  -0.73483677]\n",
            " [-0.0065081   2.96714215  0.93394725 ...  0.30865342  0.28585971\n",
            "   0.82107019]\n",
            " ...\n",
            " [ 0.92218457 -0.71467844  1.05048084 ... -2.157916    1.14359917\n",
            "   0.50628247]\n",
            " [-1.32724227  1.80199802  0.69401314 ... -2.72749959 -0.79232226\n",
            "  -0.37295208]\n",
            " [ 0.64374065  0.14529246  1.39602811 ...  1.06177179  2.17084894\n",
            "   0.50629471]]\n",
            "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
            "(83448, 7) (32986, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate distance metrics"
      ],
      "metadata": {
        "id": "0pU8BORS9vWk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Helper Functions"
      ],
      "metadata": {
        "id": "DVguOJWi-Fos"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import wasserstein_distance, entropy\n",
        "import numpy as np\n",
        "\n",
        "def compute_wasserstein(real_data, synthetic_data, selected_columns):\n",
        "    \"\"\"\n",
        "    Computes Wasserstein Distance between real and synthetic time-series data.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # Ensure both datasets have the same number of samples\n",
        "    min_length = min(len(real_data), len(synthetic_data))\n",
        "    real_trimmed = real_data[:min_length]  # Keep original order (no random sampling)\n",
        "    synthetic_trimmed = synthetic_data[:min_length]  # Match size\n",
        "    print(real_trimmed.shape,synthetic_trimmed.shape)\n",
        "\n",
        "    wasserstein_results = {}\n",
        "\n",
        "    # Compute Wasserstein Distance for each feature\n",
        "    for i, col in enumerate(selected_columns):\n",
        "        w_dist = wasserstein_distance(real_trimmed[:, i], synthetic_trimmed[:, i])\n",
        "        wasserstein_results[col] = w_dist\n",
        "        print(f\"{w_dist}\")\n",
        "\n",
        "    return wasserstein_results\n",
        "\n",
        "def compute_kl_divergence(real_data, synthetic_data, selected_columns, bins=50):\n",
        "    \"\"\"\n",
        "    Computes KL Divergence between real and synthetic time-series data.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # Ensure both datasets have the same number of samples\n",
        "    min_length = min(len(real_data), len(synthetic_data))\n",
        "    real_trimmed = real_data[:min_length]  # Keep original order\n",
        "    synthetic_trimmed = synthetic_data[:min_length]  # Match size\n",
        "\n",
        "    kl_results = {}\n",
        "\n",
        "    for i, col in enumerate(selected_columns):\n",
        "        # Compute histogram-based probability distributions\n",
        "        real_hist, _ = np.histogram(real_trimmed[:, i], bins=bins, density=True)\n",
        "        synth_hist, _ = np.histogram(synthetic_trimmed[:, i], bins=bins, density=True)\n",
        "\n",
        "        # Avoid zero probabilities (KL Divergence is undefined for zero values)\n",
        "        real_hist += 1e-10\n",
        "        synth_hist += 1e-10\n",
        "\n",
        "        # Compute KL Divergence\n",
        "        kl_div = entropy(real_hist, synth_hist)\n",
        "        kl_results[col] = kl_div\n",
        "        print(f\"{kl_div}\")\n",
        "\n",
        "    return kl_results"
      ],
      "metadata": {
        "id": "GjGk3_Zx94Ko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate Metrics"
      ],
      "metadata": {
        "id": "yLnb7Vqg-IG_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute Wasserstein Distance\n",
        "wasserstein_results = compute_wasserstein(real_data, synthetic_data, selected_columns)\n",
        "print(\"Wasserstein Distance Results:\")\n",
        "print(wasserstein_results)\n",
        "\n",
        "# Compute KL Divergence\n",
        "kl_results = compute_kl_divergence(real_data, synthetic_data, selected_columns)\n",
        "print(\"KL Divergence Results:\")\n",
        "print(kl_results)"
      ],
      "metadata": {
        "id": "olm0RYP89-SN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b1ad1ea-d355-4e66-b8e1-b204e4d42b09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32986, 7) (32986, 7)\n",
            "0.6333693243548061\n",
            "0.5754466980076927\n",
            "0.29508214647631575\n",
            "0.3802229781894522\n",
            "0.7765970668651524\n",
            "0.6079451106316505\n",
            "0.5188429106552913\n",
            "Wasserstein Distance Results:\n",
            "{'seq_temporal_HUFL': 0.6333693243548061, 'seq_temporal_HULL': 0.5754466980076927, 'seq_temporal_LUFL': 0.29508214647631575, 'seq_temporal_LULL': 0.3802229781894522, 'seq_temporal_MUFL': 0.7765970668651524, 'seq_temporal_MULL': 0.6079451106316505, 'seq_temporal_OT': 0.5188429106552913}\n",
            "11.15438525453038\n",
            "11.082115952089795\n",
            "10.636127261040281\n",
            "10.711759664455933\n",
            "12.457121032641474\n",
            "12.978326610668605\n",
            "14.624584343805381\n",
            "KL Divergence Results:\n",
            "{'seq_temporal_HUFL': 11.15438525453038, 'seq_temporal_HULL': 11.082115952089795, 'seq_temporal_LUFL': 10.636127261040281, 'seq_temporal_LULL': 10.711759664455933, 'seq_temporal_MUFL': 12.457121032641474, 'seq_temporal_MULL': 12.978326610668605, 'seq_temporal_OT': 14.624584343805381}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM downstream"
      ],
      "metadata": {
        "id": "UpJLIRUZChiz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "real_data = loader.dataframe()\n",
        "\n",
        "# 2. Drop the unwanted column\n",
        "real_data = real_data.drop(columns=[\"seq_id\", \"seq_time_id\", \"seq_out_outcome\"], errors=\"ignore\")\n",
        "df_synth = df_synth.drop(columns=[\"seq_id\", \"seq_time_id\", \"seq_out_outcome\"], errors=\"ignore\")"
      ],
      "metadata": {
        "id": "oidw2-H7OeUO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "BFHbRznzoYj_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ✧.* libraries ✧.*\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "metadata": {
        "id": "jBeVAcOyoPDz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "recheck LSTM notebook for"
      ],
      "metadata": {
        "id": "AqxZ2PLWo9pN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ──────── Load synthetic training data ────────\n",
        "\n",
        "df_synth = pd.read_csv(\"/content/drive/Shareddrives/sp_env/synthetic_datasets/TimeGAN/electricity/041725-104510-timeganplugin-n_3000.csv\")\n",
        "scaler = MinMaxScaler()\n",
        "data_synth_scaled = scaler.fit_transform(df_synth.values)\n",
        "data_synth = torch.tensor(data_synth_scaled, dtype=torch.float32)\n",
        "\n",
        "# ──────── Load real held-out test data (same columns, same scale) ────────\n",
        "df_real_test = real_data\n",
        "data_real_scaled = scaler.transform(df_real_test.values)  # Use SAME scaler\n",
        "data_real = torch.tensor(data_real_scaled, dtype=torch.float32)\n",
        "\n",
        "# ──────── Sequence builder ───────────\n",
        "def make_sequences(data, seq_len):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - seq_len):\n",
        "        X.append(data[i:i+seq_len])\n",
        "        y.append(data[i+seq_len])\n",
        "    return torch.stack(X), torch.stack(y)\n",
        "\n",
        "SEQ_LEN = sequence_length\n",
        "\n",
        "# Sequences for synthetic (train)\n",
        "X_train, y_train = make_sequences(data_synth, SEQ_LEN)\n",
        "train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=32, shuffle=True)\n",
        "\n",
        "# Sequences for real (test)\n",
        "X_test, y_test = make_sequences(data_real, SEQ_LEN)\n"
      ],
      "metadata": {
        "id": "txcyFCaxoZry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ✧.* model definition and training ✧.*\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "\n",
        "# ─── Model Definition ──────────────────────────────────────\n",
        "class ShallowLSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size=32):\n",
        "        super().__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
        "        self.linear = nn.Linear(hidden_size, input_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        _, (hn, _) = self.lstm(x)  # hn shape: (1, batch, hidden_size)\n",
        "        out = self.linear(hn.squeeze(0))  # squeeze to (batch, hidden_size)\n",
        "        return out\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Based on a study by Deswal and Kumar(2024), they indicated the following\n",
        "hyperparameters to be the best case for the dataset in their study (stock price).\n",
        "\n",
        "epoch = 200\n",
        "batch_size = 32\n",
        "neurons = 512\n",
        "learning_rate = 0.002\n",
        "dropout = 0.01\n",
        "\n",
        "*did not use yet due to long training time\n",
        "\"\"\"\n",
        "\n",
        "class TunedLSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size=64, dropout=0.01):\n",
        "        super().__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, dropout=dropout, batch_first=True)\n",
        "        self.linear = nn.Linear(hidden_size, input_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        output, _ = self.lstm(x)\n",
        "        last = output[:, -1, :]  # take the last time step\n",
        "        return self.linear(last)\n",
        "\n",
        "# ─── Model Init ─────────────────────────────────────────────\n",
        "# model = TunedLSTM(input_size=X_train.shape[2], hidden_size=64, dropout=0.01)\n",
        "model = ShallowLSTM(input_size=X_train.shape[2], hidden_size=32)\n",
        "\n",
        "# ─── Optimizer & Loss ───────────────────────────────────────\n",
        "loss_fn = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.002)\n",
        "\n",
        "# ─── Training ───────────────────────────────────────────────\n",
        "EPOCHS = 50\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    model.train()\n",
        "    for xb, yb in train_loader:\n",
        "        pred = model(xb)\n",
        "        loss = loss_fn(pred, yb)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # if epoch % 10 == 0 or epoch == 1:\n",
        "    print(f\"Epoch {epoch}: Train MSE = {loss.item():.6f}\")"
      ],
      "metadata": {
        "id": "xb92SGsLojRK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}