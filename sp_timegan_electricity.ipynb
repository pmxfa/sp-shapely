{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNGfR6EaMLYbXpbV13/NISq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pmxfa/sp-shapely/blob/main/sp_timegan_electricity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oaMLghK_ipz1",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!pip install synthcity"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "NcwQ6Yo09JC8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import sys\n",
        "import warnings\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "import synthcity.logger as log\n",
        "from synthcity.plugins import Plugins\n",
        "from synthcity.plugins.core.dataloader import TimeSeriesDataLoader\n",
        "\n",
        "log.add(sink=sys.stderr, level=\"INFO\")"
      ],
      "metadata": {
        "id": "kfDi7FQF9LIv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99aea93d-b19f-4272-edf3-cf7a95009ec4",
        "collapsed": true
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "[KeOps] Compiling cuda jit compiler engine ... OK\n",
            "[pyKeOps] Compiling nvrtc binder for python ... OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/drive/Shareddrives/sp_env/datasets/Electricity Transformer Dataset (ETDataset)/ETTh1.csv\"\n",
        "\n",
        "df = pd.read_csv(file_path)\n",
        "print(df.head())\n",
        "print(df.info())\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "id": "DCLsmN-F9NGv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2178f3e-aa92-47b6-aefd-4fbf4b40286d",
        "collapsed": true
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                  date   HUFL   HULL   MUFL   MULL   LUFL   LULL         OT\n",
            "0  2016-07-01 00:00:00  5.827  2.009  1.599  0.462  4.203  1.340  30.531000\n",
            "1  2016-07-01 01:00:00  5.693  2.076  1.492  0.426  4.142  1.371  27.787001\n",
            "2  2016-07-01 02:00:00  5.157  1.741  1.279  0.355  3.777  1.218  27.787001\n",
            "3  2016-07-01 03:00:00  5.090  1.942  1.279  0.391  3.807  1.279  25.044001\n",
            "4  2016-07-01 04:00:00  5.358  1.942  1.492  0.462  3.868  1.279  21.948000\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 17420 entries, 0 to 17419\n",
            "Data columns (total 8 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   date    17420 non-null  object \n",
            " 1   HUFL    17420 non-null  float64\n",
            " 2   HULL    17420 non-null  float64\n",
            " 3   MUFL    17420 non-null  float64\n",
            " 4   MULL    17420 non-null  float64\n",
            " 5   LUFL    17420 non-null  float64\n",
            " 6   LULL    17420 non-null  float64\n",
            " 7   OT      17420 non-null  float64\n",
            "dtypes: float64(7), object(1)\n",
            "memory usage: 1.1+ MB\n",
            "None\n",
            "date    0\n",
            "HUFL    0\n",
            "HULL    0\n",
            "MUFL    0\n",
            "MULL    0\n",
            "LUFL    0\n",
            "LULL    0\n",
            "OT      0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert 'date' to datetime, set as index, and sort\n",
        "df['date'] = pd.to_datetime(df['date'])\n",
        "df.set_index('date', inplace=True)\n",
        "df.sort_index(inplace=True)\n",
        "\n",
        "# Keep the latest 5000 rows\n",
        "df_latest = df.tail(5000)\n",
        "\n",
        "# Train-test split: 70% for training (for TimeGAN), 30% for testing (TSTR)\n",
        "train_size = int(0.7 * len(df_latest))\n",
        "df_train = df_latest.iloc[:train_size]\n",
        "df_test = df_latest.iloc[train_size:]  # use later for LSTM-TSTR\n",
        "\n",
        "# Normalize the data\n",
        "scaler = MinMaxScaler()\n",
        "scaled_train = scaler.fit_transform(df_train)\n",
        "df_scaled_train = pd.DataFrame(scaled_train, columns=df_train.columns, index=df_train.index)\n",
        "scaled_test = scaler.transform(df_test)\n",
        "df_scaled_test = pd.DataFrame(scaled_train, columns=df_train.columns, index=df_train.index)\n",
        "\n",
        "# Sequence length for time-series data (dataset = hourly; 24 hours)\n",
        "sequence_length = 24\n",
        "temporal_data = []\n",
        "observation_times = []\n",
        "\n",
        "# Generate sequences from df_scaled_train only\n",
        "for start in range(len(df_scaled_train) - sequence_length + 1):\n",
        "    sequence = df_scaled_train.iloc[start:start + sequence_length].reset_index(drop=True)\n",
        "    temporal_data.append(sequence)\n",
        "    observation_times.append(list(range(sequence_length)))  # relative time within the window\n",
        "\n",
        "# Dummy outcome for TimeGAN (can be used in DataLoader)\n",
        "dummy_outcome = pd.DataFrame(np.zeros(len(temporal_data)), columns=[\"outcome\"])\n",
        "\n",
        "# Create DataLoader for TimeGAN\n",
        "loader = TimeSeriesDataLoader(\n",
        "    temporal_data=temporal_data,\n",
        "    observation_times=observation_times,\n",
        "    static_data=None,\n",
        "    outcome=dummy_outcome,\n",
        ")\n",
        "\n",
        "# Print the loader info\n",
        "print(f\"TimeSeriesDataLoader created with {len(temporal_data)} sequences\")\n"
      ],
      "metadata": {
        "id": "siWRiBtn9O0V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ee2f6d5-cda2-4919-d858-3b65d9b89a74"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TimeSeriesDataLoader created with 3477 sequences\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(df_train))\n",
        "print(loader.dataframe())"
      ],
      "metadata": {
        "id": "FmZe08FM9Rd0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56f5b879-1d37-445c-c2fd-c590e15a8ca8",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3500\n",
            "       seq_id  seq_time_id  seq_temporal_HUFL  seq_temporal_HULL  \\\n",
            "0           0            0           0.642388           0.302720   \n",
            "1           0            1           0.613277           0.410782   \n",
            "2           0            2           0.656955           0.427003   \n",
            "3           0            3           0.647244           0.378339   \n",
            "4           0            4           0.711963           0.416189   \n",
            "...       ...          ...                ...                ...   \n",
            "83443    3476           19           0.841426           0.362118   \n",
            "83444    3476           20           0.865681           0.362118   \n",
            "83445    3476           21           0.864062           0.437818   \n",
            "83446    3476           22           0.930425           0.481075   \n",
            "83447    3476           23           0.791250           0.405375   \n",
            "\n",
            "       seq_temporal_LUFL  seq_temporal_LULL  seq_temporal_MUFL  \\\n",
            "0               0.429806           0.589646           0.659849   \n",
            "1               0.429806           0.666667           0.620829   \n",
            "2               0.364003           0.525673           0.675646   \n",
            "3               0.372786           0.525673           0.680301   \n",
            "4               0.425486           0.589646           0.741631   \n",
            "...                  ...                ...                ...   \n",
            "83443           0.605184           0.627946           0.841092   \n",
            "83444           0.605184           0.500000           0.878256   \n",
            "83445           0.627214           0.576599           0.880113   \n",
            "83446           0.776242           0.563973           0.916362   \n",
            "83447           0.385889           0.486953           0.827152   \n",
            "\n",
            "       seq_temporal_MULL  seq_temporal_OT  seq_out_outcome  \n",
            "0               0.330177         0.377483              0.0  \n",
            "1               0.403162         0.393583              0.0  \n",
            "2               0.393604         0.405629              0.0  \n",
            "3               0.374576         0.413622              0.0  \n",
            "4               0.419064         0.409625              0.0  \n",
            "...                  ...              ...              ...  \n",
            "83443           0.317492         0.642555              0.0  \n",
            "83444           0.301590         0.586321              0.0  \n",
            "83445           0.377792         0.614467              0.0  \n",
            "83446           0.377792         0.662651              0.0  \n",
            "83447           0.434876         0.730932              0.0  \n",
            "\n",
            "[83448 rows x 10 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hparams = {\n",
        "          \"mode\": \"LSTM\", # default mode = RNN\n",
        "}\n",
        "\n",
        "# Load TimeGAN with custom parameters\n",
        "syn_model = Plugins().get(\"timegan\", **hparams)"
      ],
      "metadata": {
        "id": "oYqRdbxl9W74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d49c7204-cd8b-4b7a-dbb9-fbc9523debf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2025-04-26T12:35:18.790696+0000][1314][CRITICAL] module disabled: /usr/local/lib/python3.11/dist-packages/synthcity/plugins/generic/plugin_goggle.py\n",
            "[2025-04-26T12:35:18.790696+0000][1314][CRITICAL] module disabled: /usr/local/lib/python3.11/dist-packages/synthcity/plugins/generic/plugin_goggle.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print all parameters of initialized model\n",
        "for attr in dir(syn_model):\n",
        "    if not attr.startswith(\"_\") and not callable(getattr(syn_model, attr)):\n",
        "        print(f\"{attr}: {getattr(syn_model, attr)}\")"
      ],
      "metadata": {
        "id": "y9ZVw8pT9Y_Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99608720-a947-4e58-c79d-86a19f8a46bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch_size: 64\n",
            "class_name: TimeGANPlugin\n",
            "clipping_value: 0\n",
            "compress_dataset: False\n",
            "dataloader_sampling_strategy: imbalanced_time_censoring\n",
            "device: cuda\n",
            "discriminator_batch_norm: False\n",
            "discriminator_dropout: 0.1\n",
            "discriminator_loss: None\n",
            "discriminator_lr: 0.001\n",
            "discriminator_n_iter: 1\n",
            "discriminator_n_layers_hidden: 3\n",
            "discriminator_n_units_hidden: 300\n",
            "discriminator_nonlin: leaky_relu\n",
            "discriminator_weight_decay: 0.001\n",
            "embedding_penalty: 10\n",
            "encoder: None\n",
            "encoder_max_clusters: 20\n",
            "expecting_conditional: False\n",
            "fitted: False\n",
            "gamma_penalty: 1\n",
            "generator_batch_norm: False\n",
            "generator_dropout: 0.01\n",
            "generator_loss: None\n",
            "generator_lr: 0.001\n",
            "generator_n_layers_hidden: 2\n",
            "generator_n_units_hidden: 150\n",
            "generator_nonlin: leaky_relu\n",
            "generator_nonlin_out_continuous: tanh\n",
            "generator_nonlin_out_discrete: softmax\n",
            "generator_residual: True\n",
            "generator_weight_decay: 0.001\n",
            "mode: LSTM\n",
            "module_name: synthcity.plugins.time_series.plugin_timegan\n",
            "module_relative_path: ../time_series/plugin_timegan.py\n",
            "moments_penalty: 100\n",
            "n_iter: 1000\n",
            "n_iter_print: 10\n",
            "outcome_encoder: TabularEncoder(cat_encoder_params={'handle_unknown': 'ignore',\n",
            "                                   'sparse_output': False},\n",
            "               categorical_encoder='onehot',\n",
            "               cont_encoder_params={'n_components': 20},\n",
            "               continuous_encoder='bayesian_gmm', max_clusters=20)\n",
            "random_state: 0\n",
            "sampling_patience: 500\n",
            "sampling_strategy: marginal\n",
            "strict: True\n",
            "use_horizon_condition: True\n",
            "workspace: workspace\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## fitting the model"
      ],
      "metadata": {
        "id": "IKG0O5Pg9hpG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(loader.shape)"
      ],
      "metadata": {
        "id": "THzKqhIFcWlG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Train the model\n",
        "syn_model.fit(loader)"
      ],
      "metadata": {
        "id": "-BKXe4G19l_8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4c855a1-4ce3-44c9-eb7c-07ddd0ec30e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [2:02:26<00:00,  7.35s/it]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<synthcity.plugins.time_series.plugin_timegan.TimeGANPlugin at 0x787b51703a90>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "saved_model = syn_model.save()"
      ],
      "metadata": {
        "id": "MMIE6K28AavA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from synthcity.utils.serialization import save_to_file, load_from_file\n",
        "\n",
        "# Save model to drive\n",
        "# save_to_file('/content/drive/Shareddrives/sp_env/test_model.pkl', syn_model)\n",
        "save_to_file('/content/drive/Shareddrives/sp_env/saved_models/GAN_Electricity.pkl', syn_model)\n",
        "\n",
        "# Load the model\n",
        "# loaded_model = load_from_file('/content/drive/Shareddrives/sp_env/test_model.pkl')"
      ],
      "metadata": {
        "id": "GXR9yPgyDsfe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_samples = len(temporal_data)\n",
        "syn_data = syn_model.generate(count=n_samples)\n",
        "print(data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xziCvHeRjvaM",
        "outputId": "3d7cfd68-2090-43fd-8672-35dbecff5059"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1240, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_samples = len(temporal_data)\n",
        "print(n_samples)\n",
        "data = loaded_model.generate(count=n_samples)\n",
        "print(data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09mtQbokk7iI",
        "outputId": "f7244880-7a8e-4933-8e43-67684fbde01a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3477\n",
            "(43070, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import inspect\n",
        "print(inspect.getsource(syn_model.generate))"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Oggs90DmCey",
        "outputId": "19f7cc9c-f736-424a-83f0-ad25210fc61e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    @validate_arguments\n",
            "    def generate(\n",
            "        self,\n",
            "        count: Optional[int] = None,\n",
            "        constraints: Optional[Constraints] = None,\n",
            "        random_state: Optional[int] = None,\n",
            "        **kwargs: Any,\n",
            "    ) -> DataLoader:\n",
            "        \"\"\"Synthetic data generation method.\n",
            "\n",
            "        Args:\n",
            "            count: optional int.\n",
            "                The number of samples to generate. If None, it generated len(reference_dataset) samples.\n",
            "            cond: Optional, Union[pd.DataFrame, pd.Series, np.ndarray].\n",
            "                Optional Generation Conditional. The conditional can be used only if the model was trained using a conditional too.\n",
            "                If provided, it must have `count` length.\n",
            "                Not all models support conditionals. The conditionals can be used in VAEs or GANs to speed-up the generation under some constraints. For model agnostic solutions, check out the `constraints` parameter.\n",
            "            constraints: optional Constraints.\n",
            "                Optional constraints to apply on the generated data. If none, the reference schema constraints are applied. The constraints are model agnostic, and will filter the output of the generative model.\n",
            "                The constraints are a list of rules. Each rule is a tuple of the form (<feature>, <operation>, <value>).\n",
            "\n",
            "                Valid Operations:\n",
            "                    - \"<\", \"lt\" : less than <value>\n",
            "                    - \"<=\", \"le\": less or equal with <value>\n",
            "                    - \">\", \"gt\" : greater than <value>\n",
            "                    - \">=\", \"ge\": greater or equal with <value>\n",
            "                    - \"==\", \"eq\": equal with <value>\n",
            "                    - \"in\": valid for categorical features, and <value> must be array. for example, (\"target\", \"in\", [0, 1])\n",
            "                    - \"dtype\": <value> can be a data type. For example, (\"target\", \"dtype\", \"int\")\n",
            "\n",
            "                Usage example:\n",
            "                    >>> from synthcity.plugins.core.constraints import Constraints\n",
            "                    >>> constraints = Constraints(\n",
            "                    >>>   rules=[\n",
            "                    >>>             (\"InterestingFeature\", \"==\", 0),\n",
            "                    >>>         ]\n",
            "                    >>>     )\n",
            "                    >>>\n",
            "                    >>> syn_data = syn_model.generate(\n",
            "                            count=count,\n",
            "                            constraints=constraints\n",
            "                        ).dataframe()\n",
            "                    >>>\n",
            "                    >>> assert (syn_data[\"InterestingFeature\"] == 0).all()\n",
            "\n",
            "            random_state: optional int.\n",
            "                Optional random seed to use.\n",
            "\n",
            "        Returns:\n",
            "            <count> synthetic samples\n",
            "        \"\"\"\n",
            "        if not self.fitted:\n",
            "            raise RuntimeError(\"Fit the generator first\")\n",
            "\n",
            "        if self._schema is None:\n",
            "            raise RuntimeError(\"Fit the model first\")\n",
            "\n",
            "        if random_state is not None:\n",
            "            enable_reproducible_results(random_state)\n",
            "\n",
            "        has_gen_cond = \"cond\" in kwargs and kwargs[\"cond\"] is not None\n",
            "        if has_gen_cond and not self.expecting_conditional:\n",
            "            raise RuntimeError(\n",
            "                \"Conditional mismatch. Got inference conditional, without any training conditional\"\n",
            "            )\n",
            "\n",
            "        if count is None:\n",
            "            count = self.data_info[\"len\"]\n",
            "\n",
            "        # We use the training schema for the generation\n",
            "        gen_constraints = self.training_schema().as_constraints()\n",
            "        if constraints is not None:\n",
            "            gen_constraints = gen_constraints.extend(constraints)\n",
            "\n",
            "        syn_schema = Schema.from_constraints(gen_constraints)\n",
            "\n",
            "        X_syn = self._generate(count=count, syn_schema=syn_schema, **kwargs)\n",
            "\n",
            "        if X_syn.is_tabular():\n",
            "            if self.compress_dataset:\n",
            "                X_syn = X_syn.decompress(self.compress_context)\n",
            "            if self._data_encoders is not None:\n",
            "                X_syn = X_syn.decode(self._data_encoders)\n",
            "\n",
            "        # The dataset is decompressed here, we can use the public schema\n",
            "        gen_constraints = self.schema().as_constraints()\n",
            "        if constraints is not None:\n",
            "            gen_constraints = gen_constraints.extend(constraints)\n",
            "\n",
            "        if not X_syn.satisfies(gen_constraints) and self.strict:\n",
            "            raise RuntimeError(\n",
            "                f\"Plugin {self.name()} failed to meet the synthetic constraints.\"\n",
            "            )\n",
            "\n",
            "        if self.strict:\n",
            "            X_syn = X_syn.match(gen_constraints)\n",
            "\n",
            "        return X_syn\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_samples = len(temporal_data)\n",
        "print(n_samples)\n",
        "data1 = loaded_model.generate(count=1)\n",
        "data2 = loaded_model.generate(count=10)\n",
        "data3 = loaded_model.generate(count=100)\n",
        "print(data1.shape)\n",
        "print(data2.shape)\n",
        "print(data3.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nu3McdW0or2G",
        "outputId": "11ee9a10-8820-4da8-a77a-305d5ab89e33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3477\n",
            "(16, 10)\n",
            "(134, 10)\n",
            "(1294, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save with automated format\n",
        "import datetime\n",
        "import os\n",
        "# Get the current date and time\n",
        "now = datetime.datetime.now()\n",
        "timestamp = now.strftime(\"%m%d%y-%H%M%S\")  # MMDDYY-HHMMSS format\n",
        "\n",
        "# Define the base directory\n",
        "base_dir = \"/content/drive/Shareddrives/sp_env/synthetic_datasets/TimeGAN/electricity\"  #CHANGE THIS\n",
        "if not os.path.exists(base_dir):\n",
        "    os.makedirs(base_dir)\n",
        "\n",
        "# Construct the filename\n",
        "model_name = type(syn_model).__name__.lower() # Get model name dynamically\n",
        "filename = f\"{timestamp}-{model_name}-n_3000.csv\"\n",
        "filepath = os.path.join(base_dir, filename)\n",
        "\n",
        "# Save the data\n",
        "df_syn = syn_data.dataframe()\n",
        "df_syn.to_csv(filepath, index=False)\n",
        "\n",
        "print(f\"Synthetic data saved to: {filepath}\")"
      ],
      "metadata": {
        "id": "J4rF0HY29o65",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee959a73-2f0d-4d5b-c811-c3352f113f75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synthetic data saved to: /content/drive/Shareddrives/sp_env/synthetic_datasets/TimeGAN/electricity/042625-152713-timeganplugin-n_3000.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "TICnBaoH9r8Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prerequisites"
      ],
      "metadata": {
        "id": "QlHAzxfV9uXf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define selected columns explicitly\n",
        "selected_columns = ['seq_temporal_HUFL', 'seq_temporal_HULL', 'seq_temporal_LUFL', 'seq_temporal_LULL', 'seq_temporal_MUFL', 'seq_temporal_MULL', 'seq_temporal_OT']\n",
        "\n",
        "# Ensure real_data and synthetic_data only contain the selected columns\n",
        "real_data = loader.dataframe()[selected_columns].to_numpy()\n",
        "synthetic_data = syn_data.dataframe()[selected_columns].to_numpy()"
      ],
      "metadata": {
        "id": "zUMHadsq9vw8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Check datasets\n",
        "\n",
        "print(real_data, \"\\n ------------------------------------------------------- \\n\", synthetic_data)\n",
        "print(type(real_data),type(synthetic_data))\n",
        "print(real_data.shape,synthetic_data.shape)\n",
        "\n",
        "\"\"\" TODO\n",
        "[] add adjusting off dataset to fit min length here\n",
        "[] remove min length stuff in helper funcs\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "DumXr_Gg9y6U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "outputId": "06e6d88f-502e-4611-cc9d-22444c455cf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.64238779 0.30271972 0.42980559 ... 0.65984936 0.33017688 0.37748344]\n",
            " [0.61327729 0.41078203 0.42980559 ... 0.62082855 0.4031624  0.393583  ]\n",
            " [0.65695512 0.42700348 0.36400289 ... 0.675646   0.39360371 0.40562914]\n",
            " ...\n",
            " [0.86406245 0.43781779 0.6272138  ... 0.88011299 0.37779167 0.61446676]\n",
            " [0.93042472 0.48107499 0.77624185 ... 0.91636155 0.37779167 0.6626513 ]\n",
            " [0.79124994 0.40537487 0.38588913 ... 0.82715244 0.43487582 0.7309317 ]] \n",
            " ------------------------------------------------------- \n",
            " [[0.67353536 0.32652558 0.43057038 ... 0.83059878 0.33310791 0.42354418]\n",
            " [0.67358549 0.44509754 0.38212669 ... 0.83059413 0.41668498 0.50057416]\n",
            " [0.85121252 0.28399383 0.43061993 ... 0.8305551  0.37194391 0.42362864]\n",
            " ...\n",
            " [0.7319141  0.56629246 0.38196447 ... 0.86278558 0.37179222 0.50062887]\n",
            " [0.67342589 0.44475754 0.38193633 ... 0.79199183 0.33283287 0.50064705]\n",
            " [0.75042885 0.2835606  0.4799513  ... 0.83063244 0.33277079 0.37934677]]\n",
            "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
            "(83448, 7) (42946, 7)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' TODO\\n[] add adjusting off dataset to fit min length here\\n[] remove min length stuff in helper funcs\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate distance metrics"
      ],
      "metadata": {
        "id": "0pU8BORS9vWk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Helper Functions"
      ],
      "metadata": {
        "id": "DVguOJWi-Fos"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import wasserstein_distance, entropy\n",
        "import numpy as np\n",
        "\n",
        "def compute_wasserstein(real_data, synthetic_data, selected_columns):\n",
        "    \"\"\"\n",
        "    Computes Wasserstein Distance between real and synthetic time-series data.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # Ensure both datasets have the same number of samples\n",
        "    min_length = min(len(real_data), len(synthetic_data))\n",
        "    real_trimmed = real_data[:min_length]  # Keep original order (no random sampling)\n",
        "    synthetic_trimmed = synthetic_data[:min_length]  # Match size\n",
        "    print(real_trimmed.shape,synthetic_trimmed.shape)\n",
        "\n",
        "    wasserstein_results = {}\n",
        "\n",
        "    # Compute Wasserstein Distance for each feature\n",
        "    for i, col in enumerate(selected_columns):\n",
        "        w_dist = wasserstein_distance(real_trimmed[:, i], synthetic_trimmed[:, i])\n",
        "        wasserstein_results[col] = w_dist\n",
        "        print(f\"{w_dist}\")\n",
        "\n",
        "    return wasserstein_results\n",
        "\n",
        "def compute_kl_divergence(real_data, synthetic_data, selected_columns, bins=50):\n",
        "    \"\"\"\n",
        "    Computes KL Divergence between real and synthetic time-series data.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # Ensure both datasets have the same number of samples\n",
        "    min_length = min(len(real_data), len(synthetic_data))\n",
        "    real_trimmed = real_data[:min_length]  # Keep original order\n",
        "    synthetic_trimmed = synthetic_data[:min_length]  # Match size\n",
        "\n",
        "    kl_results = {}\n",
        "\n",
        "    for i, col in enumerate(selected_columns):\n",
        "        # Compute histogram-based probability distributions\n",
        "        real_hist, _ = np.histogram(real_trimmed[:, i], bins=bins, density=True)\n",
        "        synth_hist, _ = np.histogram(synthetic_trimmed[:, i], bins=bins, density=True)\n",
        "\n",
        "        # Avoid zero probabilities (KL Divergence is undefined for zero values)\n",
        "        real_hist += 1e-10\n",
        "        synth_hist += 1e-10\n",
        "\n",
        "        # Compute KL Divergence\n",
        "        kl_div = entropy(real_hist, synth_hist)\n",
        "        kl_results[col] = kl_div\n",
        "        print(f\"{kl_div}\")\n",
        "\n",
        "    return kl_results"
      ],
      "metadata": {
        "id": "GjGk3_Zx94Ko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate Metrics"
      ],
      "metadata": {
        "id": "yLnb7Vqg-IG_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute Wasserstein Distance\n",
        "wasserstein_results = compute_wasserstein(real_data, synthetic_data, selected_columns)\n",
        "print(\"Wasserstein Distance Results:\")\n",
        "print(wasserstein_results)\n",
        "\n",
        "# Compute KL Divergence\n",
        "kl_results = compute_kl_divergence(real_data, synthetic_data, selected_columns)\n",
        "print(\"KL Divergence Results:\")\n",
        "print(kl_results)"
      ],
      "metadata": {
        "id": "olm0RYP89-SN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d844293-ba5e-46e4-8d75-ea404265b785"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(42946, 7) (42946, 7)\n",
            "0.05639391359444064\n",
            "0.03758366863714886\n",
            "0.09343952591018045\n",
            "0.05978232416685537\n",
            "0.08429052923356815\n",
            "0.06523718684914633\n",
            "0.053477183409293055\n",
            "Wasserstein Distance Results:\n",
            "{'seq_temporal_HUFL': 0.05639391359444064, 'seq_temporal_HULL': 0.03758366863714886, 'seq_temporal_LUFL': 0.09343952591018045, 'seq_temporal_LULL': 0.05978232416685537, 'seq_temporal_MUFL': 0.08429052923356815, 'seq_temporal_MULL': 0.06523718684914633, 'seq_temporal_OT': 0.053477183409293055}\n",
            "10.40922091460919\n",
            "12.911924636011225\n",
            "12.882915120034097\n",
            "10.578358954241521\n",
            "11.11602725906944\n",
            "14.83792841779404\n",
            "14.23388670843781\n",
            "KL Divergence Results:\n",
            "{'seq_temporal_HUFL': 10.40922091460919, 'seq_temporal_HULL': 12.911924636011225, 'seq_temporal_LUFL': 12.882915120034097, 'seq_temporal_LULL': 10.578358954241521, 'seq_temporal_MUFL': 11.11602725906944, 'seq_temporal_MULL': 14.83792841779404, 'seq_temporal_OT': 14.23388670843781}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM downstream"
      ],
      "metadata": {
        "id": "UpJLIRUZChiz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "real_data = df_scaled_test\n",
        "df_synth = pd.read_csv(\"/content/drive/Shareddrives/sp_env/synthetic_datasets/TimeGAN/electricity/042625-152713-timeganplugin-n_3000.csv\")\n",
        "\n",
        "# 2. Drop the unwanted column\n",
        "real_data = real_data.drop(columns=[\"seq_id\", \"seq_time_id\", \"seq_out_outcome\"], errors=\"ignore\")\n",
        "df_synth = df_synth.drop(columns=[\"seq_id\", \"seq_time_id\", \"seq_out_outcome\"], errors=\"ignore\")"
      ],
      "metadata": {
        "id": "oidw2-H7OeUO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"real_data: {real_data.shape}, synthetic_data: {df_synth.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2V3bCF9WvLsa",
        "outputId": "5b6e8b28-d2ee-4d5c-b2ba-4c3285e9d2a7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "real_data: (3500, 7), synthetic_data: (42946, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ✧.* libraries ✧.*\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error"
      ],
      "metadata": {
        "id": "jBeVAcOyoPDz"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "recheck LSTM notebook for"
      ],
      "metadata": {
        "id": "AqxZ2PLWo9pN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to tensors (float32 for PyTorch)\n",
        "data_real = torch.tensor(real_data.values, dtype=torch.float32)\n",
        "data_synth = torch.tensor(df_synth.values, dtype=torch.float32)\n",
        "\n",
        "# ──────── Sequence builder ───────────\n",
        "def make_sequences(data, seq_len):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - seq_len):\n",
        "        X.append(data[i:i+seq_len])\n",
        "        y.append(data[i+seq_len])\n",
        "    return torch.stack(X), torch.stack(y)\n",
        "\n",
        "SEQ_LEN = sequence_length\n",
        "\n",
        "# Sequences for synthetic (train)\n",
        "X_train, y_train = make_sequences(data_synth, SEQ_LEN)\n",
        "train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=32, shuffle=True)\n",
        "\n",
        "# Sequences for real (test)\n",
        "X_test, y_test = make_sequences(data_real, SEQ_LEN)\n"
      ],
      "metadata": {
        "id": "txcyFCaxoZry"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ✧.* model definition and training ✧.*\n",
        "\n",
        "# ─── Model Definition ──────────────────────────────────────\n",
        "class ShallowLSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size=64):\n",
        "        super().__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
        "        self.linear = nn.Linear(hidden_size, input_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        _, (hn, _) = self.lstm(x)  # hn shape: (1, batch, hidden_size)\n",
        "        out = self.linear(hn.squeeze(0))  # squeeze to (batch, hidden_size)\n",
        "        return out\n",
        "\n",
        "\n",
        "# ─── Model Init ─────────────────────────────────────────────\n",
        "model = ShallowLSTM(input_size=X_train.shape[2], hidden_size=64)\n",
        "\n",
        "# ─── Optimizer & Loss ───────────────────────────────────────\n",
        "loss_fn = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.002)\n",
        "\n",
        "# ─── Training ───────────────────────────────────────────────\n",
        "EPOCHS = 50\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    model.train()\n",
        "    for xb, yb in train_loader:\n",
        "        pred = model(xb)\n",
        "        loss = loss_fn(pred, yb)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # if epoch % 10 == 0 or epoch == 1:\n",
        "    print(f\"Epoch {epoch}: Train MSE = {loss.item():.6f}\")"
      ],
      "metadata": {
        "id": "xb92SGsLojRK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1149581b-4c16-4d45-b746-ded5afdc3933"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train MSE = 0.010538\n",
            "Epoch 2: Train MSE = 0.011449\n",
            "Epoch 3: Train MSE = 0.009600\n",
            "Epoch 4: Train MSE = 0.008025\n",
            "Epoch 5: Train MSE = 0.006897\n",
            "Epoch 6: Train MSE = 0.004260\n",
            "Epoch 7: Train MSE = 0.010280\n",
            "Epoch 8: Train MSE = 0.007981\n",
            "Epoch 9: Train MSE = 0.006957\n",
            "Epoch 10: Train MSE = 0.006598\n",
            "Epoch 11: Train MSE = 0.007770\n",
            "Epoch 12: Train MSE = 0.007722\n",
            "Epoch 13: Train MSE = 0.008693\n",
            "Epoch 14: Train MSE = 0.019445\n",
            "Epoch 15: Train MSE = 0.007985\n",
            "Epoch 16: Train MSE = 0.010235\n",
            "Epoch 17: Train MSE = 0.012293\n",
            "Epoch 18: Train MSE = 0.012160\n",
            "Epoch 19: Train MSE = 0.006056\n",
            "Epoch 20: Train MSE = 0.010880\n",
            "Epoch 21: Train MSE = 0.016894\n",
            "Epoch 22: Train MSE = 0.005700\n",
            "Epoch 23: Train MSE = 0.009019\n",
            "Epoch 24: Train MSE = 0.008562\n",
            "Epoch 25: Train MSE = 0.005061\n",
            "Epoch 26: Train MSE = 0.011120\n",
            "Epoch 27: Train MSE = 0.010888\n",
            "Epoch 28: Train MSE = 0.004685\n",
            "Epoch 29: Train MSE = 0.009019\n",
            "Epoch 30: Train MSE = 0.007307\n",
            "Epoch 31: Train MSE = 0.007836\n",
            "Epoch 32: Train MSE = 0.009567\n",
            "Epoch 33: Train MSE = 0.008518\n",
            "Epoch 34: Train MSE = 0.011183\n",
            "Epoch 35: Train MSE = 0.005502\n",
            "Epoch 36: Train MSE = 0.020464\n",
            "Epoch 37: Train MSE = 0.010194\n",
            "Epoch 38: Train MSE = 0.012038\n",
            "Epoch 39: Train MSE = 0.011336\n",
            "Epoch 40: Train MSE = 0.007530\n",
            "Epoch 41: Train MSE = 0.008229\n",
            "Epoch 42: Train MSE = 0.005283\n",
            "Epoch 43: Train MSE = 0.013963\n",
            "Epoch 44: Train MSE = 0.007406\n",
            "Epoch 45: Train MSE = 0.013473\n",
            "Epoch 46: Train MSE = 0.012308\n",
            "Epoch 47: Train MSE = 0.006351\n",
            "Epoch 48: Train MSE = 0.012584\n",
            "Epoch 49: Train MSE = 0.008167\n",
            "Epoch 50: Train MSE = 0.006705\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ✧.* model evaluation ✧.*\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    preds = model(X_test)\n",
        "    test_mse = loss_fn(preds, y_test).item()\n",
        "    test_mae = mean_absolute_error(y_test.numpy(), preds.numpy())\n",
        "\n",
        "    print(f\"Test MSE: {test_mse:.6f}\")\n",
        "    print(f\"Test MAE: {test_mae:.6f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKR1vr99zp5H",
        "outputId": "ade23cd7-63c2-490f-f908-a39eb7f235e0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test MSE: 0.054216\n",
            "Test MAE: 0.177322\n"
          ]
        }
      ]
    }
  ]
}