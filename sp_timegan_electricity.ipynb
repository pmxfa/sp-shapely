{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "authorship_tag": "ABX9TyNCZ+QIO/4CRjoIBOeAD+kE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pmxfa/sp-shapely/blob/main/sp_timegan_electricity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "oaMLghK_ipz1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "7d174220-2d4d-461b-b83a-897c2beafc27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: synthcity in /usr/local/lib/python3.11/dist-packages (0.2.11)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from synthcity) (8.6.1)\n",
            "Requirement already satisfied: pandas>=2.1 in /usr/local/lib/python3.11/dist-packages (from synthcity) (2.2.2)\n",
            "Requirement already satisfied: torch<2.3,>=2.1 in /usr/local/lib/python3.11/dist-packages (from synthcity) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn>=1.2 in /usr/local/lib/python3.11/dist-packages (from synthcity) (1.6.1)\n",
            "Requirement already satisfied: nflows>=0.14 in /usr/local/lib/python3.11/dist-packages (from synthcity) (0.14)\n",
            "Requirement already satisfied: numpy<2.0,>=1.20 in /usr/local/lib/python3.11/dist-packages (from synthcity) (1.26.4)\n",
            "Requirement already satisfied: lifelines<0.30.0,>=0.29.0 in /usr/local/lib/python3.11/dist-packages (from synthcity) (0.29.0)\n",
            "Requirement already satisfied: opacus>=1.3 in /usr/local/lib/python3.11/dist-packages (from synthcity) (1.5.3)\n",
            "Requirement already satisfied: networkx<3.0,>2.0 in /usr/local/lib/python3.11/dist-packages (from synthcity) (2.8.8)\n",
            "Requirement already satisfied: decaf-synthetic-data>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from synthcity) (0.1.6)\n",
            "Requirement already satisfied: optuna>=3.1 in /usr/local/lib/python3.11/dist-packages (from synthcity) (4.3.0)\n",
            "Requirement already satisfied: shap in /usr/local/lib/python3.11/dist-packages (from synthcity) (0.47.2)\n",
            "Requirement already satisfied: tenacity in /usr/local/lib/python3.11/dist-packages (from synthcity) (9.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from synthcity) (4.67.1)\n",
            "Requirement already satisfied: loguru in /usr/local/lib/python3.11/dist-packages (from synthcity) (0.7.3)\n",
            "Requirement already satisfied: pydantic<2.0 in /usr/local/lib/python3.11/dist-packages (from synthcity) (1.10.22)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from synthcity) (3.1.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from synthcity) (1.14.1)\n",
            "Requirement already satisfied: xgboost<3.0.0 in /usr/local/lib/python3.11/dist-packages (from synthcity) (2.1.4)\n",
            "Requirement already satisfied: geomloss in /usr/local/lib/python3.11/dist-packages (from synthcity) (0.2.6)\n",
            "Requirement already satisfied: pgmpy in /usr/local/lib/python3.11/dist-packages (from synthcity) (1.0.0)\n",
            "Requirement already satisfied: redis in /usr/local/lib/python3.11/dist-packages (from synthcity) (5.2.1)\n",
            "Requirement already satisfied: pycox in /usr/local/lib/python3.11/dist-packages (from synthcity) (0.3.0)\n",
            "Requirement already satisfied: xgbse>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from synthcity) (0.3.3)\n",
            "Requirement already satisfied: pykeops in /usr/local/lib/python3.11/dist-packages (from synthcity) (2.3)\n",
            "Requirement already satisfied: fflows in /usr/local/lib/python3.11/dist-packages (from synthcity) (0.0.3)\n",
            "Requirement already satisfied: monai in /usr/local/lib/python3.11/dist-packages (from synthcity) (1.4.0)\n",
            "Requirement already satisfied: arfpy in /usr/local/lib/python3.11/dist-packages (from synthcity) (0.1.1)\n",
            "Requirement already satisfied: tsai in /usr/local/lib/python3.11/dist-packages (from synthcity) (0.4.0)\n",
            "Requirement already satisfied: be-great>=0.0.5 in /usr/local/lib/python3.11/dist-packages (from synthcity) (0.0.8)\n",
            "Requirement already satisfied: datasets>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from be-great>=0.0.5->synthcity) (3.5.0)\n",
            "Requirement already satisfied: transformers>=4.22.1 in /usr/local/lib/python3.11/dist-packages (from be-great>=0.0.5->synthcity) (4.51.3)\n",
            "Requirement already satisfied: accelerate>=0.20.1 in /usr/local/lib/python3.11/dist-packages (from be-great>=0.0.5->synthcity) (1.5.2)\n",
            "Requirement already satisfied: pytorch-lightning<2.0 in /usr/local/lib/python3.11/dist-packages (from decaf-synthetic-data>=0.1.6->synthcity) (1.9.5)\n",
            "Requirement already satisfied: torchtext>=0.10 in /usr/local/lib/python3.11/dist-packages (from decaf-synthetic-data>=0.1.6->synthcity) (0.17.2)\n",
            "Requirement already satisfied: matplotlib>=3.0 in /usr/local/lib/python3.11/dist-packages (from lifelines<0.30.0,>=0.29.0->synthcity) (3.10.0)\n",
            "Requirement already satisfied: autograd>=1.5 in /usr/local/lib/python3.11/dist-packages (from lifelines<0.30.0,>=0.29.0->synthcity) (1.7.0)\n",
            "Requirement already satisfied: autograd-gamma>=0.3 in /usr/local/lib/python3.11/dist-packages (from lifelines<0.30.0,>=0.29.0->synthcity) (0.5.0)\n",
            "Requirement already satisfied: formulaic>=0.2.2 in /usr/local/lib/python3.11/dist-packages (from lifelines<0.30.0,>=0.29.0->synthcity) (1.1.1)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (from nflows>=0.14->synthcity) (2.18.0)\n",
            "Requirement already satisfied: opt-einsum>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from opacus>=1.3->synthcity) (3.4.0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna>=3.1->synthcity) (1.15.2)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna>=3.1->synthcity) (6.9.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna>=3.1->synthcity) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna>=3.1->synthcity) (2.0.40)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna>=3.1->synthcity) (6.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1->synthcity) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1->synthcity) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1->synthcity) (2025.2)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.0->synthcity) (4.13.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.2->synthcity) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.2->synthcity) (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<2.3,>=2.1->synthcity) (3.18.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch<2.3,>=2.1->synthcity) (1.13.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<2.3,>=2.1->synthcity) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<2.3,>=2.1->synthcity) (2024.12.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch<2.3,>=2.1->synthcity) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch<2.3,>=2.1->synthcity) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch<2.3,>=2.1->synthcity) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/dist-packages (from torch<2.3,>=2.1->synthcity) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch<2.3,>=2.1->synthcity) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch<2.3,>=2.1->synthcity) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch<2.3,>=2.1->synthcity) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch<2.3,>=2.1->synthcity) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch<2.3,>=2.1->synthcity) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.11/dist-packages (from torch<2.3,>=2.1->synthcity) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch<2.3,>=2.1->synthcity) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<2.3,>=2.1->synthcity) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<2.3,>=2.1->synthcity) (12.5.82)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->synthcity) (3.21.0)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.11/dist-packages (from pgmpy->synthcity) (0.14.4)\n",
            "Requirement already satisfied: pyro-ppl in /usr/local/lib/python3.11/dist-packages (from pgmpy->synthcity) (1.9.1)\n",
            "Requirement already satisfied: torchtuples>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from pycox->synthcity) (0.2.2)\n",
            "Requirement already satisfied: feather-format>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pycox->synthcity) (0.4.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from pycox->synthcity) (3.13.0)\n",
            "Requirement already satisfied: numba>=0.44 in /usr/local/lib/python3.11/dist-packages (from pycox->synthcity) (0.60.0)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.11/dist-packages (from pycox->synthcity) (2.32.3)\n",
            "Requirement already satisfied: py7zr>=0.11.3 in /usr/local/lib/python3.11/dist-packages (from pycox->synthcity) (0.22.0)\n",
            "Requirement already satisfied: pybind11 in /usr/local/lib/python3.11/dist-packages (from pykeops->synthcity) (2.13.6)\n",
            "Requirement already satisfied: keopscore==2.3 in /usr/local/lib/python3.11/dist-packages (from pykeops->synthcity) (2.3)\n",
            "Requirement already satisfied: slicer==0.0.8 in /usr/local/lib/python3.11/dist-packages (from shap->synthcity) (0.0.8)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (from tsai->synthcity) (24.1.2)\n",
            "Requirement already satisfied: fastai>=2.7.18 in /usr/local/lib/python3.11/dist-packages (from tsai->synthcity) (2.7.19)\n",
            "Requirement already satisfied: pyts>=0.13.0 in /usr/local/lib/python3.11/dist-packages (from tsai->synthcity) (0.13.0)\n",
            "Requirement already satisfied: imbalanced-learn>=0.12.4 in /usr/local/lib/python3.11/dist-packages (from tsai->synthcity) (0.13.0)\n",
            "Requirement already satisfied: psutil>=6.1.0 in /usr/local/lib/python3.11/dist-packages (from tsai->synthcity) (7.0.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.20.1->be-great>=0.0.5->synthcity) (0.30.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.20.1->be-great>=0.0.5->synthcity) (0.5.3)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna>=3.1->synthcity) (1.1.3)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.5.2->be-great>=0.0.5->synthcity) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.5.2->be-great>=0.0.5->synthcity) (0.3.8)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets>=2.5.2->be-great>=0.0.5->synthcity) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.5.2->be-great>=0.0.5->synthcity) (0.70.16)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.5.2->be-great>=0.0.5->synthcity) (3.11.15)\n",
            "Requirement already satisfied: fastdownload<2,>=0.0.5 in /usr/local/lib/python3.11/dist-packages (from fastai>=2.7.18->tsai->synthcity) (0.0.7)\n",
            "Requirement already satisfied: fastcore<1.8,>=1.5.29 in /usr/local/lib/python3.11/dist-packages (from fastai>=2.7.18->tsai->synthcity) (1.7.29)\n",
            "Requirement already satisfied: torchvision>=0.11 in /usr/local/lib/python3.11/dist-packages (from fastai>=2.7.18->tsai->synthcity) (0.17.2)\n",
            "Requirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.11/dist-packages (from fastai>=2.7.18->tsai->synthcity) (1.0.3)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from fastai>=2.7.18->tsai->synthcity) (11.1.0)\n",
            "Requirement already satisfied: spacy<4 in /usr/local/lib/python3.11/dist-packages (from fastai>=2.7.18->tsai->synthcity) (3.8.5)\n",
            "Requirement already satisfied: interface-meta>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from formulaic>=0.2.2->lifelines<0.30.0,>=0.29.0->synthcity) (1.3.0)\n",
            "Requirement already satisfied: wrapt>=1.0 in /usr/local/lib/python3.11/dist-packages (from formulaic>=0.2.2->lifelines<0.30.0,>=0.29.0->synthcity) (1.17.2)\n",
            "Requirement already satisfied: sklearn-compat<1,>=0.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn>=0.12.4->tsai->synthcity) (0.1.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines<0.30.0,>=0.29.0->synthcity) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines<0.30.0,>=0.29.0->synthcity) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines<0.30.0,>=0.29.0->synthcity) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines<0.30.0,>=0.29.0->synthcity) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines<0.30.0,>=0.29.0->synthcity) (3.2.3)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.44->pycox->synthcity) (0.43.0)\n",
            "Requirement already satisfied: texttable in /usr/local/lib/python3.11/dist-packages (from py7zr>=0.11.3->pycox->synthcity) (1.7.0)\n",
            "Requirement already satisfied: pycryptodomex>=3.16.0 in /usr/local/lib/python3.11/dist-packages (from py7zr>=0.11.3->pycox->synthcity) (3.22.0)\n",
            "Requirement already satisfied: pyzstd>=0.15.9 in /usr/local/lib/python3.11/dist-packages (from py7zr>=0.11.3->pycox->synthcity) (0.16.2)\n",
            "Requirement already satisfied: pyppmd<1.2.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from py7zr>=0.11.3->pycox->synthcity) (1.1.1)\n",
            "Requirement already satisfied: pybcj<1.1.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from py7zr>=0.11.3->pycox->synthcity) (1.0.3)\n",
            "Requirement already satisfied: multivolumefile>=0.2.3 in /usr/local/lib/python3.11/dist-packages (from py7zr>=0.11.3->pycox->synthcity) (0.2.3)\n",
            "Requirement already satisfied: inflate64<1.1.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from py7zr>=0.11.3->pycox->synthcity) (1.0.1)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from py7zr>=0.11.3->pycox->synthcity) (1.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=2.1->synthcity) (1.17.0)\n",
            "Requirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning<2.0->decaf-synthetic-data>=0.1.6->synthcity) (1.7.1)\n",
            "Requirement already satisfied: lightning-utilities>=0.6.0.post0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning<2.0->decaf-synthetic-data>=0.1.6->synthcity) (0.14.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22.0->pycox->synthcity) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22.0->pycox->synthcity) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22.0->pycox->synthcity) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22.0->pycox->synthcity) (2025.1.31)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna>=3.1->synthcity) (3.2.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.22.1->be-great>=0.0.5->synthcity) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.22.1->be-great>=0.0.5->synthcity) (0.21.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<2.3,>=2.1->synthcity) (3.0.2)\n",
            "Requirement already satisfied: pyro-api>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from pyro-ppl->pgmpy->synthcity) (0.1.2)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.11/dist-packages (from statsmodels->pgmpy->synthcity) (1.0.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch<2.3,>=2.1->synthcity) (1.3.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard->nflows>=0.14->synthcity) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard->nflows>=0.14->synthcity) (1.71.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard->nflows>=0.14->synthcity) (3.8)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard->nflows>=0.14->synthcity) (5.29.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->nflows>=0.14->synthcity) (75.2.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->nflows>=0.14->synthcity) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard->nflows>=0.14->synthcity) (3.1.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.5.2->be-great>=0.0.5->synthcity) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.5.2->be-great>=0.0.5->synthcity) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.5.2->be-great>=0.0.5->synthcity) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.5.2->be-great>=0.0.5->synthcity) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.5.2->be-great>=0.0.5->synthcity) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.5.2->be-great>=0.0.5->synthcity) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.5.2->be-great>=0.0.5->synthcity) (1.20.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai>=2.7.18->tsai->synthcity) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai>=2.7.18->tsai->synthcity) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai>=2.7.18->tsai->synthcity) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai>=2.7.18->tsai->synthcity) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai>=2.7.18->tsai->synthcity) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai>=2.7.18->tsai->synthcity) (8.3.4)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai>=2.7.18->tsai->synthcity) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai>=2.7.18->tsai->synthcity) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai>=2.7.18->tsai->synthcity) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai>=2.7.18->tsai->synthcity) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai>=2.7.18->tsai->synthcity) (0.15.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai>=2.7.18->tsai->synthcity) (3.5.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<4->fastai>=2.7.18->tsai->synthcity) (1.3.0)\n",
            "Requirement already satisfied: blis<1.3.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy<4->fastai>=2.7.18->tsai->synthcity) (1.2.1)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy<4->fastai>=2.7.18->tsai->synthcity) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<4->fastai>=2.7.18->tsai->synthcity) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<4->fastai>=2.7.18->tsai->synthcity) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<4->fastai>=2.7.18->tsai->synthcity) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<4->fastai>=2.7.18->tsai->synthcity) (0.21.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<4->fastai>=2.7.18->tsai->synthcity) (7.1.0)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<4->fastai>=2.7.18->tsai->synthcity) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4->fastai>=2.7.18->tsai->synthcity) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4->fastai>=2.7.18->tsai->synthcity) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4->fastai>=2.7.18->tsai->synthcity) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install synthcity"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "NcwQ6Yo09JC8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import sys\n",
        "import warnings\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "import synthcity.logger as log\n",
        "from synthcity.plugins import Plugins\n",
        "from synthcity.plugins.core.dataloader import TimeSeriesDataLoader\n",
        "\n",
        "log.add(sink=sys.stderr, level=\"INFO\")"
      ],
      "metadata": {
        "id": "kfDi7FQF9LIv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbf8eacd-99c3-4e92-9ae0-1f83d58ff2bb",
        "collapsed": true
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "[KeOps] Compiling cuda jit compiler engine ... OK\n",
            "[pyKeOps] Compiling nvrtc binder for python ... OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/drive/Shareddrives/sp_env/datasets/Electricity Transformer Dataset (ETDataset)/ETTh1.csv\"\n",
        "\n",
        "df = pd.read_csv(file_path)\n",
        "print(df.head())\n",
        "print(df.info())\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "id": "DCLsmN-F9NGv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "921d6483-b8fd-4582-f32e-d707cb0147a0",
        "collapsed": true
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                  date   HUFL   HULL   MUFL   MULL   LUFL   LULL         OT\n",
            "0  2016-07-01 00:00:00  5.827  2.009  1.599  0.462  4.203  1.340  30.531000\n",
            "1  2016-07-01 01:00:00  5.693  2.076  1.492  0.426  4.142  1.371  27.787001\n",
            "2  2016-07-01 02:00:00  5.157  1.741  1.279  0.355  3.777  1.218  27.787001\n",
            "3  2016-07-01 03:00:00  5.090  1.942  1.279  0.391  3.807  1.279  25.044001\n",
            "4  2016-07-01 04:00:00  5.358  1.942  1.492  0.462  3.868  1.279  21.948000\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 17420 entries, 0 to 17419\n",
            "Data columns (total 8 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   date    17420 non-null  object \n",
            " 1   HUFL    17420 non-null  float64\n",
            " 2   HULL    17420 non-null  float64\n",
            " 3   MUFL    17420 non-null  float64\n",
            " 4   MULL    17420 non-null  float64\n",
            " 5   LUFL    17420 non-null  float64\n",
            " 6   LULL    17420 non-null  float64\n",
            " 7   OT      17420 non-null  float64\n",
            "dtypes: float64(7), object(1)\n",
            "memory usage: 1.1+ MB\n",
            "None\n",
            "date    0\n",
            "HUFL    0\n",
            "HULL    0\n",
            "MUFL    0\n",
            "MULL    0\n",
            "LUFL    0\n",
            "LULL    0\n",
            "OT      0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert 'date' to datetime, set as index, and sort\n",
        "df['date'] = pd.to_datetime(df['date'])\n",
        "df.set_index('date', inplace=True)\n",
        "df.sort_index(inplace=True)\n",
        "\n",
        "# Keep the latest 5000 rows\n",
        "df_latest = df.tail(5000)\n",
        "\n",
        "# Train-test split: 70% for training (for TimeGAN), 30% for testing (TSTR)\n",
        "train_size = int(0.7 * len(df_latest))\n",
        "df_train = df_latest.iloc[:train_size]\n",
        "df_test = df_latest.iloc[train_size:]  # use later for LSTM-TSTR\n",
        "\n",
        "# Normalize the data\n",
        "scaler = MinMaxScaler()\n",
        "scaled_train = scaler.fit_transform(df_train)\n",
        "df_scaled_train = pd.DataFrame(scaled_train, columns=df_train.columns, index=df_train.index)\n",
        "scaled_test = scaler.transform(df_test)\n",
        "df_scaled_test = pd.DataFrame(scaled_train, columns=df_train.columns, index=df_train.index)\n",
        "\n",
        "# Sequence length for time-series data (dataset = hourly; 24 hours)\n",
        "sequence_length = 24\n",
        "temporal_data = []\n",
        "observation_times = []\n",
        "\n",
        "# Generate sequences from df_scaled_train only\n",
        "for start in range(len(df_scaled_train) - sequence_length + 1):\n",
        "    sequence = df_scaled_train.iloc[start:start + sequence_length].reset_index(drop=True)\n",
        "    temporal_data.append(sequence)\n",
        "    observation_times.append(list(range(sequence_length)))  # relative time within the window\n",
        "\n",
        "# Dummy outcome for TimeGAN (can be used in DataLoader)\n",
        "dummy_outcome = pd.DataFrame(np.zeros(len(temporal_data)), columns=[\"outcome\"])\n",
        "\n",
        "# Create DataLoader for TimeGAN\n",
        "loader = TimeSeriesDataLoader(\n",
        "    temporal_data=temporal_data,\n",
        "    observation_times=observation_times,\n",
        "    static_data=None,\n",
        "    outcome=dummy_outcome,\n",
        ")\n",
        "\n",
        "# Print the loader info\n",
        "print(f\"TimeSeriesDataLoader created with {len(temporal_data)} sequences\")\n"
      ],
      "metadata": {
        "id": "siWRiBtn9O0V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa22e960-55a7-4fe1-af27-2af0d6fdcfda"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TimeSeriesDataLoader created with 3477 sequences\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(df_train))\n",
        "print(loader.dataframe())"
      ],
      "metadata": {
        "id": "FmZe08FM9Rd0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56f5b879-1d37-445c-c2fd-c590e15a8ca8",
        "collapsed": true
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3500\n",
            "       seq_id  seq_time_id  seq_temporal_HUFL  seq_temporal_HULL  \\\n",
            "0           0            0           0.642388           0.302720   \n",
            "1           0            1           0.613277           0.410782   \n",
            "2           0            2           0.656955           0.427003   \n",
            "3           0            3           0.647244           0.378339   \n",
            "4           0            4           0.711963           0.416189   \n",
            "...       ...          ...                ...                ...   \n",
            "83443    3476           19           0.841426           0.362118   \n",
            "83444    3476           20           0.865681           0.362118   \n",
            "83445    3476           21           0.864062           0.437818   \n",
            "83446    3476           22           0.930425           0.481075   \n",
            "83447    3476           23           0.791250           0.405375   \n",
            "\n",
            "       seq_temporal_LUFL  seq_temporal_LULL  seq_temporal_MUFL  \\\n",
            "0               0.429806           0.589646           0.659849   \n",
            "1               0.429806           0.666667           0.620829   \n",
            "2               0.364003           0.525673           0.675646   \n",
            "3               0.372786           0.525673           0.680301   \n",
            "4               0.425486           0.589646           0.741631   \n",
            "...                  ...                ...                ...   \n",
            "83443           0.605184           0.627946           0.841092   \n",
            "83444           0.605184           0.500000           0.878256   \n",
            "83445           0.627214           0.576599           0.880113   \n",
            "83446           0.776242           0.563973           0.916362   \n",
            "83447           0.385889           0.486953           0.827152   \n",
            "\n",
            "       seq_temporal_MULL  seq_temporal_OT  seq_out_outcome  \n",
            "0               0.330177         0.377483              0.0  \n",
            "1               0.403162         0.393583              0.0  \n",
            "2               0.393604         0.405629              0.0  \n",
            "3               0.374576         0.413622              0.0  \n",
            "4               0.419064         0.409625              0.0  \n",
            "...                  ...              ...              ...  \n",
            "83443           0.317492         0.642555              0.0  \n",
            "83444           0.301590         0.586321              0.0  \n",
            "83445           0.377792         0.614467              0.0  \n",
            "83446           0.377792         0.662651              0.0  \n",
            "83447           0.434876         0.730932              0.0  \n",
            "\n",
            "[83448 rows x 10 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hparams = {\n",
        "          \"mode\": \"LSTM\", # default mode = RNN\n",
        "}\n",
        "\n",
        "# Load TimeGAN with custom parameters\n",
        "syn_model = Plugins().get(\"timegan\", **hparams)"
      ],
      "metadata": {
        "id": "oYqRdbxl9W74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d49c7204-cd8b-4b7a-dbb9-fbc9523debf0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2025-04-26T12:35:18.790696+0000][1314][CRITICAL] module disabled: /usr/local/lib/python3.11/dist-packages/synthcity/plugins/generic/plugin_goggle.py\n",
            "[2025-04-26T12:35:18.790696+0000][1314][CRITICAL] module disabled: /usr/local/lib/python3.11/dist-packages/synthcity/plugins/generic/plugin_goggle.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print all parameters of initialized model\n",
        "for attr in dir(syn_model):\n",
        "    if not attr.startswith(\"_\") and not callable(getattr(syn_model, attr)):\n",
        "        print(f\"{attr}: {getattr(syn_model, attr)}\")"
      ],
      "metadata": {
        "id": "y9ZVw8pT9Y_Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99608720-a947-4e58-c79d-86a19f8a46bc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch_size: 64\n",
            "class_name: TimeGANPlugin\n",
            "clipping_value: 0\n",
            "compress_dataset: False\n",
            "dataloader_sampling_strategy: imbalanced_time_censoring\n",
            "device: cuda\n",
            "discriminator_batch_norm: False\n",
            "discriminator_dropout: 0.1\n",
            "discriminator_loss: None\n",
            "discriminator_lr: 0.001\n",
            "discriminator_n_iter: 1\n",
            "discriminator_n_layers_hidden: 3\n",
            "discriminator_n_units_hidden: 300\n",
            "discriminator_nonlin: leaky_relu\n",
            "discriminator_weight_decay: 0.001\n",
            "embedding_penalty: 10\n",
            "encoder: None\n",
            "encoder_max_clusters: 20\n",
            "expecting_conditional: False\n",
            "fitted: False\n",
            "gamma_penalty: 1\n",
            "generator_batch_norm: False\n",
            "generator_dropout: 0.01\n",
            "generator_loss: None\n",
            "generator_lr: 0.001\n",
            "generator_n_layers_hidden: 2\n",
            "generator_n_units_hidden: 150\n",
            "generator_nonlin: leaky_relu\n",
            "generator_nonlin_out_continuous: tanh\n",
            "generator_nonlin_out_discrete: softmax\n",
            "generator_residual: True\n",
            "generator_weight_decay: 0.001\n",
            "mode: LSTM\n",
            "module_name: synthcity.plugins.time_series.plugin_timegan\n",
            "module_relative_path: ../time_series/plugin_timegan.py\n",
            "moments_penalty: 100\n",
            "n_iter: 1000\n",
            "n_iter_print: 10\n",
            "outcome_encoder: TabularEncoder(cat_encoder_params={'handle_unknown': 'ignore',\n",
            "                                   'sparse_output': False},\n",
            "               categorical_encoder='onehot',\n",
            "               cont_encoder_params={'n_components': 20},\n",
            "               continuous_encoder='bayesian_gmm', max_clusters=20)\n",
            "random_state: 0\n",
            "sampling_patience: 500\n",
            "sampling_strategy: marginal\n",
            "strict: True\n",
            "use_horizon_condition: True\n",
            "workspace: workspace\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## fitting the model"
      ],
      "metadata": {
        "id": "IKG0O5Pg9hpG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(loader.shape)"
      ],
      "metadata": {
        "id": "THzKqhIFcWlG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Train the model\n",
        "syn_model.fit(loader)"
      ],
      "metadata": {
        "id": "-BKXe4G19l_8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4c855a1-4ce3-44c9-eb7c-07ddd0ec30e4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [2:02:26<00:00,  7.35s/it]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<synthcity.plugins.time_series.plugin_timegan.TimeGANPlugin at 0x787b51703a90>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "saved_model = syn_model.save()"
      ],
      "metadata": {
        "id": "MMIE6K28AavA"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from synthcity.utils.serialization import save_to_file, load_from_file\n",
        "\n",
        "# Save model to drive\n",
        "# save_to_file('/content/drive/Shareddrives/sp_env/test_model.pkl', syn_model)\n",
        "save_to_file('/content/drive/Shareddrives/sp_env/saved_models/GAN_Electricity.pkl', syn_model)\n",
        "\n",
        "# Load the model\n",
        "# loaded_model = load_from_file('/content/drive/Shareddrives/sp_env/test_model.pkl')"
      ],
      "metadata": {
        "id": "GXR9yPgyDsfe"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_samples = len(temporal_data)\n",
        "syn_data = syn_model.generate(count=n_samples)\n",
        "print(data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xziCvHeRjvaM",
        "outputId": "3d7cfd68-2090-43fd-8672-35dbecff5059"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1240, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_samples = len(temporal_data)\n",
        "print(n_samples)\n",
        "data = loaded_model.generate(count=n_samples)\n",
        "print(data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09mtQbokk7iI",
        "outputId": "f7244880-7a8e-4933-8e43-67684fbde01a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3477\n",
            "(43070, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import inspect\n",
        "print(inspect.getsource(syn_model.generate))"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Oggs90DmCey",
        "outputId": "19f7cc9c-f736-424a-83f0-ad25210fc61e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    @validate_arguments\n",
            "    def generate(\n",
            "        self,\n",
            "        count: Optional[int] = None,\n",
            "        constraints: Optional[Constraints] = None,\n",
            "        random_state: Optional[int] = None,\n",
            "        **kwargs: Any,\n",
            "    ) -> DataLoader:\n",
            "        \"\"\"Synthetic data generation method.\n",
            "\n",
            "        Args:\n",
            "            count: optional int.\n",
            "                The number of samples to generate. If None, it generated len(reference_dataset) samples.\n",
            "            cond: Optional, Union[pd.DataFrame, pd.Series, np.ndarray].\n",
            "                Optional Generation Conditional. The conditional can be used only if the model was trained using a conditional too.\n",
            "                If provided, it must have `count` length.\n",
            "                Not all models support conditionals. The conditionals can be used in VAEs or GANs to speed-up the generation under some constraints. For model agnostic solutions, check out the `constraints` parameter.\n",
            "            constraints: optional Constraints.\n",
            "                Optional constraints to apply on the generated data. If none, the reference schema constraints are applied. The constraints are model agnostic, and will filter the output of the generative model.\n",
            "                The constraints are a list of rules. Each rule is a tuple of the form (<feature>, <operation>, <value>).\n",
            "\n",
            "                Valid Operations:\n",
            "                    - \"<\", \"lt\" : less than <value>\n",
            "                    - \"<=\", \"le\": less or equal with <value>\n",
            "                    - \">\", \"gt\" : greater than <value>\n",
            "                    - \">=\", \"ge\": greater or equal with <value>\n",
            "                    - \"==\", \"eq\": equal with <value>\n",
            "                    - \"in\": valid for categorical features, and <value> must be array. for example, (\"target\", \"in\", [0, 1])\n",
            "                    - \"dtype\": <value> can be a data type. For example, (\"target\", \"dtype\", \"int\")\n",
            "\n",
            "                Usage example:\n",
            "                    >>> from synthcity.plugins.core.constraints import Constraints\n",
            "                    >>> constraints = Constraints(\n",
            "                    >>>   rules=[\n",
            "                    >>>             (\"InterestingFeature\", \"==\", 0),\n",
            "                    >>>         ]\n",
            "                    >>>     )\n",
            "                    >>>\n",
            "                    >>> syn_data = syn_model.generate(\n",
            "                            count=count,\n",
            "                            constraints=constraints\n",
            "                        ).dataframe()\n",
            "                    >>>\n",
            "                    >>> assert (syn_data[\"InterestingFeature\"] == 0).all()\n",
            "\n",
            "            random_state: optional int.\n",
            "                Optional random seed to use.\n",
            "\n",
            "        Returns:\n",
            "            <count> synthetic samples\n",
            "        \"\"\"\n",
            "        if not self.fitted:\n",
            "            raise RuntimeError(\"Fit the generator first\")\n",
            "\n",
            "        if self._schema is None:\n",
            "            raise RuntimeError(\"Fit the model first\")\n",
            "\n",
            "        if random_state is not None:\n",
            "            enable_reproducible_results(random_state)\n",
            "\n",
            "        has_gen_cond = \"cond\" in kwargs and kwargs[\"cond\"] is not None\n",
            "        if has_gen_cond and not self.expecting_conditional:\n",
            "            raise RuntimeError(\n",
            "                \"Conditional mismatch. Got inference conditional, without any training conditional\"\n",
            "            )\n",
            "\n",
            "        if count is None:\n",
            "            count = self.data_info[\"len\"]\n",
            "\n",
            "        # We use the training schema for the generation\n",
            "        gen_constraints = self.training_schema().as_constraints()\n",
            "        if constraints is not None:\n",
            "            gen_constraints = gen_constraints.extend(constraints)\n",
            "\n",
            "        syn_schema = Schema.from_constraints(gen_constraints)\n",
            "\n",
            "        X_syn = self._generate(count=count, syn_schema=syn_schema, **kwargs)\n",
            "\n",
            "        if X_syn.is_tabular():\n",
            "            if self.compress_dataset:\n",
            "                X_syn = X_syn.decompress(self.compress_context)\n",
            "            if self._data_encoders is not None:\n",
            "                X_syn = X_syn.decode(self._data_encoders)\n",
            "\n",
            "        # The dataset is decompressed here, we can use the public schema\n",
            "        gen_constraints = self.schema().as_constraints()\n",
            "        if constraints is not None:\n",
            "            gen_constraints = gen_constraints.extend(constraints)\n",
            "\n",
            "        if not X_syn.satisfies(gen_constraints) and self.strict:\n",
            "            raise RuntimeError(\n",
            "                f\"Plugin {self.name()} failed to meet the synthetic constraints.\"\n",
            "            )\n",
            "\n",
            "        if self.strict:\n",
            "            X_syn = X_syn.match(gen_constraints)\n",
            "\n",
            "        return X_syn\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_samples = len(temporal_data)\n",
        "print(n_samples)\n",
        "data1 = loaded_model.generate(count=1)\n",
        "data2 = loaded_model.generate(count=10)\n",
        "data3 = loaded_model.generate(count=100)\n",
        "print(data1.shape)\n",
        "print(data2.shape)\n",
        "print(data3.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nu3McdW0or2G",
        "outputId": "11ee9a10-8820-4da8-a77a-305d5ab89e33"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3477\n",
            "(16, 10)\n",
            "(134, 10)\n",
            "(1294, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save with automated format\n",
        "import datetime\n",
        "import os\n",
        "# Get the current date and time\n",
        "now = datetime.datetime.now()\n",
        "timestamp = now.strftime(\"%m%d%y-%H%M%S\")  # MMDDYY-HHMMSS format\n",
        "\n",
        "# Define the base directory\n",
        "base_dir = \"/content/drive/Shareddrives/sp_env/synthetic_datasets/TimeGAN/electricity\"  #CHANGE THIS\n",
        "if not os.path.exists(base_dir):\n",
        "    os.makedirs(base_dir)\n",
        "\n",
        "# Construct the filename\n",
        "model_name = type(syn_model).__name__.lower() # Get model name dynamically\n",
        "filename = f\"{timestamp}-{model_name}-n_3000.csv\"\n",
        "filepath = os.path.join(base_dir, filename)\n",
        "\n",
        "# Save the data\n",
        "df_syn = syn_data.dataframe()\n",
        "df_syn.to_csv(filepath, index=False)\n",
        "\n",
        "print(f\"Synthetic data saved to: {filepath}\")"
      ],
      "metadata": {
        "id": "J4rF0HY29o65",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee959a73-2f0d-4d5b-c811-c3352f113f75"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synthetic data saved to: /content/drive/Shareddrives/sp_env/synthetic_datasets/TimeGAN/electricity/042625-152713-timeganplugin-n_3000.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "TICnBaoH9r8Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prerequisites"
      ],
      "metadata": {
        "id": "QlHAzxfV9uXf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define selected columns explicitly\n",
        "selected_columns = ['seq_temporal_HUFL', 'seq_temporal_HULL', 'seq_temporal_LUFL', 'seq_temporal_LULL', 'seq_temporal_MUFL', 'seq_temporal_MULL', 'seq_temporal_OT']\n",
        "\n",
        "# Ensure real_data and synthetic_data only contain the selected columns\n",
        "real_data = loader.dataframe()[selected_columns].to_numpy()\n",
        "synthetic_data = syn_data.dataframe()[selected_columns].to_numpy()"
      ],
      "metadata": {
        "id": "zUMHadsq9vw8"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Check datasets\n",
        "\n",
        "print(real_data, \"\\n ------------------------------------------------------- \\n\", synthetic_data)\n",
        "print(type(real_data),type(synthetic_data))\n",
        "print(real_data.shape,synthetic_data.shape)\n",
        "\n",
        "\"\"\" TODO\n",
        "[] add adjusting off dataset to fit min length here\n",
        "[] remove min length stuff in helper funcs\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "DumXr_Gg9y6U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "outputId": "06e6d88f-502e-4611-cc9d-22444c455cf3"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.64238779 0.30271972 0.42980559 ... 0.65984936 0.33017688 0.37748344]\n",
            " [0.61327729 0.41078203 0.42980559 ... 0.62082855 0.4031624  0.393583  ]\n",
            " [0.65695512 0.42700348 0.36400289 ... 0.675646   0.39360371 0.40562914]\n",
            " ...\n",
            " [0.86406245 0.43781779 0.6272138  ... 0.88011299 0.37779167 0.61446676]\n",
            " [0.93042472 0.48107499 0.77624185 ... 0.91636155 0.37779167 0.6626513 ]\n",
            " [0.79124994 0.40537487 0.38588913 ... 0.82715244 0.43487582 0.7309317 ]] \n",
            " ------------------------------------------------------- \n",
            " [[0.67353536 0.32652558 0.43057038 ... 0.83059878 0.33310791 0.42354418]\n",
            " [0.67358549 0.44509754 0.38212669 ... 0.83059413 0.41668498 0.50057416]\n",
            " [0.85121252 0.28399383 0.43061993 ... 0.8305551  0.37194391 0.42362864]\n",
            " ...\n",
            " [0.7319141  0.56629246 0.38196447 ... 0.86278558 0.37179222 0.50062887]\n",
            " [0.67342589 0.44475754 0.38193633 ... 0.79199183 0.33283287 0.50064705]\n",
            " [0.75042885 0.2835606  0.4799513  ... 0.83063244 0.33277079 0.37934677]]\n",
            "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
            "(83448, 7) (42946, 7)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' TODO\\n[] add adjusting off dataset to fit min length here\\n[] remove min length stuff in helper funcs\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate distance metrics"
      ],
      "metadata": {
        "id": "0pU8BORS9vWk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Helper Functions"
      ],
      "metadata": {
        "id": "DVguOJWi-Fos"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import wasserstein_distance, entropy\n",
        "import numpy as np\n",
        "\n",
        "def compute_wasserstein(real_data, synthetic_data, selected_columns):\n",
        "    \"\"\"\n",
        "    Computes Wasserstein Distance between real and synthetic time-series data.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # Ensure both datasets have the same number of samples\n",
        "    min_length = min(len(real_data), len(synthetic_data))\n",
        "    real_trimmed = real_data[:min_length]  # Keep original order (no random sampling)\n",
        "    synthetic_trimmed = synthetic_data[:min_length]  # Match size\n",
        "    print(real_trimmed.shape,synthetic_trimmed.shape)\n",
        "\n",
        "    wasserstein_results = {}\n",
        "\n",
        "    # Compute Wasserstein Distance for each feature\n",
        "    for i, col in enumerate(selected_columns):\n",
        "        w_dist = wasserstein_distance(real_trimmed[:, i], synthetic_trimmed[:, i])\n",
        "        wasserstein_results[col] = w_dist\n",
        "        print(f\"{w_dist}\")\n",
        "\n",
        "    return wasserstein_results\n",
        "\n",
        "def compute_kl_divergence(real_data, synthetic_data, selected_columns, bins=50):\n",
        "    \"\"\"\n",
        "    Computes KL Divergence between real and synthetic time-series data.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # Ensure both datasets have the same number of samples\n",
        "    min_length = min(len(real_data), len(synthetic_data))\n",
        "    real_trimmed = real_data[:min_length]  # Keep original order\n",
        "    synthetic_trimmed = synthetic_data[:min_length]  # Match size\n",
        "\n",
        "    kl_results = {}\n",
        "\n",
        "    for i, col in enumerate(selected_columns):\n",
        "        # Compute histogram-based probability distributions\n",
        "        real_hist, _ = np.histogram(real_trimmed[:, i], bins=bins, density=True)\n",
        "        synth_hist, _ = np.histogram(synthetic_trimmed[:, i], bins=bins, density=True)\n",
        "\n",
        "        # Avoid zero probabilities (KL Divergence is undefined for zero values)\n",
        "        real_hist += 1e-10\n",
        "        synth_hist += 1e-10\n",
        "\n",
        "        # Compute KL Divergence\n",
        "        kl_div = entropy(real_hist, synth_hist)\n",
        "        kl_results[col] = kl_div\n",
        "        print(f\"{kl_div}\")\n",
        "\n",
        "    return kl_results"
      ],
      "metadata": {
        "id": "GjGk3_Zx94Ko"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate Metrics"
      ],
      "metadata": {
        "id": "yLnb7Vqg-IG_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute Wasserstein Distance\n",
        "wasserstein_results = compute_wasserstein(real_data, synthetic_data, selected_columns)\n",
        "print(\"Wasserstein Distance Results:\")\n",
        "print(wasserstein_results)\n",
        "\n",
        "# Compute KL Divergence\n",
        "kl_results = compute_kl_divergence(real_data, synthetic_data, selected_columns)\n",
        "print(\"KL Divergence Results:\")\n",
        "print(kl_results)"
      ],
      "metadata": {
        "id": "olm0RYP89-SN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d844293-ba5e-46e4-8d75-ea404265b785"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(42946, 7) (42946, 7)\n",
            "0.05639391359444064\n",
            "0.03758366863714886\n",
            "0.09343952591018045\n",
            "0.05978232416685537\n",
            "0.08429052923356815\n",
            "0.06523718684914633\n",
            "0.053477183409293055\n",
            "Wasserstein Distance Results:\n",
            "{'seq_temporal_HUFL': 0.05639391359444064, 'seq_temporal_HULL': 0.03758366863714886, 'seq_temporal_LUFL': 0.09343952591018045, 'seq_temporal_LULL': 0.05978232416685537, 'seq_temporal_MUFL': 0.08429052923356815, 'seq_temporal_MULL': 0.06523718684914633, 'seq_temporal_OT': 0.053477183409293055}\n",
            "10.40922091460919\n",
            "12.911924636011225\n",
            "12.882915120034097\n",
            "10.578358954241521\n",
            "11.11602725906944\n",
            "14.83792841779404\n",
            "14.23388670843781\n",
            "KL Divergence Results:\n",
            "{'seq_temporal_HUFL': 10.40922091460919, 'seq_temporal_HULL': 12.911924636011225, 'seq_temporal_LUFL': 12.882915120034097, 'seq_temporal_LULL': 10.578358954241521, 'seq_temporal_MUFL': 11.11602725906944, 'seq_temporal_MULL': 14.83792841779404, 'seq_temporal_OT': 14.23388670843781}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM downstream"
      ],
      "metadata": {
        "id": "UpJLIRUZChiz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "real_data = loader.dataframe()\n",
        "\n",
        "# 2. Drop the unwanted column\n",
        "real_data = real_data.drop(columns=[\"seq_id\", \"seq_time_id\", \"seq_out_outcome\"], errors=\"ignore\")\n",
        "df_synth = df_synth.drop(columns=[\"seq_id\", \"seq_time_id\", \"seq_out_outcome\"], errors=\"ignore\")"
      ],
      "metadata": {
        "id": "oidw2-H7OeUO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "30303f0c-2475-4f44-b487-7fc00fcd46fc"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df_synth' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-a64ef847bb23>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# 2. Drop the unwanted column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mreal_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreal_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"seq_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"seq_time_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"seq_out_outcome\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdf_synth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_synth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"seq_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"seq_time_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"seq_out_outcome\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'df_synth' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "BFHbRznzoYj_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ✧.* libraries ✧.*\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "metadata": {
        "id": "jBeVAcOyoPDz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "recheck LSTM notebook for"
      ],
      "metadata": {
        "id": "AqxZ2PLWo9pN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ──────── Load synthetic training data ────────\n",
        "\n",
        "df_synth = pd.read_csv(\"/content/drive/Shareddrives/sp_env/synthetic_datasets/TimeGAN/electricity/041725-104510-timeganplugin-n_3000.csv\")\n",
        "scaler = MinMaxScaler()\n",
        "data_synth_scaled = scaler.fit_transform(df_synth.values)\n",
        "data_synth = torch.tensor(data_synth_scaled, dtype=torch.float32)\n",
        "\n",
        "# ──────── Load real held-out test data (same columns, same scale) ────────\n",
        "df_real_test = real_data\n",
        "data_real_scaled = scaler.transform(df_real_test.values)  # Use SAME scaler\n",
        "data_real = torch.tensor(data_real_scaled, dtype=torch.float32)\n",
        "\n",
        "# ──────── Sequence builder ───────────\n",
        "def make_sequences(data, seq_len):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - seq_len):\n",
        "        X.append(data[i:i+seq_len])\n",
        "        y.append(data[i+seq_len])\n",
        "    return torch.stack(X), torch.stack(y)\n",
        "\n",
        "SEQ_LEN = sequence_length\n",
        "\n",
        "# Sequences for synthetic (train)\n",
        "X_train, y_train = make_sequences(data_synth, SEQ_LEN)\n",
        "train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=32, shuffle=True)\n",
        "\n",
        "# Sequences for real (test)\n",
        "X_test, y_test = make_sequences(data_real, SEQ_LEN)\n"
      ],
      "metadata": {
        "id": "txcyFCaxoZry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ✧.* model definition and training ✧.*\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "\n",
        "# ─── Model Definition ──────────────────────────────────────\n",
        "class ShallowLSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size=32):\n",
        "        super().__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
        "        self.linear = nn.Linear(hidden_size, input_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        _, (hn, _) = self.lstm(x)  # hn shape: (1, batch, hidden_size)\n",
        "        out = self.linear(hn.squeeze(0))  # squeeze to (batch, hidden_size)\n",
        "        return out\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Based on a study by Deswal and Kumar(2024), they indicated the following\n",
        "hyperparameters to be the best case for the dataset in their study (stock price).\n",
        "\n",
        "epoch = 200\n",
        "batch_size = 32\n",
        "neurons = 512\n",
        "learning_rate = 0.002\n",
        "dropout = 0.01\n",
        "\n",
        "*did not use yet due to long training time\n",
        "\"\"\"\n",
        "\n",
        "class TunedLSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size=64, dropout=0.01):\n",
        "        super().__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, dropout=dropout, batch_first=True)\n",
        "        self.linear = nn.Linear(hidden_size, input_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        output, _ = self.lstm(x)\n",
        "        last = output[:, -1, :]  # take the last time step\n",
        "        return self.linear(last)\n",
        "\n",
        "# ─── Model Init ─────────────────────────────────────────────\n",
        "# model = TunedLSTM(input_size=X_train.shape[2], hidden_size=64, dropout=0.01)\n",
        "model = ShallowLSTM(input_size=X_train.shape[2], hidden_size=32)\n",
        "\n",
        "# ─── Optimizer & Loss ───────────────────────────────────────\n",
        "loss_fn = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.002)\n",
        "\n",
        "# ─── Training ───────────────────────────────────────────────\n",
        "EPOCHS = 50\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    model.train()\n",
        "    for xb, yb in train_loader:\n",
        "        pred = model(xb)\n",
        "        loss = loss_fn(pred, yb)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # if epoch % 10 == 0 or epoch == 1:\n",
        "    print(f\"Epoch {epoch}: Train MSE = {loss.item():.6f}\")"
      ],
      "metadata": {
        "id": "xb92SGsLojRK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}