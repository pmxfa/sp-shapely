{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNPLbVCgt9LoNOztDYCHCZF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pmxfa/sp-shapely/blob/main/sp_timegan_electricity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oaMLghK_ipz1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "outputId": "18a3aa10-abf8-4517-bebb-b882cb3f2e14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting synthcity\n",
            "  Downloading synthcity-0.2.11-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from synthcity) (8.6.1)\n",
            "Requirement already satisfied: pandas>=2.1 in /usr/local/lib/python3.11/dist-packages (from synthcity) (2.2.2)\n",
            "Collecting torch<2.3,>=2.1 (from synthcity)\n",
            "  Downloading torch-2.2.2-cp311-cp311-manylinux1_x86_64.whl.metadata (25 kB)\n",
            "Requirement already satisfied: scikit-learn>=1.2 in /usr/local/lib/python3.11/dist-packages (from synthcity) (1.6.1)\n",
            "Collecting nflows>=0.14 (from synthcity)\n",
            "  Downloading nflows-0.14.tar.gz (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.8/45.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting numpy<2.0,>=1.20 (from synthcity)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lifelines<0.30.0,>=0.29.0 (from synthcity)\n",
            "  Downloading lifelines-0.29.0-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting opacus>=1.3 (from synthcity)\n",
            "  Downloading opacus-1.5.3-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting networkx<3.0,>2.0 (from synthcity)\n",
            "  Downloading networkx-2.8.8-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting decaf-synthetic-data>=0.1.6 (from synthcity)\n",
            "  Downloading decaf_synthetic_data-0.1.6-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting optuna>=3.1 (from synthcity)\n",
            "  Downloading optuna-4.3.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: shap in /usr/local/lib/python3.11/dist-packages (from synthcity) (0.47.2)\n",
            "Requirement already satisfied: tenacity in /usr/local/lib/python3.11/dist-packages (from synthcity) (9.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from synthcity) (4.67.1)\n",
            "Collecting loguru (from synthcity)\n",
            "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting pydantic<2.0 (from synthcity)\n",
            "  Downloading pydantic-1.10.22-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.1/154.1 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from synthcity) (3.1.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from synthcity) (1.14.1)\n",
            "Requirement already satisfied: xgboost<3.0.0 in /usr/local/lib/python3.11/dist-packages (from synthcity) (2.1.4)\n",
            "Collecting geomloss (from synthcity)\n",
            "  Downloading geomloss-0.2.6.tar.gz (26 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pgmpy (from synthcity)\n",
            "  Downloading pgmpy-1.0.0-py3-none-any.whl.metadata (9.4 kB)\n",
            "Collecting redis (from synthcity)\n",
            "  Downloading redis-5.2.1-py3-none-any.whl.metadata (9.1 kB)\n",
            "Collecting pycox (from synthcity)\n",
            "  Downloading pycox-0.3.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting xgbse>=0.3.1 (from synthcity)\n",
            "  Downloading xgbse-0.3.3-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting pykeops (from synthcity)\n",
            "  Downloading pykeops-2.3.tar.gz (552 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m552.2/552.2 kB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting fflows (from synthcity)\n",
            "  Downloading fflows-0.0.3-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting monai (from synthcity)\n",
            "  Downloading monai-1.4.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting arfpy (from synthcity)\n",
            "  Downloading arfpy-0.1.1.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tsai (from synthcity)\n",
            "  Downloading tsai-0.4.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting be-great>=0.0.5 (from synthcity)\n",
            "  Downloading be_great-0.0.8-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting datasets>=2.5.2 (from be-great>=0.0.5->synthcity)\n",
            "  Downloading datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: transformers>=4.22.1 in /usr/local/lib/python3.11/dist-packages (from be-great>=0.0.5->synthcity) (4.51.3)\n",
            "Requirement already satisfied: accelerate>=0.20.1 in /usr/local/lib/python3.11/dist-packages (from be-great>=0.0.5->synthcity) (1.5.2)\n",
            "Collecting pytorch-lightning<2.0 (from decaf-synthetic-data>=0.1.6->synthcity)\n",
            "  Downloading pytorch_lightning-1.9.5-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting torchtext>=0.10 (from decaf-synthetic-data>=0.1.6->synthcity)\n",
            "  Downloading torchtext-0.18.0-cp311-cp311-manylinux1_x86_64.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: matplotlib>=3.0 in /usr/local/lib/python3.11/dist-packages (from lifelines<0.30.0,>=0.29.0->synthcity) (3.10.0)\n",
            "Requirement already satisfied: autograd>=1.5 in /usr/local/lib/python3.11/dist-packages (from lifelines<0.30.0,>=0.29.0->synthcity) (1.7.0)\n",
            "Collecting autograd-gamma>=0.3 (from lifelines<0.30.0,>=0.29.0->synthcity)\n",
            "  Downloading autograd-gamma-0.5.0.tar.gz (4.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting formulaic>=0.2.2 (from lifelines<0.30.0,>=0.29.0->synthcity)\n",
            "  Downloading formulaic-1.1.1-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (from nflows>=0.14->synthcity) (2.18.0)\n",
            "Requirement already satisfied: opt-einsum>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from opacus>=1.3->synthcity) (3.4.0)\n",
            "Collecting alembic>=1.5.0 (from optuna>=3.1->synthcity)\n",
            "  Downloading alembic-1.15.2-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting colorlog (from optuna>=3.1->synthcity)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna>=3.1->synthcity) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna>=3.1->synthcity) (2.0.40)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna>=3.1->synthcity) (6.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1->synthcity) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1->synthcity) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1->synthcity) (2025.2)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.0->synthcity) (4.13.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.2->synthcity) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.2->synthcity) (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<2.3,>=2.1->synthcity) (3.18.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch<2.3,>=2.1->synthcity) (1.13.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<2.3,>=2.1->synthcity) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<2.3,>=2.1->synthcity) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch<2.3,>=2.1->synthcity)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch<2.3,>=2.1->synthcity)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch<2.3,>=2.1->synthcity)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch<2.3,>=2.1->synthcity)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch<2.3,>=2.1->synthcity)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch<2.3,>=2.1->synthcity)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch<2.3,>=2.1->synthcity)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch<2.3,>=2.1->synthcity)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch<2.3,>=2.1->synthcity)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch<2.3,>=2.1->synthcity)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch<2.3,>=2.1->synthcity)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.2.0 (from torch<2.3,>=2.1->synthcity)\n",
            "  Downloading triton-2.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<2.3,>=2.1->synthcity) (12.5.82)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->synthcity) (3.21.0)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.11/dist-packages (from pgmpy->synthcity) (0.14.4)\n",
            "Collecting pyro-ppl (from pgmpy->synthcity)\n",
            "  Downloading pyro_ppl-1.9.1-py3-none-any.whl.metadata (7.8 kB)\n",
            "Collecting torchtuples>=0.2.0 (from pycox->synthcity)\n",
            "  Downloading torchtuples-0.2.2-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting feather-format>=0.4.0 (from pycox->synthcity)\n",
            "  Downloading feather-format-0.4.1.tar.gz (3.2 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from pycox->synthcity) (3.13.0)\n",
            "Requirement already satisfied: numba>=0.44 in /usr/local/lib/python3.11/dist-packages (from pycox->synthcity) (0.60.0)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.11/dist-packages (from pycox->synthcity) (2.32.3)\n",
            "Collecting py7zr>=0.11.3 (from pycox->synthcity)\n",
            "  Downloading py7zr-0.22.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting pybind11 (from pykeops->synthcity)\n",
            "  Downloading pybind11-2.13.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Collecting keopscore==2.3 (from pykeops->synthcity)\n",
            "  Downloading keopscore-2.3.tar.gz (118 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.5/118.5 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: slicer==0.0.8 in /usr/local/lib/python3.11/dist-packages (from shap->synthcity) (0.0.8)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (from tsai->synthcity) (24.1.2)\n",
            "Requirement already satisfied: fastai>=2.7.18 in /usr/local/lib/python3.11/dist-packages (from tsai->synthcity) (2.7.19)\n",
            "Collecting pyts>=0.13.0 (from tsai->synthcity)\n",
            "  Downloading pyts-0.13.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: imbalanced-learn>=0.12.4 in /usr/local/lib/python3.11/dist-packages (from tsai->synthcity) (0.13.0)\n",
            "Collecting psutil>=6.1.0 (from tsai->synthcity)\n",
            "  Downloading psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.20.1->be-great>=0.0.5->synthcity) (0.30.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.20.1->be-great>=0.0.5->synthcity) (0.5.3)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna>=3.1->synthcity) (1.1.3)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.5.2->be-great>=0.0.5->synthcity) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets>=2.5.2->be-great>=0.0.5->synthcity)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting xxhash (from datasets>=2.5.2->be-great>=0.0.5->synthcity)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets>=2.5.2->be-great>=0.0.5->synthcity)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec (from torch<2.3,>=2.1->synthcity)\n",
            "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.5.2->be-great>=0.0.5->synthcity) (3.11.15)\n",
            "Requirement already satisfied: fastdownload<2,>=0.0.5 in /usr/local/lib/python3.11/dist-packages (from fastai>=2.7.18->tsai->synthcity) (0.0.7)\n",
            "Requirement already satisfied: fastcore<1.8,>=1.5.29 in /usr/local/lib/python3.11/dist-packages (from fastai>=2.7.18->tsai->synthcity) (1.7.29)\n",
            "Requirement already satisfied: torchvision>=0.11 in /usr/local/lib/python3.11/dist-packages (from fastai>=2.7.18->tsai->synthcity) (0.21.0+cu124)\n",
            "Requirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.11/dist-packages (from fastai>=2.7.18->tsai->synthcity) (1.0.3)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from fastai>=2.7.18->tsai->synthcity) (11.1.0)\n",
            "Requirement already satisfied: spacy<4 in /usr/local/lib/python3.11/dist-packages (from fastai>=2.7.18->tsai->synthcity) (3.8.5)\n",
            "Collecting interface-meta>=1.2.0 (from formulaic>=0.2.2->lifelines<0.30.0,>=0.29.0->synthcity)\n",
            "  Downloading interface_meta-1.3.0-py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: wrapt>=1.0 in /usr/local/lib/python3.11/dist-packages (from formulaic>=0.2.2->lifelines<0.30.0,>=0.29.0->synthcity) (1.17.2)\n",
            "Requirement already satisfied: sklearn-compat<1,>=0.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn>=0.12.4->tsai->synthcity) (0.1.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines<0.30.0,>=0.29.0->synthcity) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines<0.30.0,>=0.29.0->synthcity) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines<0.30.0,>=0.29.0->synthcity) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines<0.30.0,>=0.29.0->synthcity) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines<0.30.0,>=0.29.0->synthcity) (3.2.3)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.44->pycox->synthcity) (0.43.0)\n",
            "Collecting texttable (from py7zr>=0.11.3->pycox->synthcity)\n",
            "  Downloading texttable-1.7.0-py2.py3-none-any.whl.metadata (9.8 kB)\n",
            "Collecting pycryptodomex>=3.16.0 (from py7zr>=0.11.3->pycox->synthcity)\n",
            "  Downloading pycryptodomex-3.22.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Collecting pyzstd>=0.15.9 (from py7zr>=0.11.3->pycox->synthcity)\n",
            "  Downloading pyzstd-0.16.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.4 kB)\n",
            "Collecting pyppmd<1.2.0,>=1.1.0 (from py7zr>=0.11.3->pycox->synthcity)\n",
            "  Downloading pyppmd-1.1.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
            "Collecting pybcj<1.1.0,>=1.0.0 (from py7zr>=0.11.3->pycox->synthcity)\n",
            "  Downloading pybcj-1.0.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
            "Collecting multivolumefile>=0.2.3 (from py7zr>=0.11.3->pycox->synthcity)\n",
            "  Downloading multivolumefile-0.2.3-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting inflate64<1.1.0,>=1.0.0 (from py7zr>=0.11.3->pycox->synthcity)\n",
            "  Downloading inflate64-1.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Collecting brotli>=1.1.0 (from py7zr>=0.11.3->pycox->synthcity)\n",
            "  Downloading Brotli-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=2.1->synthcity) (1.17.0)\n",
            "Collecting torchmetrics>=0.7.0 (from pytorch-lightning<2.0->decaf-synthetic-data>=0.1.6->synthcity)\n",
            "  Downloading torchmetrics-1.7.1-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting lightning-utilities>=0.6.0.post0 (from pytorch-lightning<2.0->decaf-synthetic-data>=0.1.6->synthcity)\n",
            "  Downloading lightning_utilities-0.14.3-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22.0->pycox->synthcity) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22.0->pycox->synthcity) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22.0->pycox->synthcity) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22.0->pycox->synthcity) (2025.1.31)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna>=3.1->synthcity) (3.2.1)\n",
            "INFO: pip is looking at multiple versions of torchtext to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torchtext>=0.10 (from decaf-synthetic-data>=0.1.6->synthcity)\n",
            "  Downloading torchtext-0.17.2-cp311-cp311-manylinux1_x86_64.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.22.1->be-great>=0.0.5->synthcity) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.22.1->be-great>=0.0.5->synthcity) (0.21.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<2.3,>=2.1->synthcity) (3.0.2)\n",
            "Collecting pyro-api>=0.1.1 (from pyro-ppl->pgmpy->synthcity)\n",
            "  Downloading pyro_api-0.1.2-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.11/dist-packages (from statsmodels->pgmpy->synthcity) (1.0.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch<2.3,>=2.1->synthcity) (1.3.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard->nflows>=0.14->synthcity) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard->nflows>=0.14->synthcity) (1.71.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard->nflows>=0.14->synthcity) (3.8)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard->nflows>=0.14->synthcity) (5.29.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->nflows>=0.14->synthcity) (75.2.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->nflows>=0.14->synthcity) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard->nflows>=0.14->synthcity) (3.1.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.5.2->be-great>=0.0.5->synthcity) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.5.2->be-great>=0.0.5->synthcity) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.5.2->be-great>=0.0.5->synthcity) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.5.2->be-great>=0.0.5->synthcity) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.5.2->be-great>=0.0.5->synthcity) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.5.2->be-great>=0.0.5->synthcity) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.5.2->be-great>=0.0.5->synthcity) (1.20.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai>=2.7.18->tsai->synthcity) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai>=2.7.18->tsai->synthcity) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai>=2.7.18->tsai->synthcity) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai>=2.7.18->tsai->synthcity) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai>=2.7.18->tsai->synthcity) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai>=2.7.18->tsai->synthcity) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai>=2.7.18->tsai->synthcity) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai>=2.7.18->tsai->synthcity) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai>=2.7.18->tsai->synthcity) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai>=2.7.18->tsai->synthcity) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai>=2.7.18->tsai->synthcity) (0.15.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai>=2.7.18->tsai->synthcity) (3.5.0)\n",
            "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torchvision>=0.11 (from fastai>=2.7.18->tsai->synthcity)\n",
            "  Downloading torchvision-0.22.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
            "  Downloading torchvision-0.21.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
            "  Downloading torchvision-0.20.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
            "  Downloading torchvision-0.20.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
            "  Downloading torchvision-0.19.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.0 kB)\n",
            "  Downloading torchvision-0.19.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.0 kB)\n",
            "  Downloading torchvision-0.18.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "INFO: pip is still looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading torchvision-0.18.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "  Downloading torchvision-0.17.2-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<4->fastai>=2.7.18->tsai->synthcity) (1.3.0)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy<4->fastai>=2.7.18->tsai->synthcity) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy<4->fastai>=2.7.18->tsai->synthcity) (0.1.5)\n",
            "INFO: pip is looking at multiple versions of thinc to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting thinc<8.4.0,>=8.3.4 (from spacy<4->fastai>=2.7.18->tsai->synthcity)\n",
            "  Downloading thinc-8.3.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\n",
            "Collecting blis<1.3.0,>=1.2.0 (from thinc<8.4.0,>=8.3.4->spacy<4->fastai>=2.7.18->tsai->synthcity)\n",
            "  Downloading blis-1.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<4->fastai>=2.7.18->tsai->synthcity) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<4->fastai>=2.7.18->tsai->synthcity) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<4->fastai>=2.7.18->tsai->synthcity) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<4->fastai>=2.7.18->tsai->synthcity) (0.21.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<4->fastai>=2.7.18->tsai->synthcity) (7.1.0)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<4->fastai>=2.7.18->tsai->synthcity) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4->fastai>=2.7.18->tsai->synthcity) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4->fastai>=2.7.18->tsai->synthcity) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4->fastai>=2.7.18->tsai->synthcity) (0.1.2)\n",
            "Downloading synthcity-0.2.11-py3-none-any.whl (430 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m430.1/430.1 kB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading be_great-0.0.8-py3-none-any.whl (16 kB)\n",
            "Downloading decaf_synthetic_data-0.1.6-py3-none-any.whl (9.1 kB)\n",
            "Downloading lifelines-0.29.0-py3-none-any.whl (349 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m349.3/349.3 kB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading networkx-2.8.8-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m88.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m112.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opacus-1.5.3-py3-none-any.whl (251 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.7/251.7 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading optuna-4.3.0-py3-none-any.whl (386 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.6/386.6 kB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic-1.10.22-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m114.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.2.2-cp311-cp311-manylinux1_x86_64.whl (755.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.6/755.6 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m124.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m105.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m62.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xgbse-0.3.3-py3-none-any.whl (35 kB)\n",
            "Downloading fflows-0.0.3-py3-none-any.whl (19 kB)\n",
            "Downloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading monai-1.4.0-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m80.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pgmpy-1.0.0-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m79.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pycox-0.3.0-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading redis-5.2.1-py3-none-any.whl (261 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.5/261.5 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tsai-0.4.0-py3-none-any.whl (324 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m324.3/324.3 kB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.15.2-py3-none-any.whl (231 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.9/231.9 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.5.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading formulaic-1.1.1-py3-none-any.whl (115 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.7/115.7 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (277 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.0/278.0 kB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading py7zr-0.22.0-py3-none-any.whl (67 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.9/67.9 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_lightning-1.9.5-py3-none-any.whl (829 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m829.5/829.5 kB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyts-0.13.0-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m97.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchtext-0.17.2-cp311-cp311-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m90.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchtuples-0.2.2-py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.9/41.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading pybind11-2.13.6-py3-none-any.whl (243 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.3/243.3 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyro_ppl-1.9.1-py3-none-any.whl (755 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m756.0/756.0 kB\u001b[0m \u001b[31m54.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Brotli-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m104.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading inflate64-1.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (96 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.2/96.2 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading interface_meta-1.3.0-py3-none-any.whl (14 kB)\n",
            "Downloading lightning_utilities-0.14.3-py3-none-any.whl (28 kB)\n",
            "Downloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multivolumefile-0.2.3-py3-none-any.whl (17 kB)\n",
            "Downloading pybcj-1.0.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.6/50.6 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pycryptodomex-3.22.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m93.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyppmd-1.1.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.3/141.3 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyro_api-0.1.2-py3-none-any.whl (11 kB)\n",
            "Downloading pyzstd-0.16.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (413 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m413.7/413.7 kB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchmetrics-1.7.1-py3-none-any.whl (961 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m961.5/961.5 kB\u001b[0m \u001b[31m68.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.17.2-cp311-cp311-manylinux1_x86_64.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m119.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading texttable-1.7.0-py2.py3-none-any.whl (10 kB)\n",
            "Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading thinc-8.3.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m116.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading blis-1.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.7/11.7 MB\u001b[0m \u001b[31m112.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: nflows, arfpy, geomloss, pykeops, keopscore, autograd-gamma, feather-format\n",
            "  Building wheel for nflows (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nflows: filename=nflows-0.14-py3-none-any.whl size=53654 sha256=859e921b7c4d3f58a0387991fd888a63b739ba2903fd3dd1d2165db393c1abb8\n",
            "  Stored in directory: /root/.cache/pip/wheels/11/9d/b5/5c88631a7bdb388738d147b6a28ba435ab969f25eff552f75a\n",
            "  Building wheel for arfpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for arfpy: filename=arfpy-0.1.1-py3-none-any.whl size=8664 sha256=bcc789264b284cc63c29ddba7aaa1536bef6a419fd15e51520554303bbf7f3fc\n",
            "  Stored in directory: /root/.cache/pip/wheels/9b/9a/2b/0414258a3b781854c07acca132cf155a7d93b69f23c3cd6826\n",
            "  Building wheel for geomloss (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for geomloss: filename=geomloss-0.2.6-py3-none-any.whl size=32247 sha256=88f9b7acbf9acd8c84a589017ffaac72d86250b4cfcd0f87d788610db3669389\n",
            "  Stored in directory: /root/.cache/pip/wheels/f5/cf/07/9d1d883feac2951b968fed8ef676842dc90b9860ea49a4dcac\n",
            "  Building wheel for pykeops (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pykeops: filename=pykeops-2.3-py3-none-any.whl size=120491 sha256=318fccdbb8ce23fc71a8c589e55fa79389c63a0127c85dd17083b13727cebc5a\n",
            "  Stored in directory: /root/.cache/pip/wheels/a8/91/ea/d9e54997a840e38595b9a2c5b9021f3969173edbda2fc99686\n",
            "  Building wheel for keopscore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keopscore: filename=keopscore-2.3-py3-none-any.whl size=185897 sha256=e79e3eaa4a2afd57704660ad161ee317a4bbbad9cdd4d93a3489947b46f612e6\n",
            "  Stored in directory: /root/.cache/pip/wheels/32/77/92/17707f162cb65cfa8e97f0360cdb30681038f7762cf929b1b4\n",
            "  Building wheel for autograd-gamma (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for autograd-gamma: filename=autograd_gamma-0.5.0-py3-none-any.whl size=4030 sha256=36218c8de27ffb8bf0cd6a2a73fa9bcbf6392832293aa4a8465dab5d8a9ddda9\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/67/f4/2caaae2146198dcb824f31a303833b07b14a5ec863fb3acd7b\n",
            "  Building wheel for feather-format (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for feather-format: filename=feather_format-0.4.1-py3-none-any.whl size=2434 sha256=39aa1a5338fa1cd2399f3b25526971e044dc89b27ed5745659288f6f1e2ed204\n",
            "  Stored in directory: /root/.cache/pip/wheels/77/5b/0e/0e63d10b6353208a085a321ea2eed2578f220a77bb8a4bd7ab\n",
            "Successfully built nflows arfpy geomloss pykeops keopscore autograd-gamma feather-format\n",
            "Installing collected packages: texttable, pyro-api, brotli, xxhash, triton, redis, pyzstd, pyppmd, pydantic, pycryptodomex, pybind11, pybcj, psutil, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, multivolumefile, loguru, lightning-utilities, keopscore, interface-meta, inflate64, fsspec, feather-format, dill, colorlog, pykeops, py7zr, nvidia-cusolver-cu12, nvidia-cudnn-cu12, multiprocess, blis, alembic, torch, thinc, optuna, formulaic, autograd-gamma, torchvision, torchtuples, torchtext, torchmetrics, pyts, pyro-ppl, opacus, nflows, monai, lifelines, geomloss, fflows, datasets, arfpy, xgbse, pytorch-lightning, pycox, pgmpy, be-great, decaf-synthetic-data, tsai, synthcity\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.11.3\n",
            "    Uninstalling pydantic-2.11.3:\n",
            "      Successfully uninstalled pydantic-2.11.3\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 5.9.5\n",
            "    Uninstalling psutil-5.9.5:\n",
            "      Successfully uninstalled psutil-5.9.5\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.21.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.21.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.4.2\n",
            "    Uninstalling networkx-3.4.2:\n",
            "      Successfully uninstalled networkx-3.4.2\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: blis\n",
            "    Found existing installation: blis 1.3.0\n",
            "    Uninstalling blis-1.3.0:\n",
            "      Successfully uninstalled blis-1.3.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n",
            "      Successfully uninstalled torch-2.6.0+cu124\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 8.3.6\n",
            "    Uninstalling thinc-8.3.6:\n",
            "      Successfully uninstalled thinc-8.3.6\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.21.0+cu124\n",
            "    Uninstalling torchvision-0.21.0+cu124:\n",
            "      Successfully uninstalled torchvision-0.21.0+cu124\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-core 0.3.55 requires pydantic<3.0.0,>=2.5.2; python_full_version < \"3.12.4\", but you have pydantic 1.10.22 which is incompatible.\n",
            "scikit-image 0.25.2 requires networkx>=3.0, but you have networkx 2.8.8 which is incompatible.\n",
            "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.2.2 which is incompatible.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.12.0 which is incompatible.\n",
            "google-genai 1.11.0 requires pydantic<3.0.0,>=2.0.0, but you have pydantic 1.10.22 which is incompatible.\n",
            "langchain 0.3.24 requires pydantic<3.0.0,>=2.7.4, but you have pydantic 1.10.22 which is incompatible.\n",
            "nx-cugraph-cu12 25.2.0 requires networkx>=3.2, but you have networkx 2.8.8 which is incompatible.\n",
            "albumentations 2.0.5 requires pydantic>=2.9.2, but you have pydantic 1.10.22 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed alembic-1.15.2 arfpy-0.1.1 autograd-gamma-0.5.0 be-great-0.0.8 blis-1.2.1 brotli-1.1.0 colorlog-6.9.0 datasets-3.5.0 decaf-synthetic-data-0.1.6 dill-0.3.8 feather-format-0.4.1 fflows-0.0.3 formulaic-1.1.1 fsspec-2024.12.0 geomloss-0.2.6 inflate64-1.0.1 interface-meta-1.3.0 keopscore-2.3 lifelines-0.29.0 lightning-utilities-0.14.3 loguru-0.7.3 monai-1.4.0 multiprocess-0.70.16 multivolumefile-0.2.3 networkx-2.8.8 nflows-0.14 numpy-1.26.4 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvtx-cu12-12.1.105 opacus-1.5.3 optuna-4.3.0 pgmpy-1.0.0 psutil-7.0.0 py7zr-0.22.0 pybcj-1.0.3 pybind11-2.13.6 pycox-0.3.0 pycryptodomex-3.22.0 pydantic-1.10.22 pykeops-2.3 pyppmd-1.1.1 pyro-api-0.1.2 pyro-ppl-1.9.1 pytorch-lightning-1.9.5 pyts-0.13.0 pyzstd-0.16.2 redis-5.2.1 synthcity-0.2.11 texttable-1.7.0 thinc-8.3.4 torch-2.2.2 torchmetrics-1.7.1 torchtext-0.17.2 torchtuples-0.2.2 torchvision-0.17.2 triton-2.2.0 tsai-0.4.0 xgbse-0.3.3 xxhash-3.5.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "psutil"
                ]
              },
              "id": "d57f286b9b2944a592f936c6396ab819"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install synthcity"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "NcwQ6Yo09JC8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import sys\n",
        "import warnings\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "import synthcity.logger as log\n",
        "from synthcity.plugins import Plugins\n",
        "from synthcity.plugins.core.dataloader import TimeSeriesDataLoader\n",
        "\n",
        "log.add(sink=sys.stderr, level=\"INFO\")"
      ],
      "metadata": {
        "id": "kfDi7FQF9LIv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53f7b322-0b8b-43db-9b44-7d4d290f4a4b",
        "collapsed": true
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "[KeOps] Compiling cuda jit compiler engine ... OK\n",
            "[pyKeOps] Compiling nvrtc binder for python ... OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/drive/Shareddrives/sp_env/datasets/Electricity Transformer Dataset (ETDataset)/ETTh1.csv\"\n",
        "\n",
        "df = pd.read_csv(file_path)\n",
        "print(df.head())\n",
        "print(df.info())\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "id": "DCLsmN-F9NGv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5353db95-618d-49cd-8f2a-9e5bc798ef43",
        "collapsed": true
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                  date   HUFL   HULL   MUFL   MULL   LUFL   LULL         OT\n",
            "0  2016-07-01 00:00:00  5.827  2.009  1.599  0.462  4.203  1.340  30.531000\n",
            "1  2016-07-01 01:00:00  5.693  2.076  1.492  0.426  4.142  1.371  27.787001\n",
            "2  2016-07-01 02:00:00  5.157  1.741  1.279  0.355  3.777  1.218  27.787001\n",
            "3  2016-07-01 03:00:00  5.090  1.942  1.279  0.391  3.807  1.279  25.044001\n",
            "4  2016-07-01 04:00:00  5.358  1.942  1.492  0.462  3.868  1.279  21.948000\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 17420 entries, 0 to 17419\n",
            "Data columns (total 8 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   date    17420 non-null  object \n",
            " 1   HUFL    17420 non-null  float64\n",
            " 2   HULL    17420 non-null  float64\n",
            " 3   MUFL    17420 non-null  float64\n",
            " 4   MULL    17420 non-null  float64\n",
            " 5   LUFL    17420 non-null  float64\n",
            " 6   LULL    17420 non-null  float64\n",
            " 7   OT      17420 non-null  float64\n",
            "dtypes: float64(7), object(1)\n",
            "memory usage: 1.1+ MB\n",
            "None\n",
            "date    0\n",
            "HUFL    0\n",
            "HULL    0\n",
            "MUFL    0\n",
            "MULL    0\n",
            "LUFL    0\n",
            "LULL    0\n",
            "OT      0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert 'date' to datetime, set as index, and sort\n",
        "df['date'] = pd.to_datetime(df['date'])\n",
        "df.set_index('date', inplace=True)\n",
        "df.sort_index(inplace=True)\n",
        "\n",
        "# Keep the latest 5000 rows\n",
        "df_latest = df.tail(5000)\n",
        "\n",
        "# Train-test split: 70% for training (for TimeGAN), 30% for testing (TSTR)\n",
        "train_size = int(0.7 * len(df_latest))\n",
        "df_train = df_latest.iloc[:train_size]\n",
        "df_test = df_latest.iloc[train_size:]  # use later for LSTM-TSTR\n",
        "\n",
        "# Normalize the data\n",
        "scaler = MinMaxScaler()\n",
        "scaled_train = scaler.fit_transform(df_train)\n",
        "df_scaled_train = pd.DataFrame(scaled_train, columns=df_train.columns, index=df_train.index)\n",
        "scaled_test = scaler.transform(df_test)\n",
        "df_scaled_test = pd.DataFrame(scaled_train, columns=df_train.columns, index=df_train.index)\n",
        "\n",
        "# Sequence length for time-series data (dataset = hourly; 24 hours)\n",
        "sequence_length = 24\n",
        "temporal_data = []\n",
        "observation_times = []\n",
        "\n",
        "# Generate sequences from df_scaled_train only\n",
        "for start in range(len(df_scaled_train) - sequence_length + 1):\n",
        "    sequence = df_scaled_train.iloc[start:start + sequence_length].reset_index(drop=True)\n",
        "    temporal_data.append(sequence)\n",
        "    observation_times.append(list(range(sequence_length)))  # relative time within the window\n",
        "\n",
        "# Dummy outcome for TimeGAN (can be used in DataLoader)\n",
        "dummy_outcome = pd.DataFrame(np.zeros(len(temporal_data)), columns=[\"outcome\"])\n",
        "\n",
        "# Create DataLoader for TimeGAN\n",
        "loader = TimeSeriesDataLoader(\n",
        "    temporal_data=temporal_data,\n",
        "    observation_times=observation_times,\n",
        "    static_data=None,\n",
        "    outcome=dummy_outcome,\n",
        ")\n",
        "\n",
        "# Print the loader info\n",
        "print(f\"TimeSeriesDataLoader created with {len(temporal_data)} sequences\")\n"
      ],
      "metadata": {
        "id": "siWRiBtn9O0V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a1f1c88-e60d-4ae3-c1c8-ef9aac63e64f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TimeSeriesDataLoader created with 3477 sequences\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(df_train))\n",
        "print(loader.dataframe())"
      ],
      "metadata": {
        "id": "FmZe08FM9Rd0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56f5b879-1d37-445c-c2fd-c590e15a8ca8",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3500\n",
            "       seq_id  seq_time_id  seq_temporal_HUFL  seq_temporal_HULL  \\\n",
            "0           0            0           0.642388           0.302720   \n",
            "1           0            1           0.613277           0.410782   \n",
            "2           0            2           0.656955           0.427003   \n",
            "3           0            3           0.647244           0.378339   \n",
            "4           0            4           0.711963           0.416189   \n",
            "...       ...          ...                ...                ...   \n",
            "83443    3476           19           0.841426           0.362118   \n",
            "83444    3476           20           0.865681           0.362118   \n",
            "83445    3476           21           0.864062           0.437818   \n",
            "83446    3476           22           0.930425           0.481075   \n",
            "83447    3476           23           0.791250           0.405375   \n",
            "\n",
            "       seq_temporal_LUFL  seq_temporal_LULL  seq_temporal_MUFL  \\\n",
            "0               0.429806           0.589646           0.659849   \n",
            "1               0.429806           0.666667           0.620829   \n",
            "2               0.364003           0.525673           0.675646   \n",
            "3               0.372786           0.525673           0.680301   \n",
            "4               0.425486           0.589646           0.741631   \n",
            "...                  ...                ...                ...   \n",
            "83443           0.605184           0.627946           0.841092   \n",
            "83444           0.605184           0.500000           0.878256   \n",
            "83445           0.627214           0.576599           0.880113   \n",
            "83446           0.776242           0.563973           0.916362   \n",
            "83447           0.385889           0.486953           0.827152   \n",
            "\n",
            "       seq_temporal_MULL  seq_temporal_OT  seq_out_outcome  \n",
            "0               0.330177         0.377483              0.0  \n",
            "1               0.403162         0.393583              0.0  \n",
            "2               0.393604         0.405629              0.0  \n",
            "3               0.374576         0.413622              0.0  \n",
            "4               0.419064         0.409625              0.0  \n",
            "...                  ...              ...              ...  \n",
            "83443           0.317492         0.642555              0.0  \n",
            "83444           0.301590         0.586321              0.0  \n",
            "83445           0.377792         0.614467              0.0  \n",
            "83446           0.377792         0.662651              0.0  \n",
            "83447           0.434876         0.730932              0.0  \n",
            "\n",
            "[83448 rows x 10 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hparams = {\n",
        "          \"mode\": \"LSTM\", # default mode = RNN\n",
        "}\n",
        "\n",
        "# Load TimeGAN with custom parameters\n",
        "syn_model = Plugins().get(\"timegan\", **hparams)"
      ],
      "metadata": {
        "id": "oYqRdbxl9W74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d49c7204-cd8b-4b7a-dbb9-fbc9523debf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2025-04-26T12:35:18.790696+0000][1314][CRITICAL] module disabled: /usr/local/lib/python3.11/dist-packages/synthcity/plugins/generic/plugin_goggle.py\n",
            "[2025-04-26T12:35:18.790696+0000][1314][CRITICAL] module disabled: /usr/local/lib/python3.11/dist-packages/synthcity/plugins/generic/plugin_goggle.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print all parameters of initialized model\n",
        "for attr in dir(syn_model):\n",
        "    if not attr.startswith(\"_\") and not callable(getattr(syn_model, attr)):\n",
        "        print(f\"{attr}: {getattr(syn_model, attr)}\")"
      ],
      "metadata": {
        "id": "y9ZVw8pT9Y_Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99608720-a947-4e58-c79d-86a19f8a46bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch_size: 64\n",
            "class_name: TimeGANPlugin\n",
            "clipping_value: 0\n",
            "compress_dataset: False\n",
            "dataloader_sampling_strategy: imbalanced_time_censoring\n",
            "device: cuda\n",
            "discriminator_batch_norm: False\n",
            "discriminator_dropout: 0.1\n",
            "discriminator_loss: None\n",
            "discriminator_lr: 0.001\n",
            "discriminator_n_iter: 1\n",
            "discriminator_n_layers_hidden: 3\n",
            "discriminator_n_units_hidden: 300\n",
            "discriminator_nonlin: leaky_relu\n",
            "discriminator_weight_decay: 0.001\n",
            "embedding_penalty: 10\n",
            "encoder: None\n",
            "encoder_max_clusters: 20\n",
            "expecting_conditional: False\n",
            "fitted: False\n",
            "gamma_penalty: 1\n",
            "generator_batch_norm: False\n",
            "generator_dropout: 0.01\n",
            "generator_loss: None\n",
            "generator_lr: 0.001\n",
            "generator_n_layers_hidden: 2\n",
            "generator_n_units_hidden: 150\n",
            "generator_nonlin: leaky_relu\n",
            "generator_nonlin_out_continuous: tanh\n",
            "generator_nonlin_out_discrete: softmax\n",
            "generator_residual: True\n",
            "generator_weight_decay: 0.001\n",
            "mode: LSTM\n",
            "module_name: synthcity.plugins.time_series.plugin_timegan\n",
            "module_relative_path: ../time_series/plugin_timegan.py\n",
            "moments_penalty: 100\n",
            "n_iter: 1000\n",
            "n_iter_print: 10\n",
            "outcome_encoder: TabularEncoder(cat_encoder_params={'handle_unknown': 'ignore',\n",
            "                                   'sparse_output': False},\n",
            "               categorical_encoder='onehot',\n",
            "               cont_encoder_params={'n_components': 20},\n",
            "               continuous_encoder='bayesian_gmm', max_clusters=20)\n",
            "random_state: 0\n",
            "sampling_patience: 500\n",
            "sampling_strategy: marginal\n",
            "strict: True\n",
            "use_horizon_condition: True\n",
            "workspace: workspace\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## fitting the model"
      ],
      "metadata": {
        "id": "IKG0O5Pg9hpG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(loader.shape)"
      ],
      "metadata": {
        "id": "THzKqhIFcWlG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Train the model\n",
        "syn_model.fit(loader)"
      ],
      "metadata": {
        "id": "-BKXe4G19l_8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4c855a1-4ce3-44c9-eb7c-07ddd0ec30e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [2:02:26<00:00,  7.35s/it]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<synthcity.plugins.time_series.plugin_timegan.TimeGANPlugin at 0x787b51703a90>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "saved_model = syn_model.save()"
      ],
      "metadata": {
        "id": "MMIE6K28AavA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from synthcity.utils.serialization import save_to_file, load_from_file\n",
        "\n",
        "# Save model to drive\n",
        "# save_to_file('/content/drive/Shareddrives/sp_env/test_model.pkl', syn_model)\n",
        "save_to_file('/content/drive/Shareddrives/sp_env/saved_models/GAN_Electricity.pkl', syn_model)\n",
        "\n",
        "# Load the model\n",
        "# loaded_model = load_from_file('/content/drive/Shareddrives/sp_env/test_model.pkl')"
      ],
      "metadata": {
        "id": "GXR9yPgyDsfe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_samples = len(temporal_data)\n",
        "syn_data = syn_model.generate(count=n_samples)\n",
        "print(data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xziCvHeRjvaM",
        "outputId": "3d7cfd68-2090-43fd-8672-35dbecff5059"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1240, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_samples = len(temporal_data)\n",
        "print(n_samples)\n",
        "data = loaded_model.generate(count=n_samples)\n",
        "print(data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09mtQbokk7iI",
        "outputId": "f7244880-7a8e-4933-8e43-67684fbde01a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3477\n",
            "(43070, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import inspect\n",
        "print(inspect.getsource(syn_model.generate))"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Oggs90DmCey",
        "outputId": "19f7cc9c-f736-424a-83f0-ad25210fc61e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    @validate_arguments\n",
            "    def generate(\n",
            "        self,\n",
            "        count: Optional[int] = None,\n",
            "        constraints: Optional[Constraints] = None,\n",
            "        random_state: Optional[int] = None,\n",
            "        **kwargs: Any,\n",
            "    ) -> DataLoader:\n",
            "        \"\"\"Synthetic data generation method.\n",
            "\n",
            "        Args:\n",
            "            count: optional int.\n",
            "                The number of samples to generate. If None, it generated len(reference_dataset) samples.\n",
            "            cond: Optional, Union[pd.DataFrame, pd.Series, np.ndarray].\n",
            "                Optional Generation Conditional. The conditional can be used only if the model was trained using a conditional too.\n",
            "                If provided, it must have `count` length.\n",
            "                Not all models support conditionals. The conditionals can be used in VAEs or GANs to speed-up the generation under some constraints. For model agnostic solutions, check out the `constraints` parameter.\n",
            "            constraints: optional Constraints.\n",
            "                Optional constraints to apply on the generated data. If none, the reference schema constraints are applied. The constraints are model agnostic, and will filter the output of the generative model.\n",
            "                The constraints are a list of rules. Each rule is a tuple of the form (<feature>, <operation>, <value>).\n",
            "\n",
            "                Valid Operations:\n",
            "                    - \"<\", \"lt\" : less than <value>\n",
            "                    - \"<=\", \"le\": less or equal with <value>\n",
            "                    - \">\", \"gt\" : greater than <value>\n",
            "                    - \">=\", \"ge\": greater or equal with <value>\n",
            "                    - \"==\", \"eq\": equal with <value>\n",
            "                    - \"in\": valid for categorical features, and <value> must be array. for example, (\"target\", \"in\", [0, 1])\n",
            "                    - \"dtype\": <value> can be a data type. For example, (\"target\", \"dtype\", \"int\")\n",
            "\n",
            "                Usage example:\n",
            "                    >>> from synthcity.plugins.core.constraints import Constraints\n",
            "                    >>> constraints = Constraints(\n",
            "                    >>>   rules=[\n",
            "                    >>>             (\"InterestingFeature\", \"==\", 0),\n",
            "                    >>>         ]\n",
            "                    >>>     )\n",
            "                    >>>\n",
            "                    >>> syn_data = syn_model.generate(\n",
            "                            count=count,\n",
            "                            constraints=constraints\n",
            "                        ).dataframe()\n",
            "                    >>>\n",
            "                    >>> assert (syn_data[\"InterestingFeature\"] == 0).all()\n",
            "\n",
            "            random_state: optional int.\n",
            "                Optional random seed to use.\n",
            "\n",
            "        Returns:\n",
            "            <count> synthetic samples\n",
            "        \"\"\"\n",
            "        if not self.fitted:\n",
            "            raise RuntimeError(\"Fit the generator first\")\n",
            "\n",
            "        if self._schema is None:\n",
            "            raise RuntimeError(\"Fit the model first\")\n",
            "\n",
            "        if random_state is not None:\n",
            "            enable_reproducible_results(random_state)\n",
            "\n",
            "        has_gen_cond = \"cond\" in kwargs and kwargs[\"cond\"] is not None\n",
            "        if has_gen_cond and not self.expecting_conditional:\n",
            "            raise RuntimeError(\n",
            "                \"Conditional mismatch. Got inference conditional, without any training conditional\"\n",
            "            )\n",
            "\n",
            "        if count is None:\n",
            "            count = self.data_info[\"len\"]\n",
            "\n",
            "        # We use the training schema for the generation\n",
            "        gen_constraints = self.training_schema().as_constraints()\n",
            "        if constraints is not None:\n",
            "            gen_constraints = gen_constraints.extend(constraints)\n",
            "\n",
            "        syn_schema = Schema.from_constraints(gen_constraints)\n",
            "\n",
            "        X_syn = self._generate(count=count, syn_schema=syn_schema, **kwargs)\n",
            "\n",
            "        if X_syn.is_tabular():\n",
            "            if self.compress_dataset:\n",
            "                X_syn = X_syn.decompress(self.compress_context)\n",
            "            if self._data_encoders is not None:\n",
            "                X_syn = X_syn.decode(self._data_encoders)\n",
            "\n",
            "        # The dataset is decompressed here, we can use the public schema\n",
            "        gen_constraints = self.schema().as_constraints()\n",
            "        if constraints is not None:\n",
            "            gen_constraints = gen_constraints.extend(constraints)\n",
            "\n",
            "        if not X_syn.satisfies(gen_constraints) and self.strict:\n",
            "            raise RuntimeError(\n",
            "                f\"Plugin {self.name()} failed to meet the synthetic constraints.\"\n",
            "            )\n",
            "\n",
            "        if self.strict:\n",
            "            X_syn = X_syn.match(gen_constraints)\n",
            "\n",
            "        return X_syn\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_samples = len(temporal_data)\n",
        "print(n_samples)\n",
        "data1 = loaded_model.generate(count=1)\n",
        "data2 = loaded_model.generate(count=10)\n",
        "data3 = loaded_model.generate(count=100)\n",
        "print(data1.shape)\n",
        "print(data2.shape)\n",
        "print(data3.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nu3McdW0or2G",
        "outputId": "11ee9a10-8820-4da8-a77a-305d5ab89e33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3477\n",
            "(16, 10)\n",
            "(134, 10)\n",
            "(1294, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save with automated format\n",
        "import datetime\n",
        "import os\n",
        "# Get the current date and time\n",
        "now = datetime.datetime.now()\n",
        "timestamp = now.strftime(\"%m%d%y-%H%M%S\")  # MMDDYY-HHMMSS format\n",
        "\n",
        "# Define the base directory\n",
        "base_dir = \"/content/drive/Shareddrives/sp_env/synthetic_datasets/TimeGAN/electricity\"  #CHANGE THIS\n",
        "if not os.path.exists(base_dir):\n",
        "    os.makedirs(base_dir)\n",
        "\n",
        "# Construct the filename\n",
        "model_name = type(syn_model).__name__.lower() # Get model name dynamically\n",
        "filename = f\"{timestamp}-{model_name}-n_3000.csv\"\n",
        "filepath = os.path.join(base_dir, filename)\n",
        "\n",
        "# Save the data\n",
        "df_syn = syn_data.dataframe()\n",
        "df_syn.to_csv(filepath, index=False)\n",
        "\n",
        "print(f\"Synthetic data saved to: {filepath}\")"
      ],
      "metadata": {
        "id": "J4rF0HY29o65",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee959a73-2f0d-4d5b-c811-c3352f113f75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synthetic data saved to: /content/drive/Shareddrives/sp_env/synthetic_datasets/TimeGAN/electricity/042625-152713-timeganplugin-n_3000.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "TICnBaoH9r8Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prerequisites"
      ],
      "metadata": {
        "id": "QlHAzxfV9uXf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define selected columns explicitly\n",
        "selected_columns = ['seq_temporal_HUFL', 'seq_temporal_HULL', 'seq_temporal_LUFL', 'seq_temporal_LULL', 'seq_temporal_MUFL', 'seq_temporal_MULL', 'seq_temporal_OT']\n",
        "\n",
        "# Ensure real_data and synthetic_data only contain the selected columns\n",
        "real_data = loader.dataframe()[selected_columns].to_numpy()\n",
        "synthetic_data = syn_data.dataframe()[selected_columns].to_numpy()"
      ],
      "metadata": {
        "id": "zUMHadsq9vw8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Check datasets\n",
        "\n",
        "print(real_data, \"\\n ------------------------------------------------------- \\n\", synthetic_data)\n",
        "print(type(real_data),type(synthetic_data))\n",
        "print(real_data.shape,synthetic_data.shape)\n",
        "\n",
        "\"\"\" TODO\n",
        "[] add adjusting off dataset to fit min length here\n",
        "[] remove min length stuff in helper funcs\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "DumXr_Gg9y6U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "outputId": "06e6d88f-502e-4611-cc9d-22444c455cf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.64238779 0.30271972 0.42980559 ... 0.65984936 0.33017688 0.37748344]\n",
            " [0.61327729 0.41078203 0.42980559 ... 0.62082855 0.4031624  0.393583  ]\n",
            " [0.65695512 0.42700348 0.36400289 ... 0.675646   0.39360371 0.40562914]\n",
            " ...\n",
            " [0.86406245 0.43781779 0.6272138  ... 0.88011299 0.37779167 0.61446676]\n",
            " [0.93042472 0.48107499 0.77624185 ... 0.91636155 0.37779167 0.6626513 ]\n",
            " [0.79124994 0.40537487 0.38588913 ... 0.82715244 0.43487582 0.7309317 ]] \n",
            " ------------------------------------------------------- \n",
            " [[0.67353536 0.32652558 0.43057038 ... 0.83059878 0.33310791 0.42354418]\n",
            " [0.67358549 0.44509754 0.38212669 ... 0.83059413 0.41668498 0.50057416]\n",
            " [0.85121252 0.28399383 0.43061993 ... 0.8305551  0.37194391 0.42362864]\n",
            " ...\n",
            " [0.7319141  0.56629246 0.38196447 ... 0.86278558 0.37179222 0.50062887]\n",
            " [0.67342589 0.44475754 0.38193633 ... 0.79199183 0.33283287 0.50064705]\n",
            " [0.75042885 0.2835606  0.4799513  ... 0.83063244 0.33277079 0.37934677]]\n",
            "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
            "(83448, 7) (42946, 7)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' TODO\\n[] add adjusting off dataset to fit min length here\\n[] remove min length stuff in helper funcs\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate distance metrics"
      ],
      "metadata": {
        "id": "0pU8BORS9vWk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Helper Functions"
      ],
      "metadata": {
        "id": "DVguOJWi-Fos"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import wasserstein_distance, entropy\n",
        "import numpy as np\n",
        "\n",
        "def compute_wasserstein(real_data, synthetic_data, selected_columns):\n",
        "    \"\"\"\n",
        "    Computes Wasserstein Distance between real and synthetic time-series data.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # Ensure both datasets have the same number of samples\n",
        "    min_length = min(len(real_data), len(synthetic_data))\n",
        "    real_trimmed = real_data[:min_length]  # Keep original order (no random sampling)\n",
        "    synthetic_trimmed = synthetic_data[:min_length]  # Match size\n",
        "    print(real_trimmed.shape,synthetic_trimmed.shape)\n",
        "\n",
        "    wasserstein_results = {}\n",
        "\n",
        "    # Compute Wasserstein Distance for each feature\n",
        "    for i, col in enumerate(selected_columns):\n",
        "        w_dist = wasserstein_distance(real_trimmed[:, i], synthetic_trimmed[:, i])\n",
        "        wasserstein_results[col] = w_dist\n",
        "        print(f\"{w_dist}\")\n",
        "\n",
        "    return wasserstein_results\n",
        "\n",
        "def compute_kl_divergence(real_data, synthetic_data, selected_columns, bins=50):\n",
        "    \"\"\"\n",
        "    Computes KL Divergence between real and synthetic time-series data.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # Ensure both datasets have the same number of samples\n",
        "    min_length = min(len(real_data), len(synthetic_data))\n",
        "    real_trimmed = real_data[:min_length]  # Keep original order\n",
        "    synthetic_trimmed = synthetic_data[:min_length]  # Match size\n",
        "\n",
        "    kl_results = {}\n",
        "\n",
        "    for i, col in enumerate(selected_columns):\n",
        "        # Compute histogram-based probability distributions\n",
        "        real_hist, _ = np.histogram(real_trimmed[:, i], bins=bins, density=True)\n",
        "        synth_hist, _ = np.histogram(synthetic_trimmed[:, i], bins=bins, density=True)\n",
        "\n",
        "        # Avoid zero probabilities (KL Divergence is undefined for zero values)\n",
        "        real_hist += 1e-10\n",
        "        synth_hist += 1e-10\n",
        "\n",
        "        # Compute KL Divergence\n",
        "        kl_div = entropy(real_hist, synth_hist)\n",
        "        kl_results[col] = kl_div\n",
        "        print(f\"{kl_div}\")\n",
        "\n",
        "    return kl_results"
      ],
      "metadata": {
        "id": "GjGk3_Zx94Ko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate Metrics"
      ],
      "metadata": {
        "id": "yLnb7Vqg-IG_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute Wasserstein Distance\n",
        "wasserstein_results = compute_wasserstein(real_data, synthetic_data, selected_columns)\n",
        "print(\"Wasserstein Distance Results:\")\n",
        "print(wasserstein_results)\n",
        "\n",
        "# Compute KL Divergence\n",
        "kl_results = compute_kl_divergence(real_data, synthetic_data, selected_columns)\n",
        "print(\"KL Divergence Results:\")\n",
        "print(kl_results)"
      ],
      "metadata": {
        "id": "olm0RYP89-SN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d844293-ba5e-46e4-8d75-ea404265b785"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(42946, 7) (42946, 7)\n",
            "0.05639391359444064\n",
            "0.03758366863714886\n",
            "0.09343952591018045\n",
            "0.05978232416685537\n",
            "0.08429052923356815\n",
            "0.06523718684914633\n",
            "0.053477183409293055\n",
            "Wasserstein Distance Results:\n",
            "{'seq_temporal_HUFL': 0.05639391359444064, 'seq_temporal_HULL': 0.03758366863714886, 'seq_temporal_LUFL': 0.09343952591018045, 'seq_temporal_LULL': 0.05978232416685537, 'seq_temporal_MUFL': 0.08429052923356815, 'seq_temporal_MULL': 0.06523718684914633, 'seq_temporal_OT': 0.053477183409293055}\n",
            "10.40922091460919\n",
            "12.911924636011225\n",
            "12.882915120034097\n",
            "10.578358954241521\n",
            "11.11602725906944\n",
            "14.83792841779404\n",
            "14.23388670843781\n",
            "KL Divergence Results:\n",
            "{'seq_temporal_HUFL': 10.40922091460919, 'seq_temporal_HULL': 12.911924636011225, 'seq_temporal_LUFL': 12.882915120034097, 'seq_temporal_LULL': 10.578358954241521, 'seq_temporal_MUFL': 11.11602725906944, 'seq_temporal_MULL': 14.83792841779404, 'seq_temporal_OT': 14.23388670843781}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM downstream"
      ],
      "metadata": {
        "id": "UpJLIRUZChiz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "real_data = df_scaled_test\n",
        "df_synth = pd.read_csv(\"/content/drive/Shareddrives/sp_env/synthetic_datasets/TimeGAN/electricity/042625-152713-timeganplugin-n_3000.csv\")\n",
        "\n",
        "# 2. Drop the unwanted column\n",
        "real_data = real_data.drop(columns=[\"seq_id\", \"seq_time_id\", \"seq_out_outcome\"], errors=\"ignore\")\n",
        "df_synth = df_synth.drop(columns=[\"seq_id\", \"seq_time_id\", \"seq_out_outcome\"], errors=\"ignore\")"
      ],
      "metadata": {
        "id": "oidw2-H7OeUO"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"real_data: {real_data.shape}, synthetic_data: {df_synth.shape}\")"
      ],
      "metadata": {
        "id": "2V3bCF9WvLsa",
        "outputId": "150b7599-22b0-4d82-9d1e-fb0eb84086ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "real_data: (3500, 7), synthetic_data: (42946, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ✧.* libraries ✧.*\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error"
      ],
      "metadata": {
        "id": "jBeVAcOyoPDz"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "recheck LSTM notebook for"
      ],
      "metadata": {
        "id": "AqxZ2PLWo9pN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to tensors (float32 for PyTorch)\n",
        "data_real = torch.tensor(real_data.values, dtype=torch.float32)\n",
        "data_synth = torch.tensor(df_synth.values, dtype=torch.float32)\n",
        "\n",
        "# ──────── Sequence builder ───────────\n",
        "def make_sequences(data, seq_len):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - seq_len):\n",
        "        X.append(data[i:i+seq_len])\n",
        "        y.append(data[i+seq_len])\n",
        "    return torch.stack(X), torch.stack(y)\n",
        "\n",
        "SEQ_LEN = sequence_length\n",
        "\n",
        "# Sequences for synthetic (train)\n",
        "X_train, y_train = make_sequences(data_synth, SEQ_LEN)\n",
        "train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=32, shuffle=True)\n",
        "\n",
        "# Sequences for real (test)\n",
        "X_test, y_test = make_sequences(data_real, SEQ_LEN)\n"
      ],
      "metadata": {
        "id": "txcyFCaxoZry"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ✧.* model definition and training ✧.*\n",
        "\n",
        "# ─── Model Definition ──────────────────────────────────────\n",
        "class ShallowLSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size=32):\n",
        "        super().__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
        "        self.linear = nn.Linear(hidden_size, input_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        _, (hn, _) = self.lstm(x)  # hn shape: (1, batch, hidden_size)\n",
        "        out = self.linear(hn.squeeze(0))  # squeeze to (batch, hidden_size)\n",
        "        return out\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Based on a study by Deswal and Kumar(2024), they indicated the following\n",
        "hyperparameters to be the best case for the dataset in their study (stock price).\n",
        "\n",
        "epoch = 200\n",
        "batch_size = 32\n",
        "neurons = 512\n",
        "learning_rate = 0.002\n",
        "dropout = 0.01\n",
        "\n",
        "*did not use yet due to long training time\n",
        "\"\"\"\n",
        "\n",
        "class TunedLSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size=64, dropout=0.01):\n",
        "        super().__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, dropout=dropout, batch_first=True)\n",
        "        self.linear = nn.Linear(hidden_size, input_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        output, _ = self.lstm(x)\n",
        "        last = output[:, -1, :]  # take the last time step\n",
        "        return self.linear(last)\n",
        "\n",
        "# ─── Model Init ─────────────────────────────────────────────\n",
        "# model = TunedLSTM(input_size=X_train.shape[2], hidden_size=64, dropout=0.01)\n",
        "model = ShallowLSTM(input_size=X_train.shape[2], hidden_size=32)\n",
        "\n",
        "# ─── Optimizer & Loss ───────────────────────────────────────\n",
        "loss_fn = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.002)\n",
        "\n",
        "# ─── Training ───────────────────────────────────────────────\n",
        "EPOCHS = 50\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    model.train()\n",
        "    for xb, yb in train_loader:\n",
        "        pred = model(xb)\n",
        "        loss = loss_fn(pred, yb)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # if epoch % 10 == 0 or epoch == 1:\n",
        "    print(f\"Epoch {epoch}: Train MSE = {loss.item():.6f}\")"
      ],
      "metadata": {
        "id": "xb92SGsLojRK",
        "outputId": "b991e148-304b-4449-8d29-7a85b01fbb02",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train MSE = 0.008179\n",
            "Epoch 2: Train MSE = 0.006505\n",
            "Epoch 3: Train MSE = 0.014976\n",
            "Epoch 4: Train MSE = 0.007806\n",
            "Epoch 5: Train MSE = 0.014187\n",
            "Epoch 6: Train MSE = 0.007589\n",
            "Epoch 7: Train MSE = 0.008203\n",
            "Epoch 8: Train MSE = 0.015628\n",
            "Epoch 9: Train MSE = 0.003408\n",
            "Epoch 10: Train MSE = 0.004471\n",
            "Epoch 11: Train MSE = 0.004497\n",
            "Epoch 12: Train MSE = 0.004948\n",
            "Epoch 13: Train MSE = 0.005701\n",
            "Epoch 14: Train MSE = 0.006819\n",
            "Epoch 15: Train MSE = 0.004917\n",
            "Epoch 16: Train MSE = 0.011983\n",
            "Epoch 17: Train MSE = 0.005745\n",
            "Epoch 18: Train MSE = 0.008743\n",
            "Epoch 19: Train MSE = 0.004548\n",
            "Epoch 20: Train MSE = 0.017778\n",
            "Epoch 21: Train MSE = 0.010611\n",
            "Epoch 22: Train MSE = 0.012294\n",
            "Epoch 23: Train MSE = 0.015670\n",
            "Epoch 24: Train MSE = 0.004537\n",
            "Epoch 25: Train MSE = 0.005124\n",
            "Epoch 26: Train MSE = 0.005350\n",
            "Epoch 27: Train MSE = 0.011767\n",
            "Epoch 28: Train MSE = 0.016959\n",
            "Epoch 29: Train MSE = 0.007853\n",
            "Epoch 30: Train MSE = 0.009425\n",
            "Epoch 31: Train MSE = 0.006724\n",
            "Epoch 32: Train MSE = 0.007729\n",
            "Epoch 33: Train MSE = 0.007413\n",
            "Epoch 34: Train MSE = 0.008648\n",
            "Epoch 35: Train MSE = 0.007312\n",
            "Epoch 36: Train MSE = 0.008073\n",
            "Epoch 37: Train MSE = 0.018112\n",
            "Epoch 38: Train MSE = 0.011701\n",
            "Epoch 39: Train MSE = 0.008965\n",
            "Epoch 40: Train MSE = 0.005803\n",
            "Epoch 41: Train MSE = 0.009075\n",
            "Epoch 42: Train MSE = 0.007696\n",
            "Epoch 43: Train MSE = 0.006830\n",
            "Epoch 44: Train MSE = 0.029330\n",
            "Epoch 45: Train MSE = 0.009580\n",
            "Epoch 46: Train MSE = 0.010740\n",
            "Epoch 47: Train MSE = 0.007004\n",
            "Epoch 48: Train MSE = 0.018231\n",
            "Epoch 49: Train MSE = 0.005825\n",
            "Epoch 50: Train MSE = 0.008296\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ✧.* model evaluation ✧.*\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    preds = model(X_test)\n",
        "    test_mse = loss_fn(preds, y_test).item()\n",
        "    test_mae = mean_absolute_error(y_test.numpy(), preds.numpy())\n",
        "\n",
        "    print(f\"Test MSE: {test_mse:.6f}\")\n",
        "    print(f\"Test MAE: {test_mae:.6f}\")"
      ],
      "metadata": {
        "id": "fKR1vr99zp5H",
        "outputId": "329d5930-a6ce-426f-b237-253fecea7e11",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test MSE: 0.054213\n",
            "Test MAE: 0.177336\n"
          ]
        }
      ]
    }
  ]
}