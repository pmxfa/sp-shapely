{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "authorship_tag": "ABX9TyPWZsjSiTolS/u1BbtYbi9K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pmxfa/sp-shapely/blob/main/sp_timevae_weather.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oaMLghK_ipz1",
        "collapsed": true,
        "outputId": "46f33b28-fc03-4318-e8f0-93f9693dfb15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xgbse-0.3.3-py3-none-any.whl (35 kB)\n",
            "Downloading fflows-0.0.3-py3-none-any.whl (19 kB)\n",
            "Downloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading monai-1.4.0-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pgmpy-1.0.0-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m87.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pycox-0.3.0-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading redis-6.0.0-py3-none-any.whl (268 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.9/268.9 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tsai-0.4.0-py3-none-any.whl (324 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m324.3/324.3 kB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.15.2-py3-none-any.whl (231 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.9/231.9 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.5.1-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.4/491.4 kB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading formulaic-1.1.1-py3-none-any.whl (115 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.7/115.7 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (277 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.0/278.0 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading py7zr-0.22.0-py3-none-any.whl (67 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.9/67.9 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_lightning-1.9.5-py3-none-any.whl (829 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m829.5/829.5 kB\u001b[0m \u001b[31m56.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyts-0.13.0-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m70.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchtext-0.17.2-cp311-cp311-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m74.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchtuples-0.2.2-py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.9/41.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading pybind11-2.13.6-py3-none-any.whl (243 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.3/243.3 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyro_ppl-1.9.1-py3-none-any.whl (755 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m756.0/756.0 kB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Brotli-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m83.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading inflate64-1.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (96 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.2/96.2 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading interface_meta-1.3.0-py3-none-any.whl (14 kB)\n",
            "Downloading lightning_utilities-0.14.3-py3-none-any.whl (28 kB)\n",
            "Downloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multivolumefile-0.2.3-py3-none-any.whl (17 kB)\n",
            "Downloading pybcj-1.0.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pycryptodomex-3.22.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m87.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyppmd-1.1.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.3/141.3 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyro_api-0.1.2-py3-none-any.whl (11 kB)\n",
            "Downloading pyzstd-0.16.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (413 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m413.7/413.7 kB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchmetrics-1.7.1-py3-none-any.whl (961 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m961.5/961.5 kB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.17.2-cp311-cp311-manylinux1_x86_64.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m99.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading texttable-1.7.0-py2.py3-none-any.whl (10 kB)\n",
            "Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading thinc-8.3.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m99.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading blis-1.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.7/11.7 MB\u001b[0m \u001b[31m119.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: nflows, arfpy, geomloss, pykeops, keopscore, autograd-gamma, feather-format\n",
            "  Building wheel for nflows (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nflows: filename=nflows-0.14-py3-none-any.whl size=53654 sha256=9a99553ccdd42957f2dd1051e7a324c1cdedf031d80aa71e3d57bcf51781d1ec\n",
            "  Stored in directory: /root/.cache/pip/wheels/11/9d/b5/5c88631a7bdb388738d147b6a28ba435ab969f25eff552f75a\n",
            "  Building wheel for arfpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for arfpy: filename=arfpy-0.1.1-py3-none-any.whl size=8664 sha256=981d879e56680775052eb67e325871ca3aa6b398b3e2af53a24954debcd63e28\n",
            "  Stored in directory: /root/.cache/pip/wheels/9b/9a/2b/0414258a3b781854c07acca132cf155a7d93b69f23c3cd6826\n",
            "  Building wheel for geomloss (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for geomloss: filename=geomloss-0.2.6-py3-none-any.whl size=32247 sha256=1d762736af998fbd27424b7d11919c77491868d2578ff61b33ffb82b32890212\n",
            "  Stored in directory: /root/.cache/pip/wheels/f5/cf/07/9d1d883feac2951b968fed8ef676842dc90b9860ea49a4dcac\n",
            "  Building wheel for pykeops (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pykeops: filename=pykeops-2.3-py3-none-any.whl size=120491 sha256=92197227c96b579beb28f2831a9458b409430844a446d29f2b3f884f7743f33e\n",
            "  Stored in directory: /root/.cache/pip/wheels/a8/91/ea/d9e54997a840e38595b9a2c5b9021f3969173edbda2fc99686\n",
            "  Building wheel for keopscore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keopscore: filename=keopscore-2.3-py3-none-any.whl size=185897 sha256=d51768694d43da317a6b5571eaf1f29ce8cd165d525fb508d94b38f72572fc53\n",
            "  Stored in directory: /root/.cache/pip/wheels/32/77/92/17707f162cb65cfa8e97f0360cdb30681038f7762cf929b1b4\n",
            "  Building wheel for autograd-gamma (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for autograd-gamma: filename=autograd_gamma-0.5.0-py3-none-any.whl size=4030 sha256=138621248c6095672d408062fbb16e1c42cce7336c1dca596cdb4e301dae761d\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/67/f4/2caaae2146198dcb824f31a303833b07b14a5ec863fb3acd7b\n",
            "  Building wheel for feather-format (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for feather-format: filename=feather_format-0.4.1-py3-none-any.whl size=2434 sha256=81e15e784c2da315e0d41ab962f80faac45e2a04908a17432655b26e44663e69\n",
            "  Stored in directory: /root/.cache/pip/wheels/77/5b/0e/0e63d10b6353208a085a321ea2eed2578f220a77bb8a4bd7ab\n",
            "Successfully built nflows arfpy geomloss pykeops keopscore autograd-gamma feather-format\n",
            "Installing collected packages: texttable, pyro-api, brotli, xxhash, triton, redis, pyzstd, pyppmd, pydantic, pycryptodomex, pybind11, pybcj, psutil, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, multivolumefile, loguru, lightning-utilities, keopscore, interface-meta, inflate64, fsspec, feather-format, dill, colorlog, pykeops, py7zr, nvidia-cusolver-cu12, nvidia-cudnn-cu12, multiprocess, blis, alembic, torch, thinc, optuna, formulaic, autograd-gamma, torchvision, torchtuples, torchtext, torchmetrics, pyts, pyro-ppl, opacus, nflows, monai, lifelines, geomloss, fflows, datasets, arfpy, xgbse, pytorch-lightning, pycox, pgmpy, be-great, decaf-synthetic-data, tsai, synthcity\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.11.3\n",
            "    Uninstalling pydantic-2.11.3:\n",
            "      Successfully uninstalled pydantic-2.11.3\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 5.9.5\n",
            "    Uninstalling psutil-5.9.5:\n",
            "      Successfully uninstalled psutil-5.9.5\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.21.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.21.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.4.2\n",
            "    Uninstalling networkx-3.4.2:\n",
            "      Successfully uninstalled networkx-3.4.2\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: blis\n",
            "    Found existing installation: blis 1.3.0\n",
            "    Uninstalling blis-1.3.0:\n",
            "      Successfully uninstalled blis-1.3.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n",
            "      Successfully uninstalled torch-2.6.0+cu124\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 8.3.6\n",
            "    Uninstalling thinc-8.3.6:\n",
            "      Successfully uninstalled thinc-8.3.6\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.21.0+cu124\n",
            "    Uninstalling torchvision-0.21.0+cu124:\n",
            "      Successfully uninstalled torchvision-0.21.0+cu124\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-genai 1.12.1 requires pydantic<3.0.0,>=2.0.0, but you have pydantic 1.10.22 which is incompatible.\n",
            "nx-cugraph-cu12 25.2.0 requires networkx>=3.2, but you have networkx 2.8.8 which is incompatible.\n",
            "langchain-core 0.3.56 requires pydantic<3.0.0,>=2.5.2; python_full_version < \"3.12.4\", but you have pydantic 1.10.22 which is incompatible.\n",
            "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.2.2 which is incompatible.\n",
            "scikit-image 0.25.2 requires networkx>=3.0, but you have networkx 2.8.8 which is incompatible.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\n",
            "langchain 0.3.24 requires pydantic<3.0.0,>=2.7.4, but you have pydantic 1.10.22 which is incompatible.\n",
            "albumentations 2.0.6 requires pydantic>=2.9.2, but you have pydantic 1.10.22 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed alembic-1.15.2 arfpy-0.1.1 autograd-gamma-0.5.0 be-great-0.0.8 blis-1.2.1 brotli-1.1.0 colorlog-6.9.0 datasets-3.5.1 decaf-synthetic-data-0.1.6 dill-0.3.8 feather-format-0.4.1 fflows-0.0.3 formulaic-1.1.1 fsspec-2025.3.0 geomloss-0.2.6 inflate64-1.0.1 interface-meta-1.3.0 keopscore-2.3 lifelines-0.29.0 lightning-utilities-0.14.3 loguru-0.7.3 monai-1.4.0 multiprocess-0.70.16 multivolumefile-0.2.3 networkx-2.8.8 nflows-0.14 numpy-1.26.4 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvtx-cu12-12.1.105 opacus-1.5.3 optuna-4.3.0 pgmpy-1.0.0 psutil-7.0.0 py7zr-0.22.0 pybcj-1.0.6 pybind11-2.13.6 pycox-0.3.0 pycryptodomex-3.22.0 pydantic-1.10.22 pykeops-2.3 pyppmd-1.1.1 pyro-api-0.1.2 pyro-ppl-1.9.1 pytorch-lightning-1.9.5 pyts-0.13.0 pyzstd-0.16.2 redis-6.0.0 synthcity-0.2.11 texttable-1.7.0 thinc-8.3.4 torch-2.2.2 torchmetrics-1.7.1 torchtext-0.17.2 torchtuples-0.2.2 torchvision-0.17.2 triton-2.2.0 tsai-0.4.0 xgbse-0.3.3 xxhash-3.5.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "psutil"
                ]
              },
              "id": "ade04b96b13e43dba1fdf486ec181a0b"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install synthcity"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "NcwQ6Yo09JC8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import sys\n",
        "import warnings\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "import synthcity.logger as log\n",
        "from synthcity.plugins import Plugins\n",
        "from synthcity.plugins.core.dataloader import TimeSeriesDataLoader\n",
        "from synthcity.utils.serialization import save_to_file, load_from_file\n",
        "\n",
        "log.add(sink=sys.stderr, level=\"INFO\")"
      ],
      "metadata": {
        "id": "kfDi7FQF9LIv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbe51433-50ac-46a1-91b3-5451ce3bad26",
        "collapsed": true
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "[KeOps] Compiling cuda jit compiler engine ... OK\n",
            "[pyKeOps] Compiling nvrtc binder for python ... OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define file path\n",
        "file_path = \"/content/drive/Shareddrives/sp_env/datasets/Weather/weather.csv\"\n",
        "\n",
        "df = pd.read_csv(file_path)\n",
        "print(df.head())\n",
        "print(df.info())\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "id": "DCLsmN-F9NGv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1453f91d-ecf3-4bb2-938b-341eafd77cb6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                  date  p (mbar)  T (degC)  Tpot (K)  Tdew (degC)  rh (%)  \\\n",
            "0  2020-01-01 00:10:00   1008.89      0.71    273.18        -1.33    86.1   \n",
            "1  2020-01-01 00:20:00   1008.76      0.75    273.22        -1.44    85.2   \n",
            "2  2020-01-01 00:30:00   1008.66      0.73    273.21        -1.48    85.1   \n",
            "3  2020-01-01 00:40:00   1008.64      0.37    272.86        -1.64    86.3   \n",
            "4  2020-01-01 00:50:00   1008.61      0.33    272.82        -1.50    87.4   \n",
            "\n",
            "   VPmax (mbar)  VPact (mbar)  VPdef (mbar)  sh (g/kg)  ...  wv (m/s)  \\\n",
            "0          6.43          5.54          0.89       3.42  ...      1.02   \n",
            "1          6.45          5.49          0.95       3.39  ...      0.43   \n",
            "2          6.44          5.48          0.96       3.39  ...      0.61   \n",
            "3          6.27          5.41          0.86       3.35  ...      1.11   \n",
            "4          6.26          5.47          0.79       3.38  ...      0.49   \n",
            "\n",
            "   max. wv (m/s)  wd (deg)  rain (mm)  raining (s)  SWDR (W/m�)  \\\n",
            "0           1.60     224.3        0.0          0.0          0.0   \n",
            "1           0.84     206.8        0.0          0.0          0.0   \n",
            "2           1.48     197.1        0.0          0.0          0.0   \n",
            "3           1.48     206.4        0.0          0.0          0.0   \n",
            "4           1.40     209.6        0.0          0.0          0.0   \n",
            "\n",
            "   PAR (�mol/m�/s)  max. PAR (�mol/m�/s)  Tlog (degC)     OT  \n",
            "0              0.0                   0.0        11.45  428.1  \n",
            "1              0.0                   0.0        11.51  428.0  \n",
            "2              0.0                   0.0        11.60  427.6  \n",
            "3              0.0                   0.0        11.70  430.0  \n",
            "4              0.0                   0.0        11.81  432.2  \n",
            "\n",
            "[5 rows x 22 columns]\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 52696 entries, 0 to 52695\n",
            "Data columns (total 22 columns):\n",
            " #   Column                Non-Null Count  Dtype  \n",
            "---  ------                --------------  -----  \n",
            " 0   date                  52696 non-null  object \n",
            " 1   p (mbar)              52696 non-null  float64\n",
            " 2   T (degC)              52696 non-null  float64\n",
            " 3   Tpot (K)              52696 non-null  float64\n",
            " 4   Tdew (degC)           52696 non-null  float64\n",
            " 5   rh (%)                52696 non-null  float64\n",
            " 6   VPmax (mbar)          52696 non-null  float64\n",
            " 7   VPact (mbar)          52696 non-null  float64\n",
            " 8   VPdef (mbar)          52696 non-null  float64\n",
            " 9   sh (g/kg)             52696 non-null  float64\n",
            " 10  H2OC (mmol/mol)       52696 non-null  float64\n",
            " 11  rho (g/m**3)          52696 non-null  float64\n",
            " 12  wv (m/s)              52696 non-null  float64\n",
            " 13  max. wv (m/s)         52696 non-null  float64\n",
            " 14  wd (deg)              52696 non-null  float64\n",
            " 15  rain (mm)             52696 non-null  float64\n",
            " 16  raining (s)           52696 non-null  float64\n",
            " 17  SWDR (W/m�)           52696 non-null  float64\n",
            " 18  PAR (�mol/m�/s)       52696 non-null  float64\n",
            " 19  max. PAR (�mol/m�/s)  52696 non-null  float64\n",
            " 20  Tlog (degC)           52696 non-null  float64\n",
            " 21  OT                    52696 non-null  float64\n",
            "dtypes: float64(21), object(1)\n",
            "memory usage: 8.8+ MB\n",
            "None\n",
            "date                    0\n",
            "p (mbar)                0\n",
            "T (degC)                0\n",
            "Tpot (K)                0\n",
            "Tdew (degC)             0\n",
            "rh (%)                  0\n",
            "VPmax (mbar)            0\n",
            "VPact (mbar)            0\n",
            "VPdef (mbar)            0\n",
            "sh (g/kg)               0\n",
            "H2OC (mmol/mol)         0\n",
            "rho (g/m**3)            0\n",
            "wv (m/s)                0\n",
            "max. wv (m/s)           0\n",
            "wd (deg)                0\n",
            "rain (mm)               0\n",
            "raining (s)             0\n",
            "SWDR (W/m�)             0\n",
            "PAR (�mol/m�/s)         0\n",
            "max. PAR (�mol/m�/s)    0\n",
            "Tlog (degC)             0\n",
            "OT                      0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Convert 'date' to datetime and set as index (preserves chronological order)\n",
        "df['date'] = pd.to_datetime(df['date'])\n",
        "df.set_index('date', inplace=True)\n",
        "df.sort_index(inplace=True)\n",
        "\n",
        "# Exclude 'date' from feature selection (it's now the index anyway)\n",
        "columns = df.columns  # 'date' is no longer in df.columns\n",
        "selected_features = np.random.choice(columns, size=10, replace=False)\n",
        "\n",
        "print(f\"Selected features: {selected_features}\")\n",
        "\n",
        "# Keep only the selected features\n",
        "df = df[selected_features]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m36lw5xogSIN",
        "outputId": "dbfd1f2e-0453-4eb5-bf01-8690674ec1dc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected features: ['p (mbar)' 'PAR (�mol/m�/s)' 'raining (s)' 'T (degC)' 'sh (g/kg)'\n",
            " 'VPmax (mbar)' 'wv (m/s)' 'Tdew (degC)' 'max. PAR (�mol/m�/s)'\n",
            " 'SWDR (W/m�)']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9yoUqyz4oUx9",
        "outputId": "46edf613-1b4e-43b1-ce0b-8111d54ef9df"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                     p (mbar)  PAR (�mol/m�/s)  raining (s)  T (degC)  \\\n",
            "date                                                                    \n",
            "2020-01-01 00:10:00   1008.89              0.0          0.0      0.71   \n",
            "2020-01-01 00:20:00   1008.76              0.0          0.0      0.75   \n",
            "2020-01-01 00:30:00   1008.66              0.0          0.0      0.73   \n",
            "2020-01-01 00:40:00   1008.64              0.0          0.0      0.37   \n",
            "2020-01-01 00:50:00   1008.61              0.0          0.0      0.33   \n",
            "\n",
            "                     sh (g/kg)  VPmax (mbar)  wv (m/s)  Tdew (degC)  \\\n",
            "date                                                                  \n",
            "2020-01-01 00:10:00       3.42          6.43      1.02        -1.33   \n",
            "2020-01-01 00:20:00       3.39          6.45      0.43        -1.44   \n",
            "2020-01-01 00:30:00       3.39          6.44      0.61        -1.48   \n",
            "2020-01-01 00:40:00       3.35          6.27      1.11        -1.64   \n",
            "2020-01-01 00:50:00       3.38          6.26      0.49        -1.50   \n",
            "\n",
            "                     max. PAR (�mol/m�/s)  SWDR (W/m�)  \n",
            "date                                                    \n",
            "2020-01-01 00:10:00                   0.0          0.0  \n",
            "2020-01-01 00:20:00                   0.0          0.0  \n",
            "2020-01-01 00:30:00                   0.0          0.0  \n",
            "2020-01-01 00:40:00                   0.0          0.0  \n",
            "2020-01-01 00:50:00                   0.0          0.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Keep the latest 5000 rows\n",
        "df_latest = df.tail(5000)\n",
        "\n",
        "# Train-test split: 70% for training, 30% for testing (TSTR)\n",
        "train_size = int(0.7 * len(df_latest))\n",
        "df_train = df_latest.iloc[:train_size]\n",
        "df_test = df_latest.iloc[train_size:]  # use later for LSTM-TSTR\n",
        "\n",
        "# Normalize the data\n",
        "scaler = MinMaxScaler()\n",
        "scaled_train = scaler.fit_transform(df_train)\n",
        "df_scaled_train = pd.DataFrame(scaled_train, columns=df_train.columns, index=df_train.index)\n",
        "scaled_test = scaler.transform(df_test)\n",
        "df_scaled_test = pd.DataFrame(scaled_train, columns=df_train.columns, index=df_train.index)\n",
        "\n",
        "# Sequence length for time-series data (dataset = hourly; 24 hours)\n",
        "sequence_length = 36\n",
        "temporal_data = []\n",
        "observation_times = []\n",
        "\n",
        "# Generate sequences from df_scaled_train only\n",
        "for start in range(len(df_scaled_train) - sequence_length + 1):\n",
        "    sequence = df_scaled_train.iloc[start:start + sequence_length].reset_index(drop=True)\n",
        "    temporal_data.append(sequence)\n",
        "    observation_times.append(list(range(sequence_length)))  # relative time within the window\n",
        "\n",
        "dummy_outcome = pd.DataFrame(np.zeros(len(temporal_data)), columns=[\"outcome\"])\n",
        "\n",
        "loader = TimeSeriesDataLoader(\n",
        "    temporal_data=temporal_data,\n",
        "    observation_times=observation_times,\n",
        "    static_data=None,\n",
        "    outcome=dummy_outcome,\n",
        ")\n",
        "\n",
        "# Print the loader info\n",
        "print(f\"TimeSeriesDataLoader created with {len(temporal_data)} sequences\")"
      ],
      "metadata": {
        "id": "siWRiBtn9O0V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0154da2b-d542-4ddb-9562-16775651ea01"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TimeSeriesDataLoader created with 3465 sequences\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(df_scaled_train))  # Check the length of the dataframe\n",
        "print(loader.dataframe())"
      ],
      "metadata": {
        "id": "FmZe08FM9Rd0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60f46319-c5ab-4f59-98ea-21ff0af36814"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3500\n",
            "        seq_id  seq_time_id  seq_temporal_PAR (�mol/m�/s)  \\\n",
            "0            0            0                      0.000000   \n",
            "1            0            1                      0.000000   \n",
            "2            0            2                      0.000000   \n",
            "3            0            3                      0.000000   \n",
            "4            0            4                      0.000000   \n",
            "...        ...          ...                           ...   \n",
            "124735    3464           31                      0.379520   \n",
            "124736    3464           32                      0.396154   \n",
            "124737    3464           33                      0.397787   \n",
            "124738    3464           34                      0.451815   \n",
            "124739    3464           35                      0.408922   \n",
            "\n",
            "        seq_temporal_SWDR (W/m�)  seq_temporal_T (degC)  \\\n",
            "0                       0.000000               0.114042   \n",
            "1                       0.000000               0.127230   \n",
            "2                       0.000000               0.148177   \n",
            "3                       0.000000               0.150504   \n",
            "4                       0.000000               0.149728   \n",
            "...                          ...                    ...   \n",
            "124735                  0.341668               0.576416   \n",
            "124736                  0.359281               0.577192   \n",
            "124737                  0.362148               0.577967   \n",
            "124738                  0.419480               0.589604   \n",
            "124739                  0.379857               0.605120   \n",
            "\n",
            "        seq_temporal_Tdew (degC)  seq_temporal_VPmax (mbar)  \\\n",
            "0                       0.391513                   0.077118   \n",
            "1                       0.397918                   0.087231   \n",
            "2                       0.403523                   0.102402   \n",
            "3                       0.403523                   0.103666   \n",
            "4                       0.409127                   0.103666   \n",
            "...                          ...                        ...   \n",
            "124735                  0.741393                   0.479140   \n",
            "124736                  0.742994                   0.479140   \n",
            "124737                  0.744596                   0.480405   \n",
            "124738                  0.751001                   0.493047   \n",
            "124739                  0.760608                   0.508217   \n",
            "\n",
            "        seq_temporal_max. PAR (�mol/m�/s)  seq_temporal_p (mbar)  \\\n",
            "0                                0.000000               0.837838   \n",
            "1                                0.000000               0.837838   \n",
            "2                                0.000000               0.840744   \n",
            "3                                0.000000               0.841325   \n",
            "4                                0.000000               0.839872   \n",
            "...                                   ...                    ...   \n",
            "124735                           0.332190               0.856437   \n",
            "124736                           0.339379               0.855856   \n",
            "124737                           0.349280               0.854693   \n",
            "124738                           0.385717               0.854403   \n",
            "124739                           0.357129               0.852950   \n",
            "\n",
            "        seq_temporal_raining (s)  seq_temporal_sh (g/kg)  \\\n",
            "0                            0.0                0.292105   \n",
            "1                            0.0                0.297368   \n",
            "2                            0.0                0.302632   \n",
            "3                            0.0                0.302632   \n",
            "4                            0.0                0.307895   \n",
            "...                          ...                     ...   \n",
            "124735                       0.0                0.655263   \n",
            "124736                       0.0                0.657895   \n",
            "124737                       0.0                0.657895   \n",
            "124738                       0.0                0.665789   \n",
            "124739                       0.0                0.676316   \n",
            "\n",
            "        seq_temporal_wv (m/s)  seq_out_outcome  \n",
            "0                    0.132780              0.0  \n",
            "1                    0.055325              0.0  \n",
            "2                    0.051176              0.0  \n",
            "3                    0.110650              0.0  \n",
            "4                    0.087137              0.0  \n",
            "...                       ...              ...  \n",
            "124735               0.412172              0.0  \n",
            "124736               0.420470              0.0  \n",
            "124737               0.388658              0.0  \n",
            "124738               0.271093              0.0  \n",
            "124739               0.312586              0.0  \n",
            "\n",
            "[124740 rows x 13 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "syn_model = Plugins().get(\"timevae\")"
      ],
      "metadata": {
        "id": "oYqRdbxl9W74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d4d1f21-56aa-4b35-b797-ea7517433e53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2025-05-01T08:18:03.503116+0000][1547][CRITICAL] module disabled: /usr/local/lib/python3.11/dist-packages/synthcity/plugins/generic/plugin_goggle.py\n",
            "[2025-05-01T08:18:03.503116+0000][1547][CRITICAL] module disabled: /usr/local/lib/python3.11/dist-packages/synthcity/plugins/generic/plugin_goggle.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print all parameters of initialized model\n",
        "for attr in dir(syn_model):\n",
        "    if not attr.startswith(\"_\") and not callable(getattr(syn_model, attr)):\n",
        "        print(f\"{attr}: {getattr(syn_model, attr)}\")"
      ],
      "metadata": {
        "id": "y9ZVw8pT9Y_Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be7dcb36-d265-4f2f-a9fe-826ba45409d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch_size: 64\n",
            "class_name: TimeVAEPlugin\n",
            "clipping_value: 0\n",
            "compress_dataset: False\n",
            "decoder_batch_norm: False\n",
            "decoder_dropout: 0.01\n",
            "decoder_n_layers_hidden: 2\n",
            "decoder_n_units_hidden: 150\n",
            "decoder_nonlin: leaky_relu\n",
            "decoder_nonlin_out_continuous: tanh\n",
            "decoder_nonlin_out_discrete: softmax\n",
            "decoder_residual: True\n",
            "device: cuda\n",
            "embedding_penalty: 10\n",
            "encoder: None\n",
            "encoder_batch_norm: False\n",
            "encoder_dropout: 0.1\n",
            "encoder_max_clusters: 20\n",
            "encoder_n_layers_hidden: 3\n",
            "encoder_n_units_hidden: 300\n",
            "encoder_nonlin: leaky_relu\n",
            "expecting_conditional: False\n",
            "fitted: False\n",
            "gamma_penalty: 1\n",
            "lr: 0.001\n",
            "mode: LSTM\n",
            "module_name: synthcity.plugins.time_series.plugin_timevae\n",
            "module_relative_path: ../time_series/plugin_timevae.py\n",
            "moments_penalty: 100\n",
            "n_iter: 1000\n",
            "n_iter_print: 10\n",
            "outcome_encoder: TabularEncoder(cat_encoder_params={'handle_unknown': 'ignore',\n",
            "                                   'sparse_output': False},\n",
            "               categorical_encoder='onehot',\n",
            "               cont_encoder_params={'n_components': 20},\n",
            "               continuous_encoder='bayesian_gmm', max_clusters=20)\n",
            "random_state: 0\n",
            "sampling_patience: 500\n",
            "sampling_strategy: marginal\n",
            "strict: True\n",
            "weight_decay: 0.001\n",
            "workspace: workspace\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## fitting the model"
      ],
      "metadata": {
        "id": "IKG0O5Pg9hpG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(loader.shape)\n",
        "# Train the model\n",
        "syn_model.fit(loader)"
      ],
      "metadata": {
        "id": "-BKXe4G19l_8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63cc7ab0-127d-4a76-e2d7-8dad5700ed65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(124740, 13)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<synthcity.plugins.time_series.plugin_timevae.TimeVAEPlugin at 0x7f29e3a87f50>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_to_file('/content/drive/Shareddrives/sp_env/saved_models/VAE_Weather.pkl', syn_model)"
      ],
      "metadata": {
        "id": "4_28A0BLm_0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Generate Synthetic Data ---\n",
        "n_samples = len(temporal_data)\n",
        "syn_data = syn_model.generate(count=n_samples)\n",
        "print(syn_data.shape)"
      ],
      "metadata": {
        "id": "JviqEDru9nMO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbfc65fd-5fac-4df4-cfb5-0c8ec43c0513"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(124740, 13)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Save with automated format ---\n",
        "import datetime\n",
        "import os\n",
        "# Get the current date and time\n",
        "now = datetime.datetime.now()\n",
        "timestamp = now.strftime(\"%m%d%y-%H%M%S\")  # MMDDYY-HHMMSS format\n",
        "\n",
        "# Define the base directory\n",
        "base_dir = \"/content/drive/Shareddrives/sp_env/synthetic_datasets/TimeVAE/weather\"  #CHANGE THIS\n",
        "if not os.path.exists(base_dir):\n",
        "    os.makedirs(base_dir)\n",
        "\n",
        "# Construct the filename\n",
        "model_name = type(syn_model).__name__.lower() # Get model name dynamically\n",
        "filename = f\"{timestamp}-{model_name}-n_3000.csv\"\n",
        "filepath = os.path.join(base_dir, filename)\n",
        "\n",
        "# Save the data\n",
        "df_syn = syn_data.dataframe()\n",
        "df_syn.to_csv(filepath, index=False)\n",
        "\n",
        "print(f\"Synthetic data saved to: {filepath}\")"
      ],
      "metadata": {
        "id": "J4rF0HY29o65",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "598c59ca-8585-45a7-ccfb-7f621882951f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synthetic data saved to: /content/drive/Shareddrives/sp_env/synthetic_datasets/TimeVAE/weather/050125-085757-timevaeplugin-n_3000.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "TICnBaoH9r8Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prerequisites"
      ],
      "metadata": {
        "id": "QlHAzxfV9uXf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "selected_columns = ['seq_temporal_PAR (�mol/m�/s)', 'seq_temporal_SWDR (W/m�)', 'seq_temporal_T (degC)',\t'seq_temporal_Tdew (degC)',\t'seq_temporal_VPmax (mbar)',\t'seq_temporal_max. PAR (�mol/m�/s)',\t'seq_temporal_p (mbar)',\t'seq_temporal_raining (s)',\t'seq_temporal_sh (g/kg)',\t'seq_temporal_wv (m/s)']\n",
        "# Ensure real_data and synthetic_data only contain the selected columns\n",
        "real_data = loader.dataframe()[selected_columns].to_numpy()\n",
        "synthetic_data = syn_data.dataframe()[selected_columns].to_numpy()"
      ],
      "metadata": {
        "id": "zUMHadsq9vw8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(real_data, \"\\n ------------------------------------------------------- \\n\", synthetic_data)\n",
        "print(type(real_data),type(synthetic_data))\n",
        "print(real_data.shape,synthetic_data.shape)"
      ],
      "metadata": {
        "id": "DumXr_Gg9y6U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54eb3775-41cb-4cad-bf78-4a9307e3ffac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.         0.         0.11404189 ... 0.         0.29210526 0.13278008]\n",
            " [0.         0.         0.12723041 ... 0.         0.29736842 0.05532503]\n",
            " [0.         0.         0.14817688 ... 0.         0.30263158 0.05117566]\n",
            " ...\n",
            " [0.39778664 0.36214804 0.57796742 ... 0.         0.65789474 0.38865837]\n",
            " [0.45181468 0.41948019 0.58960434 ... 0.         0.66578947 0.27109267]\n",
            " [0.40892219 0.37985731 0.60512025 ... 0.         0.67631579 0.31258645]] \n",
            " ------------------------------------------------------- \n",
            " [[0.55969194 0.16735992 0.63528333 ... 0.05576173 0.38321587 0.24738849]\n",
            " [0.0497281  0.18382783 0.19698515 ... 0.26311472 0.7505566  0.42824979]\n",
            " [0.180474   0.16735992 0.26041931 ... 0.51152689 0.49017772 0.38798876]\n",
            " ...\n",
            " [0.11980377 0.14982813 0.11016495 ... 0.03436267 0.03389352 0.04138451]\n",
            " [0.31936363 0.44767405 0.77762817 ... 0.05091336 0.5704801  0.5044388 ]\n",
            " [0.180474   0.44767405 0.4841849  ... 0.26311472 0.7505566  0.1886928 ]]\n",
            "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
            "(124740, 10) (124740, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate distance metrics"
      ],
      "metadata": {
        "id": "0pU8BORS9vWk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Helper Functions"
      ],
      "metadata": {
        "id": "DVguOJWi-Fos"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import wasserstein_distance, entropy\n",
        "import numpy as np\n",
        "\n",
        "def compute_wasserstein(real_data, synthetic_data, selected_columns):\n",
        "    \"\"\"\n",
        "    Computes Wasserstein Distance between real and synthetic time-series data.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # Ensure both datasets have the same number of samples\n",
        "    min_length = min(len(real_data), len(synthetic_data))\n",
        "    real_trimmed = real_data[:min_length]  # Keep original order (no random sampling)\n",
        "    synthetic_trimmed = synthetic_data[:min_length]  # Match size\n",
        "    print(real_trimmed.shape,synthetic_trimmed.shape)\n",
        "\n",
        "    wasserstein_results = {}\n",
        "\n",
        "    # Compute Wasserstein Distance for each feature\n",
        "    for i, col in enumerate(selected_columns):\n",
        "        w_dist = wasserstein_distance(real_trimmed[:, i], synthetic_trimmed[:, i])\n",
        "        wasserstein_results[col] = w_dist\n",
        "        print(f\"{w_dist}\")\n",
        "\n",
        "    return wasserstein_results\n",
        "\n",
        "def compute_kl_divergence(real_data, synthetic_data, selected_columns, bins=50):\n",
        "    \"\"\"\n",
        "    Computes KL Divergence between real and synthetic time-series data.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # Ensure both datasets have the same number of samples\n",
        "    min_length = min(len(real_data), len(synthetic_data))\n",
        "    real_trimmed = real_data[:min_length]  # Keep original order\n",
        "    synthetic_trimmed = synthetic_data[:min_length]  # Match size\n",
        "\n",
        "    kl_results = {}\n",
        "\n",
        "    for i, col in enumerate(selected_columns):\n",
        "        # Compute histogram-based probability distributions\n",
        "        real_hist, _ = np.histogram(real_trimmed[:, i], bins=bins, density=True)\n",
        "        synth_hist, _ = np.histogram(synthetic_trimmed[:, i], bins=bins, density=True)\n",
        "\n",
        "        # Avoid zero probabilities (KL Divergence is undefined for zero values)\n",
        "        real_hist += 1e-10\n",
        "        synth_hist += 1e-10\n",
        "\n",
        "        # Compute KL Divergence\n",
        "        kl_div = entropy(real_hist, synth_hist)\n",
        "        kl_results[col] = kl_div\n",
        "        print(f\"{kl_div}\")\n",
        "\n",
        "    return kl_results"
      ],
      "metadata": {
        "id": "GjGk3_Zx94Ko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate Metrics"
      ],
      "metadata": {
        "id": "yLnb7Vqg-IG_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute Wasserstein Distance\n",
        "wasserstein_results = compute_wasserstein(real_data, synthetic_data, selected_columns)\n",
        "print(\"Wasserstein Distance Results:\")\n",
        "print(wasserstein_results)\n",
        "\n",
        "# Compute KL Divergence\n",
        "kl_results = compute_kl_divergence(real_data, synthetic_data, selected_columns)\n",
        "print(\"KL Divergence Results:\")\n",
        "print(kl_results)"
      ],
      "metadata": {
        "id": "olm0RYP89-SN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc737e45-65f5-4364-e71b-b684c31765fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(124740, 10) (124740, 10)\n",
            "0.23688909792139168\n",
            "0.2719719388618763\n",
            "0.0762417138134981\n",
            "0.05476511070850991\n",
            "0.09085458536974098\n",
            "0.23815391921701956\n",
            "0.04997520085512207\n",
            "0.22812857509092654\n",
            "0.05684131195725542\n",
            "0.100859472522241\n",
            "Wasserstein Distance Results:\n",
            "{'seq_temporal_PAR (�mol/m�/s)': 0.23688909792139168, 'seq_temporal_SWDR (W/m�)': 0.2719719388618763, 'seq_temporal_T (degC)': 0.0762417138134981, 'seq_temporal_Tdew (degC)': 0.05476511070850991, 'seq_temporal_VPmax (mbar)': 0.09085458536974098, 'seq_temporal_max. PAR (�mol/m�/s)': 0.23815391921701956, 'seq_temporal_p (mbar)': 0.04997520085512207, 'seq_temporal_raining (s)': 0.22812857509092654, 'seq_temporal_sh (g/kg)': 0.05684131195725542, 'seq_temporal_wv (m/s)': 0.100859472522241}\n",
            "5.504778274928425\n",
            "5.737495614674456\n",
            "10.290058391681391\n",
            "11.859912164992515\n",
            "10.899121662615698\n",
            "5.124645057980104\n",
            "12.473151583968384\n",
            "3.2007951587861703\n",
            "11.812102565594072\n",
            "12.577014140504607\n",
            "KL Divergence Results:\n",
            "{'seq_temporal_PAR (�mol/m�/s)': 5.504778274928425, 'seq_temporal_SWDR (W/m�)': 5.737495614674456, 'seq_temporal_T (degC)': 10.290058391681391, 'seq_temporal_Tdew (degC)': 11.859912164992515, 'seq_temporal_VPmax (mbar)': 10.899121662615698, 'seq_temporal_max. PAR (�mol/m�/s)': 5.124645057980104, 'seq_temporal_p (mbar)': 12.473151583968384, 'seq_temporal_raining (s)': 3.2007951587861703, 'seq_temporal_sh (g/kg)': 11.812102565594072, 'seq_temporal_wv (m/s)': 12.577014140504607}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM downstream"
      ],
      "metadata": {
        "id": "UpJLIRUZChiz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filepath = \"/content/drive/Shareddrives/sp_env/synthetic_datasets/TimeVAE/weather/050125-085757-timevaeplugin-n_3000.csv\""
      ],
      "metadata": {
        "id": "qVI6XPh8KHQz"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"real_data: {real_data.shape}, synthetic_data: {df_synth.shape}\")"
      ],
      "metadata": {
        "id": "ShEEO5GlKXSK",
        "outputId": "45f469ae-ef89-4cac-e3ac-f96a9e424a04",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "real_data: (3500, 10), synthetic_data: (124740, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "real_data = df_scaled_test\n",
        "df_synth = pd.read_csv(filepath)\n",
        "\n",
        "# Drop the unwanted column\n",
        "real_data = real_data.drop(columns=[\"seq_id\", \"seq_time_id\", \"seq_out_outcome\"], errors=\"ignore\")\n",
        "df_synth = df_synth.drop(columns=[\"seq_id\", \"seq_time_id\", \"seq_out_outcome\"], errors=\"ignore\")\n",
        ""
      ],
      "metadata": {
        "id": "OhcWWnI8JCF1"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error"
      ],
      "metadata": {
        "id": "y1Gg4O5bnOWp"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to tensors (float32 for PyTorch)\n",
        "data_real = torch.tensor(real_data.values, dtype=torch.float32)\n",
        "data_synth = torch.tensor(df_synth.values, dtype=torch.float32)\n",
        "\n",
        "# ──────── Sequence builder ───────────\n",
        "def make_sequences(data, seq_len):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - seq_len):\n",
        "        X.append(data[i:i+seq_len])\n",
        "        y.append(data[i+seq_len])\n",
        "    return torch.stack(X), torch.stack(y)\n",
        "\n",
        "SEQ_LEN = sequence_length\n",
        "\n",
        "# Sequences for synthetic (train)\n",
        "X_train, y_train = make_sequences(data_synth, SEQ_LEN)\n",
        "train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=32, shuffle=True)\n",
        "\n",
        "# Sequences for real (test)\n",
        "X_test, y_test = make_sequences(data_real, SEQ_LEN)"
      ],
      "metadata": {
        "id": "4XQyd3HLnPFj"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ─── Model Definition ──────────────────────────────────────\n",
        "class ShallowLSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size=64):\n",
        "        super().__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
        "        self.linear = nn.Linear(hidden_size, input_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        _, (hn, _) = self.lstm(x)  # hn shape: (1, batch, hidden_size)\n",
        "        out = self.linear(hn.squeeze(0))  # squeeze to (batch, hidden_size)\n",
        "        return out\n",
        "\n",
        "\n",
        "# ─── Model Init ─────────────────────────────────────────────\n",
        "model = ShallowLSTM(input_size=X_train.shape[2], hidden_size=64)\n",
        "\n",
        "# ─── Optimizer & Loss ───────────────────────────────────────\n",
        "loss_fn = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.002)\n",
        "\n",
        "# ─── Training ───────────────────────────────────────────────\n",
        "EPOCHS = 50\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    model.train()\n",
        "    for xb, yb in train_loader:\n",
        "        pred = model(xb)\n",
        "        loss = loss_fn(pred, yb)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # if epoch % 10 == 0 or epoch == 1:\n",
        "    print(f\"Epoch {epoch}: Train MSE = {loss.item():.6f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v74HfVJZnQDI",
        "outputId": "0d93db11-6df5-4e4c-c9b3-15ce310c3517"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train MSE = 0.061166\n",
            "Epoch 2: Train MSE = 0.055942\n",
            "Epoch 3: Train MSE = 0.062349\n",
            "Epoch 4: Train MSE = 0.055855\n",
            "Epoch 5: Train MSE = 0.056223\n",
            "Epoch 6: Train MSE = 0.061403\n",
            "Epoch 7: Train MSE = 0.055855\n",
            "Epoch 8: Train MSE = 0.058057\n",
            "Epoch 9: Train MSE = 0.054990\n",
            "Epoch 10: Train MSE = 0.059917\n",
            "Epoch 11: Train MSE = 0.058516\n",
            "Epoch 12: Train MSE = 0.055999\n",
            "Epoch 13: Train MSE = 0.060728\n",
            "Epoch 14: Train MSE = 0.062357\n",
            "Epoch 15: Train MSE = 0.054606\n",
            "Epoch 16: Train MSE = 0.051315\n",
            "Epoch 17: Train MSE = 0.057704\n",
            "Epoch 18: Train MSE = 0.064060\n",
            "Epoch 19: Train MSE = 0.057147\n",
            "Epoch 20: Train MSE = 0.055788\n",
            "Epoch 21: Train MSE = 0.060213\n",
            "Epoch 22: Train MSE = 0.053340\n",
            "Epoch 23: Train MSE = 0.055352\n",
            "Epoch 24: Train MSE = 0.054120\n",
            "Epoch 25: Train MSE = 0.053724\n",
            "Epoch 26: Train MSE = 0.063190\n",
            "Epoch 27: Train MSE = 0.056931\n",
            "Epoch 28: Train MSE = 0.061038\n",
            "Epoch 29: Train MSE = 0.053703\n",
            "Epoch 30: Train MSE = 0.055803\n",
            "Epoch 31: Train MSE = 0.052391\n",
            "Epoch 32: Train MSE = 0.060201\n",
            "Epoch 33: Train MSE = 0.056900\n",
            "Epoch 34: Train MSE = 0.059275\n",
            "Epoch 35: Train MSE = 0.057678\n",
            "Epoch 36: Train MSE = 0.063363\n",
            "Epoch 37: Train MSE = 0.065651\n",
            "Epoch 38: Train MSE = 0.061599\n",
            "Epoch 39: Train MSE = 0.061520\n",
            "Epoch 40: Train MSE = 0.056134\n",
            "Epoch 41: Train MSE = 0.058931\n",
            "Epoch 42: Train MSE = 0.063053\n",
            "Epoch 43: Train MSE = 0.055185\n",
            "Epoch 44: Train MSE = 0.053169\n",
            "Epoch 45: Train MSE = 0.054100\n",
            "Epoch 46: Train MSE = 0.062737\n",
            "Epoch 47: Train MSE = 0.065622\n",
            "Epoch 48: Train MSE = 0.061206\n",
            "Epoch 49: Train MSE = 0.060550\n",
            "Epoch 50: Train MSE = 0.058693\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    preds = model(X_test)\n",
        "    test_mse = loss_fn(preds, y_test).item()\n",
        "    test_mae = mean_absolute_error(y_test.numpy(), preds.numpy())\n",
        "\n",
        "    print(f\"Test MSE: {test_mse:.6f}\")\n",
        "    print(f\"Test MAE: {test_mae:.6f}\")"
      ],
      "metadata": {
        "id": "G6MjbcdAnRAR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3ba09ea-5348-4849-afa1-7bbcc6180028"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test MSE: 2.572263\n",
            "Test MAE: 1.059710\n"
          ]
        }
      ]
    }
  ]
}